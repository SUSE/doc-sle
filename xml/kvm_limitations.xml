<?xml version="1.0"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<chapter id="cha.kvm.limits">
 <title>&kvm; Limitations</title>
 <para>
  Although virtualized machines behave almost like physical machines, some
  limitations apply. These affect both, the &vmguest; as well as the
  &vmhost; system.
 </para>
 <sect1 id="sec.kvm.limits.general">
  <title>General Limitations</title>

  <para>
   The following general restrictions apply when using &kvm;:
  </para>

  <variablelist>
   <varlistentry>
    <term>Overcommits</term>
    <listitem>
     <para>
      &kvm; allows for both memory and disk space overcommit. It is up to
      the user to understand the implications of doing so. However, hard
      errors resulting from exceeding available resources will result in
      guest failures. CPU overcommit is also supported but carries
      performance implications.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry condition="kvm4x86">
    <term>Time Synchronization</term>
    <listitem>
     <para>
      Most guests require some additional support for accurate time keeping.
      Where available, <systemitem>kvm-clock</systemitem> is to be used. NTP
      or similar network based time keeping protocols are also highly
      recommended (for &vmhost; and &vmguest;) to help maintain a stable
      time. Running NTP inside the guest is not recommended when using the
      <systemitem>kvm-clock</systemitem> . Refer to
      <xref
       linkend="sec.kvm.managing.clock"/> for details.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MAC addresses</term>
    <listitem>
     <para>
      If no MAC address is specified for a NIC, a default MAC address will
      be assigned. This may result in network problems when more than one
      NIC receives the same MAC address. It is recommended to always assure
      a unique MAC address has been assigned for each NIC.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Live Migration</term>
    <listitem>
     <para condition="kvm4x86">
      Live Migration is only possible between &vmhost;s with the same CPU
      features. The only supported CPU model for migration is <option>-cpu
      qemu64</option> (default) with no additional features specified. No
      physical devices can be passed from host to guest. Guest storage has
      to be accessible from both &vmhost;s and guest definitions need to be
      compatible. &vmhost; and &vmguest;s need to have proper timekeeping
      installed. The use of the AHCI interface, the
      <literal>virtfs</literal> feature, and the
      <literal>-mem-path</literal> command-line option are not compatible
      with migration. Migration from SP3 to SP2 or SP1 hosted guests is not
      supported.
     </para>
     <para condition="kvm4zSeries">
      Live migration is not supported on IBM &zseries;.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>User Permissions</term>
    <listitem>
     <para>
      The management tools (&vmm;, <command>virsh</command>,
      <command>vm-install</command>) need to authenticate with
      &libvirt;&mdash;see <xref linkend="cha.libvirt.connect"/> for details.
      In order to invoke <command>qemu-kvm</command> from the command line,
      a user has to be a member of the group
      <systemitem
       class="groupname">kvm</systemitem>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Suspending/Hibernating the &vmhost;</term>
    <listitem>
     <para>
      Suspending or hibernating the &vmhost; system while guests are running
      is not supported.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 id="sec.kvm.limits.hardware">
  <title>Hardware Limitations</title>

  <para>
   The following virtual hardware limits for guests have been tested. We
   ensure host and VMs install and work successfully, even when reaching the
   limits and there are no major performance regressions (CPU, memory, disk,
   network) since the last release.
  </para>

  <informaltable>
   <tgroup cols="2">
    <colspec colname="c1" colwidth="40*"/>
    <colspec colname="c2" colwidth="60*"/>
    <tbody>
     <row>
      <entry>
       <para>
        <emphasis>Max. Guest RAM Size</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        <phrase condition="kvm4x86">2TB</phrase>
        <phrase condition="kvm4zSeries">256 GB</phrase>
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis>Max. Virtual CPUs per Guest</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        <phrase condition="kvm4x86">160</phrase>
        <phrase condition="kvm4zSeries">64 Num CPUs</phrase>
       </para>
      </entry>
     </row>
     <row condition="kvm4x86">
      <entry>
       <para>
        <emphasis>Max. Virtual Network Devices per Guest</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        8
       </para>
      </entry>
     </row>
     <row condition="kvm4x86">
      <entry>
       <para>
        <emphasis>Max. Block Devices per Guest</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        4 emulated (IDE), 20 para-virtual (using
        <systemitem>virtio-blk</systemitem>), or 100
        (<systemitem>virtio-scsi</systemitem>)
       </para>
      </entry>
     </row>
     <row condition="kvm4zSeries">
      <entry>
       <para>
        <emphasis>Max. Block/Network Devices per Guest</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        64.000
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis>Max. Number of &vmguest;s per &vmhost;</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        Limit is defined as the total number of virtual CPUs in all guests
        being no greater than 8 times the number of CPU cores in the host.
       </para>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </sect1>
 <sect1 id="sec.kvm.limits.performance" condition="kvm4x86">
  <title>Performance Limitations</title>

  <para>
   Basically, workloads designed for physical installations can be
   virtualized and therefore inherit the benefits of modern virtualization
   techniques. However, virtualization comes at the cost of a slight to
   moderate performance impact. You should always test your workload with
   the maximum anticipated CPU and I/O load to verify if it is suited for
   being virtualized. Although every reasonable effort is made to provide a
   broad virtualization solution to meet disparate needs, there will be
   cases where the workload itself is unsuited for &kvm; virtualization.
  </para>

  <para>
   We therefore propose the following performance expectations for guests
   performance to be used as a guideline. The given percentage values are a
   comparison of performance achieved with the same workload under
   non-virtualized conditions. The values are rough approximations and
   cannot be guaranteed.
  </para>

  <informaltable>
   <tgroup cols="4">
    <thead>
     <row>
      <entry>
       <para>
        Category
       </para>
      </entry>
      <entry>
       <para>
        Fully Virtualized
       </para>
      </entry>
      <entry>
       <para>
        Paravirtualized
       </para>
      </entry>
      <entry>
       <para>
        Host Pass-through
       </para>
      </entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry>
       <para>
        <emphasis>CPU, MMU</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        7%
       </para>
      </entry>
      <entry>
       <para>
        not applicable
       </para>
      </entry>
      <entry>
       <simplelist>
        <member>
	 97% (Hardware Virtualization with Extended Page Tables (Intel)
	 or Nested Page Tables (AMD)
	</member>
        <member>
	 85% (Hardware Virtualization with shadow page tables)
	</member>
       </simplelist>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis>Network I/O (1GB LAN)</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        60% (e1000 emulated NIC)
       </para>
      </entry>
      <entry>
       <para>
        75% (<systemitem>virtio-net</systemitem>)
       </para>
      </entry>
      <entry>
       <para>
        95%
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis>Disk I/O</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        40% (IDE emulation)
       </para>
      </entry>
      <entry>
       <para>
        85% (<systemitem>virtio-blk</systemitem>)
       </para>
      </entry>
      <entry>
       <para>
        95%
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis>Graphics (non-accelerated)</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        50% (VGA or Cirrus)
       </para>
      </entry>
      <entry>
       <para>
        not applicable
       </para>
      </entry>
      <entry>
       <para>
        not applicable
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        <emphasis>Time accuracy (worst case, using recommended settings
        without NTP)</emphasis>
       </para>
      </entry>
      <entry>
       <para>
        95% - 105% (where 100% = accurate)
       </para>
      </entry>
      <entry>
       <para>
        100% (<systemitem>kvm-clock</systemitem>)
       </para>
      </entry>
      <entry>
       <para>
        not applicable
       </para>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </informaltable>
 </sect1>
</chapter>
