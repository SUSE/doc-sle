<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="storage_nvmeof.xml" version="5.0" xml:id="cha-nvmeof" xml:lang="zh-tw">
 <title>NVMe over Fabric</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>是</dm:translation>
  </dm:docmanager>
  <abstract>
   <para>
    本章介紹如何設定 NVMe over Fabric 主機和目標。
   </para>
  </abstract>
 </info>
 <sect1 xml:id="sec-nvmeof-overview">
  <title>綜覽</title>
  <para>
   <emphasis>NVM Express</emphasis> (<emphasis>NVMe</emphasis>) 是有關存取非揮發性儲存 (通常是 SSD 磁碟) 的介面標準。與 SATA 相比，NVMe 支援的速度要高得多，並且延遲更低。
  </para>
  <para>
   <emphasis>NVMe over Fabric</emphasis> 是用於透過不同網路架構存取 NVMe 儲存的結構。這些網路架構有 <emphasis>RDMA</emphasis> 或<emphasis>光纖通道 NVMe</emphasis> (<emphasis>FC-NVMe</emphasis>) 等。NVMe over Fabric 的作用類似於 iSCSI。為提高容錯能力，NVMe over Fabric 內建了多重路徑支援。NVMe over Fabric 多重路徑不是以傳統 DM 多重路徑為基礎。
  </para>
  <para>
   <emphasis>NVMe 主機</emphasis>是連接到 NVMe 目標的機器。<emphasis>NVMe 目標</emphasis>是共用其 NVMe 區塊裝置的機器。
  </para>
  <para>
   SUSE Linux Enterprise Server <phrase role="productnumber"><phrase os="sles;sled">15 SP1</phrase></phrase> 支援 NVMe。提供了可用於 NVMe 區塊儲存及 NVMe over Fabric 目標和主機的核心模組。
  </para>
  <para>
   若要查看您的硬體是否有任何特殊考量，請參閱<xref linkend="sec-nvmeof-hardware"/>。
  </para>
 </sect1>
 <sect1 xml:id="sec-nvmeof-host-configuration">
  <title>設定 NVMe over Fabric 主機</title>
  <para>
   若要使用 NVMe over Fabric，必須在目標上使用支援的網路方法。支援的方法包括光纖通道 NVMe 和 RDMA。以下小節介紹如何將主機連接到 NVMe 目標。
  </para>
  <sect2 xml:id="sec-nvmeof-host-configuration-cli">
   <title>安裝指令行用戶端</title>
   <para>
    若要使用 NVMe over Fabric，需要安裝 <command>nvme</command> 指令行工具。請使用 <command>zypper</command> 安裝該工具︰
   </para>
   <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>zypper in nvme-cli</command></screen>
   <para>
    使用 <command>nvme --help</command> 可列出所有可用的子指令。我們提供了 <command>nvme</command> 子指令的 man 頁面。執行 <command>man nvme-<replaceable>SUBCOMMAND</replaceable></command> 可參閱相關的 man 頁面。例如，若要檢視 <option>discover</option> 子指令的 man 頁面，請執行 <command>man nvme-discover</command>。
   </para>
  </sect2>
  <sect2 xml:id="sec-nvmeof-host-configuration-target-discovery">
   <title>探查 NVMe over Fabric 目標</title>
   <para>
    若要列出 NVMe over Fabric 目標上的可用 NVMe 子系統，您需有探查控制器位址和服務 ID。
   </para>
   <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>nvme discover -t <replaceable>TRANSPORT</replaceable> -a <replaceable>DISCOVERY_CONTROLLER_ADDRESS</replaceable> -s <replaceable>SERVICE_ID</replaceable></command></screen>
   <para>
    以基礎傳輸媒體 (<option>loop</option>、<option>rdma</option> 或 <option>fc</option>) 取代 <replaceable>TRANSPORT</replaceable>。以探查控制器的位址取代 <replaceable>DISCOVERY_CONTROLLER_ADDRESS</replaceable>。對於 RDMA，此位址應是 IPv4 位址。以傳輸服務 ID 取代 <replaceable>SERVICE_ID</replaceable>。如果服務以 IP 為基礎 (例如 RDMA)，則服務 ID 指定連接埠號碼。對於光纖通道，不需要提供服務 ID。
   </para>
   <para>
    NVMe 主機只會看到它們有權連接的子系統。
   </para>
   <para>
    範例︰
   </para>
   <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>nvme discover -t rdma -a 10.0.0.1 -s 4420</command></screen>
   <para>
    如需更多詳細資料，請參閱 <command>man nvme-discover</command>。
   </para>
  </sect2>
  <sect2 xml:id="sec-nvmeof-host-configuration-connect-target">
   <title>連接 NVMe over Fabric 目標</title>
   <para>
    識別 NVMe 子系統後，可以使用 <command>nvme connect</command> 指令來連接它。
   </para>
   <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>nvme connect -t <replaceable>transport</replaceable> -a <replaceable>DISCOVERY_CONTROLLER_ADDRESS</replaceable> -s <replaceable>SERVICE_ID</replaceable> -n <replaceable>SUBSYSTEM_NQN</replaceable></command></screen>
   <para>
    以基礎傳輸媒體 (<option>loop</option>、<option>rdma</option> 或 <option>fc</option>) 取代 <replaceable>TRANSPORT</replaceable>。以探查控制器的位址取代 <replaceable>DISCOVERY_CONTROLLER_ADDRESS</replaceable>。對於 RDMA，此位址應是 IPv4 位址。以傳輸服務 ID 取代 <replaceable>SERVICE_ID</replaceable>。如果服務以 IP 為基礎 (例如 RDMA)，則此 ID 指定連接埠號碼。以探查指令找到的所需子系統的 NVMe 合格名稱取代 <replaceable>SUBSYSTEM_NQN</replaceable>。<emphasis>NQN</emphasis> 是 <emphasis>NVMe 合格名稱</emphasis> (NVMe Qualified Name) 的縮寫。NQN 必須是唯一的。
   </para>
   <para>範例︰</para>
   <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>nvme connect -t rdma -a 10.0.0.1 -s 4420 -n nqn.2014-08.com.example:nvme:nvm-subsystem-sn-d78432</command></screen>
   <para>
    或者，使用 <command>nvme connect-all</command> 連接探查到的所有名稱空間。如需進階用法，請參閱 <command>man nvme-connect</command> 和 <command>man nvme-connect-all</command>。
   </para>
  </sect2>
  <sect2 xml:id="sec-nvmeof-host-configuration-multipathing">
   <title>多重路徑</title>
   <para>
    預設會啟用 NVMe 原生多重路徑。若要列印多重路徑裝置的配置，請使用指令 <command>nvme list-subsys</command>。若要停用 NVMe 原生多重路徑，請新增 <option>nvme-core.multipath=N</option> 做為開機參數。
   </para>
   <para>
    指令 <command>multipath -ll</command> 有相容模式，可顯示 NVMe 多重路徑裝置。
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-nvmeof-target-configuration">
  <title>設定 NVMe over Fabric 目標</title>
  <sect2 xml:id="sec-nvmeof-target-configuration-cli">
   <title>安裝指令行用戶端</title>
   <para>
    若要設定 NVMe over Fabric 目標，需要安裝 <command>nvmetcli</command> 指令行工具。請使用 <command>zypper</command> 安裝該工具︰
   </para>
   <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>zypper in nvmetcli</command></screen>
   <para>
    <command> 上提供了 </command>nvmetcli<link xlink:href="http://git.infradead.org/users/hch/nvmetcli.git/blob_plain/HEAD:/Documentation/nvmetcli.txt"/> 的最新文件.
   </para>
  </sect2>
  <sect2 xml:id="sec-nvmeof-target-configuration-steps">
   <title>組態步驟</title>
   <para>
    下面的程序舉例說明如何設定 NVMe over Fabric 目標。
   </para>
   <para>
    組態儲存在樹狀結構中。使用 <command>cd</command> 指令可進行導覽。使用 <command>ls</command> 可列出物件。您可以使用 <command>create</command> 建立新物件。
   </para>
   <procedure>
    <step>
     <para>
      啟動 <command>nvmectli</command> 互動式外圍程序：
     </para>
     <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>nvmetcli</command></screen>
    </step>
    <step>
     <para>
      建立新連接埠：
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd ports</command>
<prompt>(nvmetcli)&gt; </prompt><command>create 1</command>
<prompt>(nvmetcli)&gt; </prompt><command>ls 1/</command>
o- 1
  o- referrals
  o- subsystems</screen>
    </step>
    <step>
     <para>
      建立 NVMe 子系統：
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd /subsystems</command>
<prompt>(nvmetcli)&gt; </prompt><command>create nqn.2014-08.org.nvmexpress:NVMf:uuid:c36f2c23-354d-416c-95de-f2b8ec353a82</command>
<prompt>(nvmetcli)&gt; </prompt><command>cd nqn.2014-08.org.nvmexpress:NVMf:uuid:c36f2c23-354d-416c-95de-f2b8ec353a82/</command>
<prompt>(nvmetcli)&gt; </prompt><command>ls</command>
o- nqn.2014-08.org.nvmexpress:NVMf:uuid:c36f2c23-354d-416c-95de-f2b8ec353a82
  o- allowed_hosts
  o- namespaces</screen>
    </step>
    <step>
     <para>
      建立新的名稱空間，並在其中設定 NVMe 裝置：
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd namespaces</command>
<prompt>(nvmetcli)&gt; </prompt><command>create 1</command>
<prompt>(nvmetcli)&gt; </prompt><command>cd 1</command>
<prompt>(nvmetcli)&gt; </prompt><command>set device path=/dev/nvme0n1</command>
Parameter path is now '/dev/nvme0n1'.</screen>
    </step>
    <step>
     <para>
      啟用先前建立的名稱空間：
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd ..</command>
<prompt>(nvmetcli)&gt; </prompt><command>enable</command>
The Namespace has been enabled.</screen>
    </step>
    <step>
     <para>
      顯示建立的名稱空間：
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd ..</command>
<prompt>(nvmetcli)&gt; </prompt><command>ls</command>
o- nqn.2014-08.org.nvmexpress:NVMf:uuid:c36f2c23-354d-416c-95de-f2b8ec353a82
  o- allowed_hosts
  o- namespaces
    o- 1</screen>
    </step>
    <step>
     <para>
      允許所有主機使用該子系統。只有在安全環境中才可這樣做。
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>set attr allow_any_host=1</command>
Parameter allow_any_host is now '1'.</screen>
     <para>
      或者，可以只允許特定的主機建立連接︰
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd nqn.2014-08.org.nvmexpress:NVMf:uuid:c36f2c23-354d-416c-95de-f2b8ec353a82/allowed_hosts/</command>
<prompt>(nvmetcli)&gt; </prompt><command>create hostnqn</command></screen>
    </step>
    <step>
     <para>
      列出建立的所有物件︰
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd /</command>
<prompt>(nvmetcli)&gt; </prompt><command>ls</command>
o- /
  o- hosts
  o- ports
  | o- 1
  |   o- referrals
  |   o- subsystems
  o- subsystems
    o- nqn.2014-08.org.nvmexpress:NVMf:uuid:c36f2c23-354d-416c-95de-f2b8ec353a82
      o- allowed_hosts
      o- namespaces
        o- 1</screen>
    </step>
    <step>
     <para>
      使目標可透過 RDMA 使用︰
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd ports/1/</command>
<prompt>(nvmetcli)&gt; </prompt><command>set addr adrfam=ipv4 trtype=rdma traddr=10.0.0.1 trsvcid=4420</command>
Parameter trtype is now 'rdma'.
Parameter adrfam is now 'ipv4'.
Parameter trsvcid is now '4420'.
Parameter traddr is now '10.0.0.1'.</screen>
     <para>
      或者，使目標可透過光纖通道使用︰
     </para>
<screen><prompt>(nvmetcli)&gt; </prompt><command>cd ports/1/</command>
<prompt>(nvmetcli)&gt; </prompt><command>set addr adrfam=fc trtype=fc traddr=nn-0x1000000044001123:pn-0x2000000055001123 trsvcid=none</command></screen>
    </step>
   </procedure>
  </sect2>
  <sect2 xml:id="sec-nvmeof-target-configuration-backup-configuration">
   <title>備份和還原目標組態</title>
   <para>
    可使用以下指令在 JSON 檔案中儲存目標組態︰
   </para>
<screen><prompt>tux &gt; </prompt><command>sudo</command> <command>nvmetcli</command>
<prompt>(nvmetcli)&gt; </prompt><command>saveconfig nvme-target-backup.json</command></screen>
    <para>
     若要還原組態，請使用︰
    </para>
    <screen><prompt>(nvmetcli)&gt; </prompt><command>restore nvme-target-backup.json</command></screen>
    <para>
     您還可以抹除目前組態︰
    </para>
    <screen><prompt>(nvmetcli)&gt; </prompt><command>clear</command></screen>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-nvmeof-hardware">
  <title>特殊硬體組態</title>
  <sect2 xml:id="sec-nvmeof-hardware-overview">
   <title>綜覽</title>
   <para>
    某些硬體需要特殊的組態才能正常運作。請瀏覽以下章節的標題，確定您是否使用了所提到的任何裝置或廠商。
   </para>
  </sect2>
  <sect2 xml:id="sec-nvmeof-hardware-broadcom">
   <title>Broadcom</title>
   <para>
    如果您在使用 <emphasis>Broadcom Emulex LightPulse Fibre Channel SCSI</emphasis> 驅動程式，請在 <literal>lpfc</literal> 模組的目標和主機中新增核心組態參數︰
   </para>
   <screen><prompt>tux &gt; </prompt><command>sudo</command> <command>echo "options lpfc lpfc_enable_fc4_type=3" &gt; /etc/modprobe.d/lpfc.conf</command></screen>
   <para>
    確定 Broadcom 介面卡韌體的版本至少為 11.4.204.33。另請確定已安裝最新版本的
    <package>nvme-cli</package>、 <package>nvmetcli</package> 和核心。
   </para>
   <para>
    若要啟用光纖通道連接埠做為 NVMe 目標，需要額外設定一個模組參數︰<option>lpfc_enable_nvmet=<replaceable> COMMA_SEPARATED_WWPNS</replaceable></option>。請輸入帶有前置 <literal>0x</literal> 的 WWPN，例如 <option>lpfc_enable_nvmet=0x2000000055001122,0x2000000055003344</option>。系統只會為目標模式設定列出的 WWPN。可將光纖通道連接埠設定為目標<emphasis>或</emphasis>啟動器。
   </para>
   <para>
    如需更多詳細資料，請參閱 <link xlink:href="https://docs.broadcom.com/docs/12379413"/>。
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-nvmeof-more-information">
  <title>更多資訊</title>
  <para>
   如需 <command>nvme</command> 功能的更多詳細資料，請參閱 <command>nvme nvme-help</command>。
  </para>
  <para>
   以下連結提供了 NVMe 和 NVMe over Fabric 的簡介︰
  </para>
  <itemizedlist>
   <listitem>
    <para><link xlink:href="http://nvmexpress.org/"/></para>
   </listitem>
   <listitem>
    <para><link xlink:href="http://www.nvmexpress.org/wp-content/uploads/NVMe_Over_Fabrics.pdf"/></para>
   </listitem>
   <listitem>
    <para><link xlink:href="https://storpool.com/blog/demystifying-what-is-nvmeof"/></para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>
