<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-tuning-taskscheduler">
 <title>Tuning the Task Scheduler</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:bugtracker>
          </dm:bugtracker>
      </dm:docmanager>
    </info>
    <para>
  Modern operating systems, such as &productnamereg;, normally run many
  tasks at the same time. For example, you can be searching in a
  text file while receiving an e-mail and copying a big file to an external
  hard disk. These simple tasks require many additional processes to be run
  by the system. To provide each task with its required system resources,
  the Linux kernel needs a tool to distribute available system resources to
  individual tasks. And this is exactly what the <emphasis>task
  scheduler</emphasis> does.
 </para>
 <para>
  The following sections explain the most important terms related to a
  process scheduling. They also introduce information about the task
  scheduler policy, scheduling algorithm, description of the task scheduler
  used by &productname;, and references to other sources of relevant
  information.
 </para>
 <sect1 xml:id="sec-tuning-taskscheduler-intro">
  <title>Introduction</title>

  <para>
   The Linux kernel controls the way that tasks (or processes) are managed
   on the system. The task scheduler, sometimes called <emphasis>process
   scheduler</emphasis>, is the part of the kernel that decides which task
   to run next. It is responsible for best using system resources to
   guarantee that multiple tasks are being executed simultaneously. This
   makes it a core component of any multitasking operating system.
  </para>

  <sect2 xml:id="sec-tuning-taskscheduler-intro-preemption">
   <title>Preemption</title>
   <para>
    The theory behind task scheduling is very simple. If there are runnable
    processes in a system, at least one process must always be running. If
    there are more runnable processes than processors in a system, not all
    the processes can be running all the time.
   </para>
   <para>
    Therefore, some processes need to be stopped temporarily, or
    <emphasis>suspended</emphasis>, so that others can be running again. The
    scheduler decides what process in the queue will run next.
   </para>
   <para>
    As already mentioned, Linux, like all other Unix variants, is a
    <emphasis>multitasking</emphasis> operating system. That means that
    several tasks can be running at the same time. Linux provides a so
    called <emphasis>preemptive</emphasis> multitasking, where the scheduler
    decides when a process is suspended. This forced suspension is called
    <emphasis>preemption</emphasis>. All Unix flavors have been providing
    preemptive multitasking since the beginning.
   </para>
  </sect2>

  <sect2 xml:id="sec-tuning-taskscheduler-intro-timeslice">
   <title>Timeslice</title>
   <para>
    The time period for which a process will be running before it is
    <emphasis>preempted</emphasis> is defined in advance. It is called a
    <emphasis>timeslice</emphasis> of a process and represents the amount of
    processor time that is provided to each process. By assigning
    timeslices, the scheduler makes global decisions for the running system,
    and prevents individual processes from dominating over the processor
    resources.
    <remark>sknorr, 2014-08-22: "dominate over" sounds weird, not sure if just
     "dominate" would be better, though.</remark>
   </para>
  </sect2>

  <sect2 xml:id="sec-tuning-taskscheduler-intro-priority">
   <title>Process Priority</title>
   <para>
    The scheduler evaluates processes based on their priority. To calculate
    the current priority of a process, the task scheduler uses complex
    algorithms. As a result, each process is given a value according to
    which it is <quote>allowed</quote> to run on a processor.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-tuning-taskscheduler-policy-class">
  <title>Process Classification</title>

  <para>
   Processes are usually classified according to their purpose and behavior.
   Although the borderline is not always clearly distinct, generally two
   criteria are used to sort them. These criteria are independent and do not
   exclude each other.
  </para>

  <para>
   One approach is to classify a process either
   <emphasis>I/O-bound</emphasis> or <emphasis>processor-bound</emphasis>.
  </para>

  <variablelist>
   <varlistentry>
    <term>I/O-bound</term>
    <listitem>
     <para>
      I/O stands for Input/Output devices, such as keyboards, mice, or
      optical and hard disks. <emphasis>I/O-bound processes</emphasis> spend
      the majority of time submitting and waiting for requests. They are run
      very frequently, but for short time intervals, not to block other
      processes waiting for I/O requests.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>processor-bound</term>
    <listitem>
     <para>
      On the other hand, <emphasis>processor-bound</emphasis> tasks use
      their time to execute a code, and usually run until they are preempted
      by the scheduler. They do not block processes waiting for I/O
      requests, and, therefore, can be run less frequently but for longer
      time intervals.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Another approach is to divide processes by type into
   <emphasis>interactive</emphasis>, <emphasis>batch</emphasis>, and
   <emphasis>real-time</emphasis> processes.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <emphasis>Interactive</emphasis> processes spend a lot of time waiting
     for I/O requests, such as keyboard or mouse operations. The scheduler
     must wake up such processes quickly on user request, or the user will
     find the environment unresponsive. The typical delay is approximately
     100 ms. Office applications, text editors or image manipulation
     programs represent typical interactive processes.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Batch</emphasis> processes often run in the background and do
     not need to be responsive. They usually receive lower priority from the
     scheduler. Multimedia converters, database search engines, or log files
     analyzers are typical examples of batch processes.
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis>Real-time</emphasis> processes must never be blocked by
     low-priority processes, and the scheduler guarantees a short response
     time to them. Applications for editing multimedia content are a good
     example here.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
<!-- 2014-07-22 tbazant: removing, O1 not used anymore
 <sect1 id="sec-tuning-taskscheduler-o1">
  <title>O(1) Scheduler</title>

  <para>
   The Linux kernel version 2.6 introduced a new task scheduler, called O(1)
   scheduler (see
   <ulink
    url="http://en.wikipedia.org/wiki/Big_O_notation">Big O
   notation</ulink>), It was used as the default scheduler up to Linux kernel
   version 2.6.22. Its main task is to schedule tasks within a fixed amount
   of time, no matter how many runnable processes there are in the system.
  </para>

  <para>
   The scheduler calculates the timeslices dynamically. However, to
   determine the appropriate timeslice is a complex task: Too long
   timeslices cause the system to be less interactive and responsive, while
   too short ones make the processor waste a lot of time on the overhead of
   switching the processes too frequently. The default timeslice is usually
   rather low, for example 20ms. The scheduler determines the timeslice
   based on priority of a process, which allows the processes with higher
   priority to run more often and for a longer time.
  </para>

  <para>
   A process does not have to use all its timeslice at once. For instance, a
   process with a timeslice of 150ms does not have to be running for 150ms
   in one go. It can be running in five different schedule slots for 30ms
   instead. Interactive tasks typically benefit from this approach because
   they do not need such a large timeslice at once while they need to be
   responsive as long as possible.
  </para>

  <para>
   The scheduler also assigns process priorities dynamically. It monitors
   the processes' behavior and, if needed, adjusts its priority. For
   example, a process which is being suspended for a long time is brought up
   by increasing its priority.
  </para>
 </sect1>
 -->
 <sect1 xml:id="sec-tuning-taskscheduler-cfs">
  <title>Completely Fair Scheduler</title>

  <para>
   Since the Linux kernel version 2.6.23, a new approach has been taken to
   the scheduling of runnable processes. Completely Fair Scheduler (CFS)
   became the default Linux kernel scheduler. Since then, important changes
   and improvements have been made. The information in this chapter applies
   to &productname; with kernel version 2.6.32 and higher (including 3.x
   kernels). The scheduler environment was divided into several parts, and
   three main new features were introduced:
  </para>

  <variablelist>
   <varlistentry>
    <term>Modular Scheduler Core</term>
    <listitem>
     <para>
      The core of the scheduler was enhanced with <emphasis>scheduling
      classes</emphasis>. These classes are modular and represent scheduling
      policies.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Completely Fair Scheduler</term>
    <listitem>
     <para>
      Introduced in kernel 2.6.23 and extended in 2.6.24, CFS tries to
      assure that each process obtains its <quote>fair</quote> share of the
      processor time.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Group Scheduling</term>
    <listitem>
     <para>
      For example, if you split processes into groups according to which
      user is running them, CFS tries to provide each of these groups with
      the same amount of processor time.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   As a result, CFS brings optimized scheduling for both servers and
   desktops.
  </para>

  <sect2 xml:id="sec-tuning-taskscheduler-cfs-howitworks">
   <title>How CFS Works</title>
   <para>
    CFS tries to guarantee a fair approach to each runnable task. To find
    the most balanced way of task scheduling, it uses the concept of
    <emphasis>red-black tree</emphasis>. A red-black tree is a type of
    self-balancing data search tree which provides inserting and removing
    entries in a reasonable way so that it remains well balanced. For more
    information, see the wiki pages of
    <link xlink:href="http://en.wikipedia.org/wiki/Red_black_tree">Red-black
    tree</link>.
   </para>
   <para>
    When CFS schedules a task it accumulates <quote>virtual
    runtime</quote> or <emphasis>vruntime</emphasis>. The next task picked
    to run is always the task with the minimum accumulated vruntime so
    far. By balancing the red-black tree when tasks are inserted into the
    <emphasis>run queue</emphasis> (a planned time line of processes to be
    executed next), the task with the minimum vruntime is always the first
    entry in the red-black tree.
   </para>
   <para>
    The amount of vruntime a task accrues is related to its priority.
    High priority tasks gain vruntime at a slower rate than low priority
    tasks, which results in high priority tasks being picked to run on the
    processor more often.
   </para>
  </sect2>

  <sect2 xml:id="sec-tuning-taskscheduler-cfs-grouping">
   <title>Grouping Processes</title>
   <para>
    Since the Linux kernel version 2.6.24, CFS can be tuned to be fair
    to groups rather than to tasks only. Runnable tasks are then grouped
    to form entities, and CFS tries to be fair to these entities instead
    of individual runnable tasks. The scheduler also tries to be fair to
    individual tasks within these entities.
   </para>
   <para>
    The kernel scheduler lets you group runnable tasks using control
    groups. For more information, see <xref linkend="cha-tuning-cgroups"/>.
   </para>
  </sect2>

  <sect2 xml:id="sec-tuning-taskscheduler-cfs-kernelconfig">
   <title>Kernel Configuration Options</title>
   <para>
    Basic aspects of the task scheduler behavior can be set through the
    kernel configuration options. Setting these options is part of the
    kernel compilation process. Because kernel compilation process is a
    complex task and out of this document's scope, refer to relevant source
    of information.
   </para>
   <warning>
    <title>Kernel Compilation</title>
    <para>
     If you run &productname; on a kernel that was not shipped with it,
     for example on a self-compiled kernel, you lose the entire support
     entitlement.
    </para>
   </warning>
  </sect2>

  <sect2 xml:id="sec-tuning-taskscheduler-cfs-terms">
   <title>Terminology</title>
   <para>
    Documents regarding task scheduling policy often use several technical
    terms which you need to know to understand the information correctly.
    Here are some:
   </para>
   <variablelist>
    <varlistentry>
     <term>Latency</term>
     <listitem>
      <para>
       Delay between the time a process is scheduled to run and the actual
       process execution.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Granularity</term>
     <listitem>
      <para>
       The relation between granularity and latency can be expressed by the
       following equation:
      </para>
<screen>gran = ( lat / rtasks ) - ( lat / rtasks / rtasks )</screen>
      <para>
       where <emphasis>gran</emphasis> stands for granularity,
       <emphasis>lat</emphasis> stand for latency, and
       <emphasis>rtasks</emphasis> is the number of running tasks.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <sect3 xml:id="kernel-tasksched-policies">
    <title>Scheduling Policies</title>
    <para>
     The Linux kernel supports the following scheduling policies:
    </para>
    <variablelist>
     <varlistentry>
      <term>SCHED_FIFO</term>
      <listitem>
       <para>
        Scheduling policy designed for special time-critical applications.
        It uses the First In-First Out scheduling algorithm.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>SCHED_BATCH</term>
      <listitem>
       <para>
        Scheduling policy designed for CPU-intensive tasks.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>SCHED_IDLE</term>
      <listitem>
       <para>
        Scheduling policy intended for <emphasis>very</emphasis> low
        prioritized tasks.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>SCHED_OTHER</term>
      <listitem>
       <para>
        Default Linux time-sharing scheduling policy used by the majority of
        processes.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>SCHED_RR</term>
      <listitem>
       <para>
        Similar to <systemitem>SCHED_FIFO</systemitem>, but uses the Round
        Robin scheduling algorithm.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>

  <sect2 xml:id="sec-tuning-taskscheduler-cfs-chrt">
   <title>Changing Real-time Attributes of&nbsp;Processes with <command>chrt</command></title>
   <para>
    The <command>chrt</command> command sets or retrieves the real-time
    scheduling attributes of a running process, or runs a command with the
    specified attributes. You can get or retrieve both the scheduling policy
    and priority of a process.
   </para>
   <para>
    In the following examples, a process whose PID is 16244 is used.
   </para>
   <para>
    To <emphasis>retrieve</emphasis> the real-time attributes of an existing
    task:
   </para>
<screen>&prompt.root;chrt -p 16244
pid 16244's current scheduling policy: SCHED_OTHER
pid 16244's current scheduling priority: 0
</screen>
   <para>
    Before setting a new scheduling policy on the process, you need to find
    out the minimum and maximum valid priorities for each scheduling
    algorithm:
   </para>
<screen>&prompt.root;chrt -m
SCHED_SCHED_OTHER min/max priority : 0/0
SCHED_SCHED_FIFO min/max priority : 1/99
SCHED_SCHED_RR min/max priority : 1/99
SCHED_SCHED_BATCH min/max priority : 0/0
SCHED_SCHED_IDLE min/max priority : 0/0
</screen>
   <para>
    In the above example, SCHED_OTHER, SCHED_BATCH, SCHED_IDLE polices only
    allow for priority 0, while that of SCHED_FIFO and SCHED_RR can range
    from 1 to 99.
   </para>
   <para>
    To set SCHED_BATCH scheduling policy:
   </para>
<screen>&prompt.root;chrt -b -p 0 16244
pid 16244's current scheduling policy: SCHED_BATCH
pid 16244's current scheduling priority: 0
</screen>
   <para>
    For more information on <command>chrt</command>, see its man page
    (<command>man 1 chrt</command>).
   </para>
  </sect2>

  <sect2 xml:id="sec-tuning-taskscheduler-cfs-tuning">
   <title>Runtime Tuning with <command>sysctl</command></title>
   <para>
    The <command>sysctl</command> interface for examining and changing
    kernel parameters at runtime introduces important variables by means of
    which you can change the default behavior of the task scheduler. The
    syntax of the <command>sysctl</command> is simple, and all the following
    commands must be entered on the command line as &rootuser;.
   </para>
   <para>
    To read a value from a kernel variable, enter
   </para>
<screen>&prompt.root;<command>sysctl</command> <replaceable>VARIABLE</replaceable></screen>
   <para>
    To assign a value, enter
   </para>
<screen>&prompt.root;<command>sysctl</command> <replaceable>VARIABLE</replaceable>=<replaceable>VALUE</replaceable></screen>
   <para>
    To get a list of all scheduler related <command>sysctl</command>
    variables, enter
   </para>
<screen>&prompt.root;<command>sysctl</command> <option>-A</option> | <command>grep</command> <replaceable>"sched"</replaceable> | <command>grep</command> <option>-v</option><replaceable>"domain"</replaceable></screen>
<screen>&prompt.root;sysctl -A | grep "sched" | grep -v "domain"
kernel.sched_cfs_bandwidth_slice_us = 5000
kernel.sched_child_runs_first = 0
kernel.sched_compat_yield = 0
kernel.sched_latency_ns = 24000000
kernel.sched_migration_cost_ns = 500000
kernel.sched_min_granularity_ns = 8000000
kernel.sched_nr_migrate = 32
kernel.sched_rr_timeslice_ms = 25
kernel.sched_rt_period_us = 1000000
kernel.sched_rt_runtime_us = 950000
kernel.sched_schedstats = 0
kernel.sched_shares_window_ns = 10000000
kernel.sched_time_avg_ms = 1000
kernel.sched_tunable_scaling = 1
kernel.sched_wakeup_granularity_ns = 10000000</screen>
   <para>
    Note that variables ending with <quote>_ns</quote> and
    <quote>_us</quote> accept values in nanoseconds and microseconds,
    respectively.
   </para>
<!-- fs 2010-07-01: Commenting, since we give some more tuning advice below
   <para>
    According to Ingo Molnar, the author of CFS, there is only one important
    tuning option for CFS:
    <literal>kernel.sched_min_granularity_ns</literal>. It can be used to
    fine-tune the scheduler from low-latency response suitable for desktops,
    to server deployment giving more priority to batch tasks.
   </para>
-->
   <para>
    A list of the most important task scheduler <command>sysctl</command>
    tuning variables (located at <filename>/proc/sys/kernel/</filename>)
    with a short description follows:
   </para>
   <variablelist>
    <varlistentry>
     <term><systemitem>sched_cfs_bandwidth_slice_us</systemitem>
     </term>
     <listitem>
      <para>
       When CFS bandwidth control is in use, this parameter controls
       the amount of run-time (bandwidth) transferred to a run queue from the
       task's control group bandwidth pool. Small values allow the global
       bandwidth to be shared in a fine-grained manner among tasks, larger
       values reduce transfer overhead. See
       <link xlink:href="https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_child_runs_first</systemitem>
     </term>
     <listitem>
      <para>
       A freshly forked child runs before the parent continues execution.
       Setting this parameter to <literal>1</literal> is beneficial for an
       application in which the child performs an execution after fork. For
       example <command>make</command>
       <option>-j<replaceable>&lt;NO_CPUS&gt;</replaceable></option>
       performs better when sched_child_runs_first is turned off. The
       default value is <literal>0</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_compat_yield</systemitem>
     </term>
     <listitem>
      <para>
       Enables the aggressive CPU yielding behavior of the old
       <emphasis>O(1)</emphasis> scheduler by moving the relinquishing task to
       the end of the runnable queue (right-most position in the red-black
       tree). Applications that depend on the <option>sched_yield(2)</option>
       syscall behavior may see performance improvements by giving other
       processes a chance to run when there are highly contended resources
       (such as locks). On the other hand, given that this call occurs in
       context switching, misusing the call can hurt the workload. Only use it
       when you see a drop in performance. The default value is
       <literal>0</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_migration_cost_ns</systemitem>
     </term>
     <listitem>
      <para>
       Amount of time after the last execution that a task is considered to
       be <quote>cache hot</quote> in migration decisions. A
       <quote>hot</quote> task is less likely to be migrated to another CPU,
       so increasing this variable reduces task migrations. The default value is
       <literal>500000</literal> (ns).
      </para>
      <para>
       If the CPU idle time is higher than expected when there are runnable
       processes, try reducing this value. If tasks bounce between CPUs or
       nodes too often, try increasing it.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_latency_ns</systemitem>
     </term>
     <listitem>
      <para>
       Targeted preemption latency for CPU bound tasks. Increasing this
       variable increases a CPU bound task's timeslice. A task's timeslice
       is its weighted fair share of the scheduling period:
      </para>
      <para>
       timeslice = scheduling period * (task's weight/total weight of tasks
       in the run queue)
      </para>
      <para>
       The task's weight depends on the task's nice level and the scheduling
       policy. Minimum task weight for a SCHED_OTHER task is 15,
       corresponding to nice 19. The maximum task weight is 88761,
       corresponding to nice -20.
      </para>
      <para>
       Timeslices become smaller as the load increases. When the number of
       runnable tasks exceeds
       <systemitem>sched_latency_ns</systemitem>/<systemitem>sched_min_granularity_ns</systemitem>,
       the slice becomes number_of_running_tasks *
       <systemitem>sched_min_granularity_ns</systemitem>. Prior to that, the
       slice is equal to <systemitem>sched_latency_ns</systemitem>.
      </para>
      <para>
       This value also specifies the maximum amount of time during which a
       sleeping task is considered to be running for entitlement
       calculations. Increasing this variable increases the amount of time a
       waking task may consume before being preempted, thus increasing
       scheduler latency for CPU bound tasks. The default value is
       <literal>6000000</literal> (ns).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_min_granularity_ns</systemitem>
     </term>
     <listitem>
      <para>
       Minimal preemption granularity for CPU bound tasks. See
       <systemitem>sched_latency_ns</systemitem> for details. The default
       value is <literal>4000000</literal> (ns).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_wakeup_granularity_ns</systemitem>
     </term>
     <listitem>
      <para>
       The wake-up preemption granularity. Increasing this variable reduces
       wake-up preemption, reducing disturbance of compute bound tasks.
       Lowering it improves wake-up latency and throughput for latency
       critical tasks, particularly when a short duty cycle load component
       must compete with CPU bound components. The default value is
       <literal>2500000</literal> (ns).
      </para>
      <warning>
       <title>Setting the Right Wake-up Granularity Value</title>
       <para>
        Settings larger than half of
        <systemitem>sched_latency_ns</systemitem> will result in no wake-up
        preemption. Short duty cycle tasks will be unable to compete with
        CPU hogs effectively.
       </para>
      </warning>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_rr_timeslice_ms</systemitem>
     </term>
     <listitem>
      <para>
       Quantum that SCHED_RR tasks are allowed to run before they are
       preempted and put to the end of the task list.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_rt_period_us</systemitem>
     </term>
     <listitem>
      <para>
       Period over which real-time task bandwidth enforcement is measured.
       The default value is <literal>1000000</literal> (µs).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_rt_runtime_us</systemitem>
     </term>
     <listitem>
      <para>
       Quantum allocated to real-time tasks during sched_rt_period_us.
       Setting to -1 disables RT bandwidth enforcement. By default, RT tasks
       may consume 95%CPU/sec, thus leaving 5%CPU/sec or 0.05s to be used by
       SCHED_OTHER tasks. The default value is <literal>950000</literal>
       (µs).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_nr_migrate</systemitem>
     </term>
     <listitem>
      <para>
       Controls how many tasks can be migrated across processors for
       load-balancing purposes. Because balancing iterates the runqueue
       with interrupts disabled (softirq), it can incur in irq-latency
       penalties for real-time tasks.  Therefore increasing this value
       may give a performance boost to large SCHED_OTHER threads at the
       expense of increased irq-latencies for real-time tasks. The default
       value is <literal>32</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><systemitem>sched_time_avg_ms</systemitem>
     </term>
     <listitem>
      <para>
      This parameter sets the period over which the time spent running
      real-time tasks is averaged. That average assists CFS in making
      load-balancing decisions and gives an indication of how busy a CPU is
      with high-priority real-time tasks.
      </para>
      <para>
      The optimal setting for this parameter is highly workload
      dependent and depends, among other things, on how frequently
      real-time tasks are running and for how long.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

<!-- fs commenting, since the package schedtool is not available for
     any SUSE Linux/opensuse distribution
     but see FATE#310074 !!

  <sect2 id="sec-tuning-taskscheduler-cfs-tuning-other">
   <title>Other Tuning Options</title>
   <para>
    Long running, non-interactive tasks (that don't like preemption) and batch
    workloads may benefit from setting the scheduler policy to SCHED_BATCH.
    Changing the scheduling policy of the shell to SCHED_BATCH can be done by:
   </para>
<screen>~# schedtool -B $$
~# <replaceable>START_YOUR_PROGRAM</replaceable>
</screen>
   <para>
    After doing this, all programs being started in this shell will inherit
    using the SCHED_BATCH scheduling policy instead of SCHED_NORMAL.
   </para>
   <note>
    <para>
     You need to have the package <systemitem
      class="ressource">schedtool</systemitem> installed.
    </para>
   </note>
  </sect2>
-->

  <sect2 xml:id="sec-tuning-taskscheduler-cfs-debug">
   <title>Debugging Interface and Scheduler Statistics</title>
   <para>
    CFS comes with a new improved debugging interface, and provides runtime
    statistics information. Relevant files were added to the
    <filename>/proc</filename> file system, which can be examined simply
    with the <command>cat</command> or <command>less</command> command. A
    list of the related <filename>/proc</filename> files follows with their
    short description:
   </para>
   <variablelist>
    <varlistentry>
     <term><filename>/proc/sched_debug</filename>
     </term>
     <listitem>
      <para>
       Contains the current values of all tunable variables (see <xref
       linkend="sec-tuning-taskscheduler-cfs-tuning"/>) that affect the task
       scheduler behavior, CFS statistics, and information about the run queues
       (CFS, RT and deadline) on all available processors.  A summary of the
       task running on each processor is also shown, with the task name and
       PID, along with scheduler specific statistics. The first
       being <option>tree-key</option> column, it indicates the task's virtual
       runtime, and its name comes from the kernel sorting all runnable tasks
       by this key in a red-black tree. The <option>switches</option> column
       indicates the total number of switches (involuntary or not), and
       naturally the <option>prio</option> refers to the process priority. The
       <option>wait-time</option> value indicates the amount of time the task
       waited to be scheduled. Finally both <option>sum-exec</option> and
       <option>sum-sleep</option> account for the total amount of time (in
       nanoseconds) the task was running on the processor or asleep,
       respectively.
      </para>
<screen>&prompt.root;cat /proc/sched_debug
Sched Debug Version: v0.11, 4.4.21-64-default #1
ktime                                   : 23533900.395978
sched_clk                               : 23543587.726648
cpu_clk                                 : 23533900.396165
jiffies                                 : 4300775771
sched_clock_stable                      : 0

sysctl_sched
  .sysctl_sched_latency                    : 6.000000
  .sysctl_sched_min_granularity            : 2.000000
  .sysctl_sched_wakeup_granularity         : 2.500000
  .sysctl_sched_child_runs_first           : 0
  .sysctl_sched_features                   : 154871
  .sysctl_sched_tunable_scaling            : 1 (logaritmic)

cpu#0, 2666.762 MHz
  .nr_running                    : 1
  .load                          : 1024
  .nr_switches                   : 1918946
[...]

cfs_rq[0]:/
  .exec_clock                    : 170176.383770
  .MIN_vruntime                  : 0.000001
  .min_vruntime                  : 347375.854324
  .max_vruntime                  : 0.000001
[...]

rt_rq[0]:/
  .rt_nr_running                 : 0
  .rt_throttled                  : 0
  .rt_time                       : 0.000000
  .rt_runtime                    : 950.000000

dl_rq[0]:
  .dl_nr_running                 : 0

  task   PID         tree-key  switches  prio     wait-time        [...]
------------------------------------------------------------------------
R  cc1 63477     98876.717832       197   120      0.000000         ...</screen>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/proc/schedstat</filename>
     </term>
     <listitem>
      <para>
       Displays statistics relevant to the current run queue. Also
       domain-specific statistics for SMP systems are displayed for all
       connected processors. Because the output format is not user-friendly,
       read the contents of
       <filename>/usr/src/linux/Documentation/scheduler/sched-stats.txt</filename>
       for more information.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><filename>/proc/<replaceable>PID</replaceable>/sched</filename>
     </term>
     <listitem>
      <para>
       Displays scheduling information on the process with id
       <replaceable>PID</replaceable>.
      </para>
<screen>&prompt.root;cat /proc/$(pidof gdm)/sched
gdm (744, #threads: 3)
-------------------------------------------------------------------
se.exec_start                                :          8888.758381
se.vruntime                                  :          6062.853815
se.sum_exec_runtime                          :             7.836043
se.statistics.wait_start                     :             0.000000
se.statistics.sleep_start                    :          8888.758381
se.statistics.block_start                    :             0.000000
se.statistics.sleep_max                      :          1965.987638
[...]
se.avg.decay_count                           :                 8477
policy                                       :                    0
prio                                         :                  120
clock-delta                                  :                  128
mm-&gt;numa_scan_seq                            :                    0
numa_migrations, 0
numa_faults_memory, 0, 0, 1, 0, -1
numa_faults_memory, 1, 0, 0, 0, -1
</screen>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 xml:id="cha-tuning-taskscheduler-moreinfo">
  <title>For More Information</title>

  <para>
   To get a compact knowledge about Linux kernel task scheduling, you need
   to explore several information sources. Here are some:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     For task scheduler System Calls description, see the relevant manual
     page (for example <command>man 2 sched_setaffinity</command>).
    </para>
   </listitem>
   <listitem>
    <para>
     General information on scheduling is described in
     <link xlink:href="http://en.wikipedia.org/wiki/Scheduling_(computing)">Scheduling</link>
     wiki page.
    </para>
   </listitem>
<!--taroth 2014-08-29:  daps linkcheck reported following links as broken-->
<!--
   <listitem>
    <para>
     General information on Linux task scheduling is described in
     <ulink
   url="http://www.ibm.com/developerworks/linux/library/l-scheduler/">Inside
     the Linux scheduler</ulink>.
    </para>
   </listitem>
   <listitem>
    <para>
     Information specific to Completely Fair Scheduler is available in
     <ulink
   url="http://www.ibm.com/developerworks/linux/library/l-cfs/?ca=dgr-lnxw06CFC4Linux">Multiprocessing
     with the Completely Fair Scheduler</ulink>
    </para>
   </listitem>
   <listitem>
    <para>
     Information specific to tuning Completely Fair Scheduler is available
     in
     <ulink
   url="http://www.hotaboutlinux.com/2010/01/tuning-the-linux-kernels-completely-fair-scheduler/">Tuning
     the Linux Kernel’s Completely Fair Scheduler</ulink>
    </para>
   </listitem>
   -->
   <listitem>
    <para>
     A useful lecture on Linux scheduler policy and algorithm is available
     in
     <link xlink:href="http://www.inf.fu-berlin.de/lehre/SS01/OS/Lectures/Lecture08.pdf"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     A good overview of Linux process scheduling is given in
     <citetitle>Linux Kernel Development</citetitle> by Robert Love
     (ISBN-10: 0-672-32512-8). See
     <link xlink:href="http://www.informit.com/articles/article.aspx?p=101760"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     A very comprehensive overview of the Linux kernel internals is given in
     <citetitle>Understanding the Linux Kernel</citetitle> by Daniel P.
     Bovet and Marco Cesati (ISBN 978-0-596-00565-8).
    </para>
   </listitem>
   <listitem>
    <para>
     Technical information about task scheduler is covered in files under
     <filename>/usr/src/linux/Documentation/scheduler</filename>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>
