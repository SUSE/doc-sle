<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.xen.vhost">
 <title>Setting Up a Virtual Machine Host</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
  </dm:docmanager>
 </info>
 <para>
  This section documents how to set up and use &productname; &productnumber; as
  a virtual machine host.
 </para>
 <para>
  Usually, the hardware requirements for the &dom0; are the same as those for
  the &productname; operating system. Additional CPU, disk, memory, and network
  resources should be added to accommodate the resource demands of all planned
  &vmguest; systems.
 </para>
 <tip>
  <title>Resources</title>
  <para>
   Remember that &vmguest; systems, like physical machines, perform better when
   they run on faster processors and have access to more system memory.
  </para>
 </tip>
<!-- <para>
  &xen; virtualization technology is available in &productname; products based
  on code path 10 and later. Code path 10 products include Open Enterprise
  Server 2 Linux, &productname; 10, &sled; 10, and &opensuse; 10.x.
 </para> -->
 <para>
  The virtual machine host requires several software packages and their
  dependencies to be installed. To install all necessary packages, run &yast;
  <guimenu>Software Management</guimenu>, select
  <menuchoice><guimenu>View</guimenu> <guimenu>Patterns</guimenu></menuchoice>
  and choose <guimenu>&xen; Virtual Machine Host Server</guimenu> for
  installation. The installation can also be performed with &yast; using the
  module <menuchoice><guimenu>Virtualization</guimenu><guimenu>Install
  Hypervisor and Tools</guimenu></menuchoice>.
 </para>
 <para>
  After the &xen; software is installed, restart the computer and, on the boot
  screen, choose the newly added option with the &xen; kernel.
 </para>
 <para>
  Updates are available through your update channel. To be sure to have the
  latest updates installed, run &yast; <guimenu>Online Update</guimenu> after
  the installation has finished.
 </para>
 <sect1 xml:id="sec.xen.vhost.best">
  <title>Best Practices and Suggestions</title>

  <para>
   When installing and configuring the &productname; operating system on the
   host, be aware of the following best practices and suggestions:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     If the host should always run as &xen; host, run &yast; <menuchoice>
     <guimenu>System</guimenu> <guimenu>Boot Loader</guimenu> </menuchoice> and
     activate the &xen; boot entry as default boot section.
    </para>
    <itemizedlist mark="bullet" spacing="normal">
     <listitem>
      <para>
       In &yast;, click <guimenu>System &gt; Boot Loader</guimenu>.
      </para>
     </listitem>
     <listitem>
      <para>
       Change the default boot to the <guimenu>&xen;</guimenu> label, then
       click <guimenu>Set as Default</guimenu>.
      </para>
     </listitem>
     <listitem>
      <para>
       Click <guimenu>Finish</guimenu>.
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     For best performance, only the applications and processes required for
     virtualization should be installed on the virtual machine host.
    </para>
   </listitem>
   <listitem>
    <para>
     When using both iSCSI and OCFS2 to host &xen; images, the latency required
     for OCFS2 default timeouts in &productname; may not be met. To reconfigure
     this timeout, run <command>systemctl configure o2cb</command> or edit
     <literal>O2CB_HEARTBEAT_THRESHOLD</literal> in the system configuration.
    </para>
   </listitem>
   <listitem>
    <para>
     If you intend to use a watchdog device attached to the &xen; host, use
     only one at a time. It is recommended to use a driver with actual hardware
     integration over a generic software one.
    </para>
   </listitem>
  </itemizedlist>

  <note>
<!-- Bugzilla #878036 -->
   <title>Hardware Monitoring</title>
   <para>
    The &dom0; kernel is running virtualized, so tools like
    <command>irqbalance</command> or <command>lscpu</command> will not reflect
    the real hardware characteristics.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="sec.xen.vhost.memory">
  <title>Managing &dom0; Memory</title>

  <para>
   In a default &xen; installation, a small percentage of system memory is
   reserved for the hypervisor, and all remaining memory is automatically
   allocated to &dom0;. When virtual machines are created, memory is ballooned
   out of &dom0; to provide memory for the virtual machine. This process is
   called "autoballooning".
  </para>

  <para>
   SUSE recommends disabling autoballooning and configuring &dom0; with
   adequate memory. Generally 10 percent of the total system memory is
   sufficient, with a minimum of 1 GiB and a maximum of 64 GiB.
  </para>

  <warning>
   <title>Insufficient Memory for &dom0;</title>
   <para>
    The amount of memory reserved for &dom0; is a function of the number of
    &vmguest;s running on the host since &dom0; provides back-end network and
    disk I/O services for each &vmguest;. Other workloads running in &dom0;
    should also be considered when calculating &dom0; memory allocation. In
    general, memory sizing of &dom0; should be determined like any other
    virtual machine.
   </para>
  </warning>

  <sect2 xml:id="sec.xen.vhost.maxmem">
   <title>Setting &dom0; Memory Allocation</title>
   <procedure>
    <step>
     <para>
      Determine memory allocation required for &dom0;.
     </para>
    </step>
    <step>
     <para>
      At &dom0;, type <command>xl info</command> to view the amount of memory
      that is available on the machine. &dom0;'s current memory allocation can
      be determined with the <command>xl list</command> command.
     </para>
    </step>
    <step>
     <para>
      Run <menuchoice> <guimenu>&yast;</guimenu> <guimenu>Boot Loader</guimenu>
      </menuchoice>.
     </para>
    </step>
    <step>
     <para>
      Select the &xen; section.
     </para>
    </step>
    <step>
     <para>
      In <guimenu>Additional &xen; Hypervisor Parameters</guimenu>, add
      <command>dom0_mem=<replaceable>MEM_AMOUNT</replaceable></command> where
      <replaceable>MEM_AMOUNT</replaceable> is the maximum amount of memory to
      allocate to &dom0;. Add <command>K</command>, <command>M</command>, or
      <command>G</command>, to specify the size, for example,
      <command>dom0_mem=2G</command>.
     </para>
    </step>
    <step>
     <para>
      Restart the computer to apply the changes.
     </para>
    </step>
   </procedure>
   <warning>
    <title>&xen; &dom0; Memory</title>
    <para>
     When using the XL tool stack and the <command>dom0_mem=</command> option
     for the &xen; hypervisor in &grub; you need to disable xl
     <emphasis>autoballoon</emphasis> in <filename>etc/xen/xl.conf</filename>.
     Otherwise launching VMs will fail with errors about not being able to
     balloon down &dom0;. So add <emphasis>autoballoon=0</emphasis> to
     <filename>xl.conf</filename> if you have the <command>dom0_mem=</command>
     option specified for &xen;. Also see
     <link xlink:href="http://wiki.xen.org/wiki/Xen_Best_Practices#Xen_dom0_dedicated_memory_and_preventing_dom0_memory_ballooning">Xen
     dom0 memory</link>
    </para>
   </warning>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.xen.vhost.netcard">
  <title>Network Card in Fully Virtualized Guests</title>

  <para>
   In a fully virtualized guest, the default network card is an emulated
   Realtek network card. However, it also possible to use the split network
   driver to run the communication between &dom0; and a &vmguest;. By default,
   both interfaces are presented to the &vmguest;, because the drivers of some
   operating systems require both to be present.
  </para>

  <para>
   When using &productname;, only the paravirtualized network cards are
   available for the &vmguest; by default. The following network options are
   available:
  </para>

  <variablelist>
   <varlistentry>
    <term>emulated</term>
    <listitem>
     <para>
      To use an emulated network interface like an emulated Realtek card,
      specify <literal>type=ioemu</literal> in the <literal>vif</literal>
      device section of the domain xl configuration. An example configuration
      would look like:
     </para>
<screen>vif = [ 'type=ioemu,mac=00:16:3e:5f:48:e4,bridge=br0' ]</screen>
     <para>
      Find more details about the xl configuration in the
      <filename>xl.conf</filename> manual page <command>man 5
      xl.conf</command>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>paravirtualized</term>
    <listitem>
     <para>
      When you specify <literal>type=vif</literal> and do not specify a model
      or type, the paravirtualized network interface is used:
     </para>
<screen>vif = [ 'type=vif,mac=00:16:3e:5f:48:e4,bridge=br0,backen=0' ]</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>emulated and paravirtualized</term>
    <listitem>
     <para>
      If the administrator should be offered both options, simply specify both
      type and model. The xl configuration would look like:
     </para>
<screen>vif = [ 'type=ioemu,mac=00:16:3e:5f:48:e4,model=rtl8139,bridge=br0' ]</screen>
     <para>
      In this case, one of the network interfaces should be disabled on the
      &vmguest;.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.xen.vhost.start">
  <title>Starting the Virtual Machine Host</title>

  <para>
   If virtualization software is correctly installed, the computer boots to
   display the &grub; boot loader with a <guimenu>&xen;</guimenu> option on the
   menu. Select this option to start the virtual machine host.
  </para>

  <note>
   <title>Xen and Kdump</title>
   <para>
    In &xen;, the hypervisor manages the memory resource. If you need to
    reserve system memory for a recovery kernel in &dom0;, this memory need to
    be reserved by the hypervisor. Thus, it is necessary to add the parameter
    <systemitem>crashkernel=size</systemitem> to the <literal>kernel</literal>
    line instead of using the line with the other boot parameters.
   </para>
   <para>
    For more information on the crashkernel parameter, see
    <xref linkend="sec.tuning.kexec.crashkernel"/>.
   </para>
  </note>

  <para>
   If the <guimenu>&xen;</guimenu> option is not on the &grub; menu, review the
   steps for installation and verify that the &grub; boot loader has been
   updated. If the installation has been done without selecting the &xen;
   pattern, run the &yast; <guimenu>Software Management</guimenu>, select the
   filter <guimenu>Patterns</guimenu> and choose <guimenu>&xen; Virtual Machine
   Host Server</guimenu> for installation.
  </para>

  <para>
   After booting the hypervisor, the &dom0; virtual machine starts and displays
   its graphical desktop environment. If you did not install a graphical
   desktop, the command line environment appears.
  </para>

  <tip>
   <title>Graphics Problems</title>
   <para>
    Sometimes it may happen that the graphics system does not work properly. In
    this case, add <literal>vga=ask</literal> to the boot parameters. To
    activate permanent settings, use <literal>vga=mode-0x???</literal> where
    <literal>???</literal> is calculated as <literal>0x100</literal> + VESA
    mode from
    <link xlink:href="http://en.wikipedia.org/wiki/VESA_BIOS_Extensions"/>, for
    example <literal>vga=mode-0x361</literal>.
   </para>
  </tip>

  <para>
   Before starting to install virtual guests, make sure that the system time is
   correct. To do this, configure NTP (Network Time Protocol) on the
   controlling domain:
  </para>

  <procedure>
   <step>
    <para>
     In &yast; select <menuchoice> <guimenu>Network Services</guimenu>
     <guimenu>NTP Configuration</guimenu> </menuchoice>.
    </para>
   </step>
   <step>
    <para>
     Select the option to automatically start the NTP daemon during boot.
     Provide the IP address of an existing NTP time server, then click
     <guimenu>Finish</guimenu>.
    </para>
   </step>
  </procedure>

  <note>
   <title>Time Services on Virtual Guests</title>
   <para>
    Hardware clocks commonly are not very precise. All modern operating systems
    try to correct the system time compared to the hardware time by means of an
    additional time source. To get the correct time on all &vmguest; systems,
    also activate the network time services on each respective guest or make
    sure that the guest uses the system time of the host. For more about
    <literal>Independent Wallclocks</literal> in &productname; see
    <xref linkend="sec.xen.guests.suse.time"/>.
   </para>
  </note>

  <para>
   For more information about managing virtual machines, see
   <xref linkend="cha.xen.manage"/>.
  </para>
 </sect1>
 <sect1 xml:id="sec.xen.vhost.pciback">
  <title>&pciback;</title>

  <para>
   To take full advantage of &vmguest; systems, it is sometimes necessary to
   assign specific PCI devices to a dedicated domain. When using fully
   virtualized guests, this functionality is only available if the chipset of
   the system supports this feature, and if it is activated from the BIOS.
  </para>

  <para>
   This feature is available from both AMD* and Intel*. For AMD machines, the
   feature is called <xref linkend="gloss.vt.acronym.iommu"/>; in Intel speak,
   this is <xref linkend="gloss.vt.acronym.vtd"/>. Note that Intel-VT
   technology is not sufficient to use this feature for fully virtualized
   guests. To make sure that your computer supports this feature, ask your
   supplier specifically to deliver a system that supports &pciback;.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <title>Limitations</title>
   <listitem>
    <para>
     Some graphics drivers use highly optimized ways to access DMA. This is not
     supported, and thus using graphics cards may be difficult.
    </para>
   </listitem>
   <listitem>
    <para>
     When accessing PCI devices behind a
     <xref linkend="gloss.vt.acronym.pcie"/> bridge, all of the PCI devices
     must be assigned to a single guest. This limitation does not apply to
     <xref linkend="gloss.vt.acronym.pcie"/> devices.
    </para>
   </listitem>
   <listitem>
    <para>
     Guests with dedicated PCI devices cannot be migrated live to a different
     host.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   The configuration of &pciback; is twofold. First, the hypervisor must be
   informed at boot time that a PCI device should be available for reassigning.
   Second, the PCI device must be assigned to the &vmguest;.
  </para>

  <sect2 xml:id="config.hypervisor.pciback">
   <title>Configuring the Hypervisor for &pciback;</title>
   <procedure>
    <step>
     <para>
      Select a device to reassign to a &vmguest;. To do this, run
      <command>lspci -k</command>, and read the device number and the name of
      the original module that is assigned to the device:
     </para>
<screen>06:01.0 Ethernet controller: Intel Corporation Ethernet Connection I217-LM (rev 05)
        Subsystem: Dell Device 0617
        Kernel driver in use: e1000e
        Kernel modules: e1000e</screen>
     <para>
      In this case, the PCI number is <literal>(06:01.0)</literal> and the
      dependent kernel module is <literal>e1000e</literal>.
     </para>
    </step>
    <step>
     <para>
      Specify a module dependency to ensure that
      <systemitem>xen_pciback</systemitem> is the first module to control the
      device. Add the file named
      <filename>/etc/modprobe.d/50-e1000e.conf</filename> with the following
      content:
     </para>
<screen>install e1000e /sbin/modprobe xen_pciback ; /sbin/modprobe \
 --first-time --ignore-install e1000e</screen>
    </step>
    <step>
     <para>
      Instruct the <systemitem>xen_pciback</systemitem> module to control the
      device using the 'hide' option. Edit or create
      <filename>/etc/modprobe.d/50-xen-pciback.conf</filename> with the
      following content:
     </para>
<screen>options xen_pciback hide=(06:01.0)</screen>
    </step>
    <step>
     <para>
      Reboot the system.
     </para>
    </step>
    <step>
     <para>
      Check if the device is in the list of assignable devices with the command
     </para>
<screen>xl pci-assignable-list</screen>
    </step>
   </procedure>
   <sect3 xml:id="config.hypervisor.pciback.xl">
    <title>Dynamic Assignment with xl</title>
    <para>
     To avoid restarting the host system, you can use dynamic assignment with
     xl to use &pciback;.
    </para>
    <para>
     Begin by making sure that dom0 has the pciback module loaded:
    </para>
<screen>&prompt.sudo;modprobe pciback</screen>
    <para>
     Then make a device assignable by using <command>xl
     pci-assignable-add</command>. For example, to make the device
     <emphasis>06:01.0</emphasis> available for guests, run the command:
    </para>
<screen>&prompt.sudo;xl pci-assignable-add 06:01.0</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="config.hypervisor.pciback.guests">
   <title>Assigning PCI Devices to &vmguest; Systems</title>
   <para>
    There are several possibilities to dedicate a PCI device to a &vmguest;:
   </para>
   <variablelist>
    <varlistentry>
     <term>Adding the device while installing:</term>
     <listitem>
      <para>
       During installation, add the <literal>pci</literal> line to the
       configuration file:
      </para>
<screen>pci=['06:01.0']</screen>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Hotplugging PCI devices to &vmguest; systems</term>
     <listitem>
      <para>
       The command <literal>xl</literal> can be used to add or remove PCI
       devices on the fly. To add the device with number
       <literal>06:01.0</literal> to a guest with name
       <literal>sles12</literal> use:
      </para>
<screen>xl pci-attach sles12 06:01.0</screen>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Adding the PCI device to Xend</term>
     <listitem>
      <para>
       To add the device to the guest permanently, add the following snippet to
       the guest configuration file:
      </para>
<screen>pci = [ '06:01.0,power_mgmt=1,permissive=1' ]</screen>
     </listitem>
    </varlistentry>
   </variablelist>
   <para>
    After assigning the PCI device to the &vmguest;, the guest system must care
    for the configuration and device drivers for this device.
   </para>
  </sect2>

  <sect2 xml:id="config.hypervisor.vgaback">
   <title>&vgaback;</title>
   <para>
    &xen; 4.0 and newer supports VGA graphics adapter pass-through on fully
    virtualized &vmguest;s. The guest can take full control of the graphics
    adapter with high-performance full 3D and video acceleration.
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <title>Limitations</title>
    <listitem>
     <para>
      &vgaback; functionality is similar to &pciback; and as such also requires
      <xref linkend="gloss.vt.acronym.iommu"/> (or Intel VT-d) support from the
      mainboard chipset and BIOS.
     </para>
    </listitem>
    <listitem>
     <para>
      Only the primary graphics adapter (the one that is used when you power on
      the computer) can be used with &vgaback;.
     </para>
    </listitem>
    <listitem>
     <para>
      &vgaback; is supported only for fully virtualized guests. Paravirtual
      guests (PV) are not supported.
     </para>
    </listitem>
    <listitem>
     <para>
      The graphics card cannot be shared between multiple &vmguest;s using
      &vgaback; &mdash; you can dedicate it to one guest only.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    To enable &vgaback;, add the following settings to your fully virtualized
    guest configuration file:
   </para>
<screen>gfx_passthru=1
pci=['yy:zz.n']</screen>
   <para>
    where <literal>yy:zz.n</literal> is the PCI controller ID of the VGA
    graphics adapter as found with <command>lspci -v</command> on &dom0;.
   </para>
  </sect2>

  <sect2 xml:id="sec.xen.vm.known">
   <title>Troubleshooting</title>
   <para>
    In some circumstances, problems may occur during the installation of the
    &vmguest;. This section describes some known problems and their solutions.
   </para>
   <variablelist>
    <varlistentry>
     <term>During boot, the system hangs</term>
     <listitem>
      <para>
       The software I/O translation buffer allocates a large chunk of low
       memory early in the bootstrap process. If the requests for memory exceed
       the size of the buffer it usually results in a hung boot process. To
       check if this is the case, switch to console 10 and check the output
       there for a message similar to
      </para>
<screen>kernel: PCI-DMA: Out of SW-IOMMU space for 32768 bytes at device 000:01:02.0</screen>
      <para>
       In this case you need to increase the size of the
       <literal>swiotlb</literal>. Add <literal>swiotlb=<replaceable>VALUE</replaceable></literal>
       (where <replaceable>VALUE</replaceable> is specified as number of slab entries) on the
       cmdline of &dom0;. Note that the number can be adjusted up or down to
       find the optimal size for the machine.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <note>
    <title>swiotlb a PV guest</title>
    <para>
     The <literal>swiotlb=force</literal> kernel parameter is required for DMA
     access to work for PCI devices on a PV guest. For more information about
     IOMMU and the <literal>swiotlb</literal> option see the file
     <filename>boot-options.txt</filename> from the package
     <systemitem>kernel-source</systemitem>.
    </para>
   </note>
  </sect2>

  <sect2 xml:id="sec.xen.vm.info">
   <title>For More Information</title>
   <para>
    There are several resources on the Internet that provide interesting
    information about &pciback;:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      <link xlink:href="http://wiki.xensource.com/xenwiki/VTdHowTo"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="http://software.intel.com/en-us/articles/intel-virtualization-technology-for-directed-io-vt-d-enhancing-intel-platforms-for-efficient-virtualization-of-io-devices/"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="http://support.amd.com/TechDocs/48882_IOMMU.pdf"/>
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.xen.vhost.usbpass">
  <title>USB Pass-Through</title>

  <para>
   There are two methods for passing through individual host USB devices to a
   guest. The first is via an emulated USB device controller, the second is
   using PVUSB.
  </para>

  <sect2 xml:id="xen.usb.identify">
   <title>Identify the USB Device</title>
   <para>
    Before you can pass through a USB device to the &vmguest;, you need to
    identify it on the &vmhost;. Use the <command>lsusb</command> command to
    list the USB devices on the host system:
   </para>
<screen>&prompt.root;lsusb
Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
Bus 002 Device 003: ID 0461:4d15 Primax Electronics, Ltd Dell Optical Mouse
Bus 002 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub</screen>
   <para>
    To pass through the Dell mouse, for example, specify either the device tag
    in the form <literal>vendor_id:device_id</literal> (0461:4d15) or the bus
    address in the form <literal>bus.device</literal> (2.3). Remember to remove
    leading zeros, otherwise <command>xl</command> would interpret the numbers
    as octal values.
   </para>
  </sect2>

  <sect2 xml:id="xen.usb.emulated">
   <title>Emulated USB Device</title>
   <para>
    In emulated USB, the device model (&qemu;) presents an emulated USB
    controller to the guest. The USB device is then controlled from &dom0;
    while USB commands are translated between the &vmguest; and the host USB
    device. This method is only available to fully virtualized domains (HVM).
   </para>
   <para>
    Enable the emulated USB hub with the <option>usb=1</option> option. Then
    specify devices among the list of devices in the config file along with
    other emulated devices by using <literal>host:USBID</literal>. For example:
   </para>
<screen>
usb=1
usbdevice=['tablet','host:2.3','host:0424:460']
</screen>
  </sect2>

  <sect2 xml:id="xen.usb.pv">
   <title>Paravirtualized PVUSB</title>
   <para>
    PVUSB is a new high performance method for USB Pass-Through from dom0 to
    the virtualized guests. With PVUSB, there are two ways to add USB devices
    to a guest:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      via the configuration file at domain creation time
     </para>
    </listitem>
    <listitem>
     <para>
      via hotplug while the VM is running
     </para>
    </listitem>
   </itemizedlist>
   <para>
    PVUSB uses paravirtualized front- and back-end interfaces. PVUSB supports
    USB 1.1 and USB 2.0, and it works for both PV and HVM guests. To use PVUSB,
    you need usbfront in your guest OS, and usbback in dom0 or usb back-end in
    qemu. On &productname;, the USB back-end comes with qemu.
<!--
       Additionally, for easy use of PVUSB, you need support in the
       toolstack to get the two sides to talk to each
       other.
       <!-\-(Alternately, you can write a script to talk over xenstore
       to the front and backends manually; see the section below for
       more information.)
       -\->
   -->
   </para>
   <para>
    As of Xen 4.7, <command>xl</command> PVUSB support and hotplug support is
    introduced.
   </para>
   <para>
    In the configuration file, specify USB controllers and USB host devices
    with <literal>usbctrl</literal> and <literal>usbdev</literal>. For example,
    in case of HVM guests:
   </para>
<screen>usbctrl=['type=qusb,version=2,ports=4', 'type=qusb,version=1,ports=4', ]
usbdev=['hostbus=2, hostaddr=1, controller=0,port=1', ]</screen>
   <note>
    <para>
     It is important to specify <literal>type=qusb</literal> for the controller
     of HVM guests.
    </para>
   </note>
   <para>
    To manage hotpluggin PVUSB devices, use the
    <literal>usbctrl-attach</literal>, <literal>usbctrl-detach</literal>,
    <literal>usb-list</literal>, <literal>usbdev-attach</literal> and
    <literal>usb-detach</literal> subcommands. For example:
   </para>
   <para>
    Create a USB controller which is version USB 1.1 and has 8 ports:
   </para>
<screen>&prompt.root;xl usbctrl-attach test_vm version=1 ports=8 type=qusb</screen>
   <para>
    Find the first available controller:port in the domain, and attach USB
    device whose busnum:devnum is 2:3 to it; you can also specify
    <literal>controller</literal> and <literal>port</literal>:
   </para>
<screen>&prompt.root;xl usbdev-attach test_vm hostbus=2 hostaddr=3</screen>
   <para>
    Show all USB controllers and USB devices in the domain:
   </para>
<screen>&prompt.root;xl usb-list test_vm
Devid  Type   BE  state usb-ver ports
0      qusb   0   1     1       8
  Port 1: Bus 002 Device 003
  Port 2:
  Port 3:
  Port 4:
  Port 5:
  Port 6:
  Port 7:
  Port 8:</screen>
   <para>
    Detach the USB device under controller 0 port 1:
   </para>
<screen>&prompt.root;xl usbdev-detach test_vm 0 1</screen>
   <para>
    Remove the USB controller with the indicated <literal>dev_id</literal>, and
    all USB devices under it:
   </para>
<screen>&prompt.root;xl usbctrl-detach test_vm dev_id</screen>
   <para>
    For more information, see
    <link
 xlink:href="https://wiki.xenproject.org/wiki/Xen_USB_Passthrough"/>.
   </para>
  </sect2>
 </sect1>
</chapter>
