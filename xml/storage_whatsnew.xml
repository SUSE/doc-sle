<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="storwhatsnew" xml:lang="en">
 <title>What’s New for Storage in SLES 11</title>
 <info/>
 <para>
  The features and behavior changes noted in this section were made for
  &productname; 11.
 </para>
 <itemizedlist role="subtoc" mark="bullet" spacing="normal">
  <listitem>
   <para>
    <xref linkend="new_sles11sp3" xrefstyle="SectTitleOnPage"/>
   </para>
  </listitem>
  <listitem>
   <para>
    <xref linkend="bwkb7my" xrefstyle="SectTitleOnPage"/>
   </para>
  </listitem>
  <listitem>
   <para>
    <xref linkend="bndgyod" xrefstyle="SectTitleOnPage"/>
   </para>
  </listitem>
  <listitem>
   <para>
    <xref linkend="bndgyoe" xrefstyle="SectTitleOnPage"/>
   </para>
  </listitem>
 </itemizedlist>
 <sect1 xml:id="new_sles11sp3">
  <title>What’s New in SLES 11 SP3</title>

  <para>
   In addition to bug fixes, the features and behavior changes in this
   section were made for the &productname; 11 SP3 release:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <xref linkend="b15ds08f" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="b15ds08d" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="b15ds08c" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="b15ds08g" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="b15ds08e" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="b15ds08f">
   <title>Btrfs Quotas</title>
   <para>
    Btrfs quota support for subvolumes on the &rootuser; file system has
    been added in the <command>btrfs(8)</command> command.
   </para>
  </sect2>

  <sect2 xml:id="b15ds08d">
   <title>iSCSI LIO Target Server</title>
   <para>
    &yast; supports the iSCSI LIO Target Server software. For
    information, see
    <xref linkend="cha_iscsi_lio" xrefstyle="ChapTitleOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="b15ds08c">
   <title>Linux Software RAIDs</title>
   <para>
    The following enhancements were added for Linux software RAIDs:
   </para>
   <itemizedlist role="subtoc" mark="bullet" spacing="normal">
    <listitem>
     <para>
      <xref linkend="b15jy5sx" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="b15jy5sy" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="b15jy5sz" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
   </itemizedlist>
   <sect3 xml:id="b15jy5sx">
    <title>Support for Intel RSTe+</title>
    <para>
     The software RAID provides improved support on the Intel RSTe+ (Rapid
     Storage Technology Enterprise) platform to support RAID level 0, 1, 4,
     5, 6, and 10.
    </para>
   </sect3>
   <sect3 xml:id="b15jy5sy">
    <title>LEDMON Utility</title>
    <para>
     The LEDMON utility supports PCIe-SSD enclosure LEDs for MD software
     RAIDs. For information, see
     <xref linkend="cha_raids_lee" xrefstyle="ChapTitleOnPage"/>.
    </para>
   </sect3>
   <sect3 xml:id="b15jy5sz">
    <title>Device Order in the Software RAID</title>
    <para>
     In the <guimenu>Add RAID</guimenu> wizard in the &yast; Partitioner,
     the <guimenu>Classify</guimenu> option allows you to specify the order
     in which the selected devices in a Linux software RAID will be used to
     ensure that one half of the array resides on one disk subsystem and the
     other half of the array resides on a different disk subsystem. For
     example, if one disk subsystem fails, the system keeps running from the
     second disk subsystem. For information, see
     <xref linkend="b14dtk77" xrefstyle="StepXRef"/> in
     <xref linkend="b14drcbo" xrefstyle="SectTitleOnPage"/>.
    </para>
   </sect3>
  </sect2>

  <sect2 xml:id="b15ds08g">
   <title>LVM2</title>
   <para>
    The following enhancements were added for LVM2:
   </para>
   <itemizedlist role="subtoc" mark="bullet" spacing="normal">
    <listitem>
     <para>
      <xref linkend="b15jy33d" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="b15jy33e" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
   </itemizedlist>
   <sect3 xml:id="b15jy33d">
    <title>Thin Pool and Thin Volumes</title>
    <para>
     LVM logical volumes can be thinly provisioned. For information, see
     <xref linkend="bgchx8c" xrefstyle="SectTitleOnPage"/>.
    </para>
    <itemizedlist mark="bullet" spacing="normal">
     <listitem>
      <formalpara xml:id="b15jy6mq">
       <title>Thin pool:</title>
       <para>
        The logical volume is a pool of space that is reserved for use with
        thin volumes. The thin volumes can allocate their needed space from
        it on demand.
       </para>
      </formalpara>
     </listitem>
     <listitem>
      <formalpara xml:id="b15jy6mr">
       <title>Thin volume:</title>
       <para>
        The volume is created as a sparse volume. The volume allocates
        needed space on demand from a thin pool.
       </para>
      </formalpara>
     </listitem>
    </itemizedlist>
   </sect3>
   <sect3 xml:id="b15jy33e">
    <title>Thin Snapshots</title>
    <para>
     LVM logical volume snapshots can be thinly provisioned. Thin
     provisioning is assumed if you to create a snapshot without a specified
     size. For information, see
     <xref linkend="bi7uttc" xrefstyle="SectTitleOnPage"/>.
    </para>
   </sect3>
  </sect2>

  <sect2 xml:id="b15ds08e">
   <title>Multipath I/O</title>
   <para>
    The following changes and enhancements were made for multipath I/O:
   </para>
   <itemizedlist role="subtoc" mark="bullet" spacing="normal">
    <listitem>
     <para>
      <xref linkend="b15jxva2" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="b15jxva1" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="b15jxva0" xrefstyle="HeadingOnPage"/>
     </para>
    </listitem>
   </itemizedlist>
   <sect3 xml:id="b15jxva2">
    <title>mpathpersist(8)</title>
    <para>
     The <command>mpathpersist(8)</command> utility is new. It can be used
     to manage SCSI persistent reservations on Device Mapper Multipath
     devices. For information, see
     <xref linkend="b15jw320" xrefstyle="SectTitleOnPage"/>.
    </para>
   </sect3>
   <sect3 xml:id="b15jxva1">
    <title>multipath(8)</title>
    <para>
     The following enhancement was added to the
     <command>multipath(8)</command> command:
    </para>
    <itemizedlist mark="bullet" spacing="normal">
     <listitem>
      <para>
       The <literal>-r</literal> option allows you to force a device map
       reload.
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
   <sect3 xml:id="b15jxva0">
    <title>/etc/multipath.conf</title>
    <para>
     The Device Mapper - Multipath tool added the following enhancements for
     the <filename>/etc/multipath.conf</filename> file:
    </para>
    <itemizedlist mark="bullet" spacing="normal">
     <listitem>
      <formalpara xml:id="b15jxy6m" role="intro">
       <title>udev_dir</title>
       <para/>
      </formalpara>
      <para>
       The <literal>udev_dir</literal> attribute is deprecated. After you
       upgrade to SLES 11 SP3, you can remove the following line from the
       <literal>defaults</literal> section of your
       <filename>/etc/multipath.conf</filename> file:
      </para>
<screen>
udev_dir /dev
</screen>
     </listitem>
     <listitem>
      <formalpara xml:id="b15jxy6n" role="intro">
       <title>getuid_callout</title>
       <para/>
      </formalpara>
      <para>
       In the <literal>defaults</literal> section of the
       <filename>/etc/multipath.conf</filename> file, the
       <literal>getuid_callout </literal>attribute is deprecated and
       replaced by the <literal>uid_attribute</literal> parameter. This
       parameter is a udev attribute that provides a unique path identifier.
       The default value is <literal>ID_SERIAL</literal>.
      </para>
      <para>
       After you upgrade to SLES 11 SP3, you can modify the attributes in
       the <literal>defaults</literal> section of your
       <filename>/etc/multipath.conf</filename> file:
      </para>
      <itemizedlist mark="bullet" spacing="normal">
       <listitem>
        <para>
         Remove the following line from the <literal>defaults</literal>
         section:
        </para>
<screen>
  getuid_callout "/lib/udev/scsi_id --whitelisted --device=/dev/%n"
</screen>
       </listitem>
       <listitem>
        <para>
         Add the following line to the <literal>defaults</literal> section:
        </para>
<screen>
  uid_attribute "ID_SERIAL"
</screen>
       </listitem>
      </itemizedlist>
     </listitem>
     <listitem>
      <formalpara xml:id="b15jxy6o" role="intro">
       <title>path_selector</title>
       <para/>
      </formalpara>
      <para>
       In the <literal>defaults</literal> section of the
       <filename>/etc/multipath.conf</filename> file, the default value for
       the <literal>path_selector </literal>attribute was changed from
       <literal>"round-robin 0"</literal> to <literal>"service-time
       0"</literal>. The <literal>service-time</literal> option chooses the
       path for the next bunch of I/O based on the amount of outstanding I/O
       to the path and its relative throughput.
      </para>
      <para>
       After you upgrade to SLES 11 SP3, you can modify the attribute value
       in the <literal>defaults</literal> section of your
       <filename>/etc/multipath.conf</filename> file to use the recommended
       default:
      </para>
<screen>
  path_selector "service-time 0"
</screen>
     </listitem>
     <listitem>
      <formalpara xml:id="b15jxy6p" role="intro">
       <title>user_friendly_names</title>
       <para/>
      </formalpara>
      <para>
       The <literal>user_friendly_names</literal> attribute can be
       configured in the <literal>devices</literal> section and in the
       <literal>multipaths</literal> section.
      </para>
     </listitem>
     <listitem>
      <formalpara xml:id="b15jxy6q" role="intro">
       <title>max_fds</title>
       <para/>
      </formalpara>
      <para role="intro">
       The default setting for the <literal>max_fds</literal> attribute was
       changed to <literal>max</literal>. This allows the multipath daemon
       to open as many file descriptors as the system allows when it is
       monitoring paths.
      </para>
      <para role="intro">
       After you upgrade to SLES 11 SP3, you can modify the attribute value
       in your <filename>/etc/multipath.conf</filename> file:
      </para>
<screen>
max_fds "max"
</screen>
     </listitem>
     <listitem>
      <formalpara xml:id="b15jxy6r" role="intro">
       <title>reservation_key</title>
       <para/>
      </formalpara>
      <para role="intro">
       In the <literal>defaults</literal> section or
       <literal>multipaths</literal> section of the
       <filename>/etc/multipath.conf</filename> file, the
       <literal>reservation_key</literal> attribute can be used to assign a
       Service Action Reservation Key that is used with the
       <command>mpathpersist(8)</command> utility to manage persistent
       reservations for Device Mapper Multipath devices. The attribute is
       not used by default. If it is not set, the
       <command>multipathd</command> daemon does not check for persistent
       reservation for newly discovered paths or reinstated paths.
      </para>
<screen>
reservation_key &lt;<replaceable>reservation key</replaceable>&gt;
</screen>
      <para>
       For example:
      </para>
<screen>
multipaths {
        multipath {
                          wwid   XXXXXXXXXXXXXXXX
                         alias      yellow
                         reservation_key  0x123abc
      }
}
</screen>
      <para>
       For information about setting persistent reservations, see
       <xref linkend="b15jw320" xrefstyle="SectTitleOnPage"/>.
      </para>
     </listitem>
     <listitem>
      <formalpara xml:id="b15jxy6s" role="intro">
       <title>hardware_handler</title>
       <para/>
      </formalpara>
      <para>
       Four SCSI hardware handlers were added in the SCSI layer that can be
       used with DM-Multipath:
      </para>
      <simplelist>
       <member><filename>scsi_dh_alua</filename>
       </member>
       <member><filename>scsi_dh_rdac</filename>
       </member>
       <member><literal>scsi_dh_hp_sw</literal>
       </member>
       <member><literal>scsi_dh_emc</literal>
       </member>
      </simplelist>
      <para>
       These handlers are modules created under the SCSI directory in the
       Linux kernel. Previously, the hardware handler in the Device Mapper
       layer was used.
      </para>
      <para>
       Add the modules to the <filename>initrd</filename> image, then
       specify them in the <filename>/etc/multipath.conf</filename> file as
       hardware handler types <literal>alua</literal>,
       <literal>rdac</literal>, <literal>hp_sw</literal>, and
       <literal>emc</literal>. For information about adding the device
       drivers to the <filename>initrd</filename> image, see
       <xref linkend="mpiosysconfsvr" xrefstyle="SectTitleOnPage"/>.
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="bwkb7my">
  <title>What’s New in SLES 11 SP2</title>

  <para>
   In addition to bug fixes, the features and behavior changes in this
   section were made for the &productname; 11 SP2 release:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Btrfs File System. See
     <xref linkend="sec.filesystems.major.btrfs" xrefstyle="SectTitleOnPage"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Open Fibre Channel over Ethernet. See
     <xref linkend="cha_fcoe" xrefstyle="ChapTitleOnPage"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Tagging for LVM storage objects. See
     <xref linkend="sec.lvm.tagging" xrefstyle="SectTitleOnPage"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     NFSv4 ACLs tools. See
     <xref linkend="nfsv4acls" xrefstyle="ChapTitleOnPage"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     <command>--assume-clean</command> option for <command>mdadm
     resize</command> command. See
     <xref linkend="resizeincrraid" xrefstyle="SectTitleOnPage"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     In the <literal>defaults</literal> section of the
     <filename>/etc/multipath.conf</filename> file, the
     <literal>default_getuid</literal> parameter was obsoleted and replaced
     by the <literal>getuid_callout </literal>parameter:
    </para>
    <para>
     The line changed from this:
    </para>
<screen>
  default_getuid "/sbin/scsi_id -g -u -s /block/%n"
</screen>
    <para>
     to this:
    </para>
<screen>
  getuid_callout "/lib/udev/scsi_id --whitelisted --device=/dev/%n"
</screen>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="bndgyod">
  <title>What’s New in SLES 11 SP1</title>

  <para>
   In addition to bug fixes, the features and behavior changes noted in this
   section were made for the &productname; 11 SP1 release.
  </para>

  <itemizedlist role="subtoc" mark="bullet" spacing="normal">
   <listitem>
    <para>
     <xref linkend="bnmqoyw" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmr1a1" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmqre5" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmti6z" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmtvr8" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmrccr" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmrfnk" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmtwna" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmss2g" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmszsy" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bnmtqql" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="bnmqoyw">
   <title>Saving iSCSI Target Information</title>
   <remark>#301932: Export credentials for target of iSCSI target</remark>
   <para>
    In the
    <link linkend="sec_inst_system_iscsi_target_yast"><guimenu>&yast;</guimenu><guimenu>Network
    Services</guimenu><guimenu>iSCSI Target</guimenu></link> function, a
    <guimenu>Save</guimenu> option was added that allows you to export the
    iSCSI target information. This makes it easier to provide information to
    consumers of the resources.
   </para>
  </sect2>

  <sect2 xml:id="bnmr1a1">
   <title>Modifying Authentication Parameters in the iSCSI Initiator</title>
   <remark>#305306: [YaST2] allow modification of authentication in iSCSI initiator</remark>
   <para>
    In the
    <link linkend="sec_inst_system_iscsi_target_yast"><guimenu>YaST</guimenu><guimenu>Network
    Services</guimenu><guimenu>iSCSI Initiator</guimenu></link> function,
    you can modify the authentication parameters for connecting to a target
    devices. Previously, you needed to delete the entry and re-create it in
    order to change the authentication information.
   </para>
  </sect2>

  <sect2 xml:id="bnmqre5">
   <title>Allowing Persistent Reservations for MPIO Devices</title>
   <remark>#301980: SCSI persistent reservations on MPIO devices</remark>
   <para>
    A SCSI initiator can issue SCSI reservations for a shared storage
    device, which locks out SCSI initiators on other servers from accessing
    the device. These reservations persist across SCSI resets that might
    happen as part of the SCSI exception handling process.
   </para>
   <para>
    The following are possible scenarios where SCSI reservations would be
    useful:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      In a simple SAN environment, persistent SCSI reservations help protect
      against administrator errors where a LUN is attempted to be added to
      one server but it is already in use by another server, which might
      result in data corruption. SAN zoning is typically used to prevent
      this type of error.
     </para>
    </listitem>
    <listitem>
     <para>
      In a high-availability environment with failover set up, persistent
      SCSI reservations help protect against errant servers connecting to
      SCSI devices that are reserved by other servers.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="bnmti6z">
   <title>MDADM 3.0.2</title>
   <remark>#307159: MDADM update to most recent version</remark>
   <para>
    Use the latest version of the Multiple Devices Administration (MDADM,
    <command>mdadm</command>) utility to take advantage of bug fixes and
    improvements.
   </para>
  </sect2>

  <sect2 xml:id="bnmtvr8">
   <title>Boot Loader Support for MDRAID External Metadata</title>
   <remark>#307447: Boot support for MDRAID External Metadata (ISW)</remark>
   <para>
    Support was added to use the external metadata capabilities of the MDADM
    utility version 3.0 to install and run the operating system from RAID
    volumes defined by the Intel Matrix Storage Technology metadata format.
    This moves the functionality from the Device Mapper RAID (DMRAID)
    infrastructure to the Multiple Devices RAID (MDRAID) infrastructure,
    which offers the more mature RAID 5 implementation and offers a wider
    feature set of the MD kernel infrastructure. It allows a common RAID
    driver to be used across all metadata formats, including Intel, DDF
    (common RAID disk data format), and native MD metadata.
   </para>
  </sect2>

  <sect2 xml:id="bnmrccr">
   <title>&yast; Install and Boot Support for MDRAID External Metadata</title>
   <remark>#305883: Install and boot support for MDRAID External Metadata (ISW)</remark>
   <para>
    The &yast; installer tool added support for MDRAID External Metadata
    for RAID 0, 1, 10, 5, and 6. The installer can detect RAID arrays and
    whether the platform RAID capabilities are enabled. If multipath RAID is
    enabled in the platform BIOS for Intel Matrix Storage Manager, it offers
    options for DMRAID, MDRAID (recommended), or none. The
    <filename>initrd</filename> was also modified to support assembling
    BIOS-based RAID arrays.
   </para>
  </sect2>

  <sect2 xml:id="bnmrfnk">
   <title>Improved Shutdown for MDRAID Arrays that Contain the Root File System</title>
   <remark>#305885: Handle the metadata "dirty" bit when an ISW array contains the root file system</remark>
   <remark>#306823: Handle the metadata "dirty" bit when an ISW array contains the root filesystem</remark>
   <para>
    Shutdown scripts were modified to wait until all of the MDRAID arrays
    are marked clean. The operating system shutdown process now waits for a
    dirty-bit to be cleared until all MDRAID volumes have finished write
    operations.
   </para>
   <para>
    Changes were made to the startup script, shutdown script, and the
    <command>initrd</command> to consider whether the root
    (<filename>/</filename>) file system (the system volume that contains
    the operating system and application files) resides on a software RAID
    array. The metadata handler for the array is started early in the
    shutdown process to monitor the final root file system environment
    during the shutdown. The handler is excluded from the general
    <command>killall</command> events. The process also allows for writes to
    be quiesced and for the array’s metadata dirty-bit (which indicates
    whether an array needs to be resynchronized) to be cleared at the end of
    the shutdown.
   </para>
  </sect2>

  <sect2 xml:id="bnmtwna">
   <title>MD over iSCSI Devices</title>
   <remark>#307478: md over iscsi devices</remark>
   <para>
    The &yast; installer now allows MD to be configured over iSCSI
    devices.
   </para>
   <para>
    If RAID arrays are needed on boot, the iSCSI initiator software is
    loaded before <filename>boot.md</filename> so that the iSCSI targets are
    available to be auto-configured for the RAID.
   </para>
   <para>
    For a new install, Libstorage creates an
    <filename>/etc/mdadm.conf</filename> file and adds the line
    <literal>AUTO -all</literal>. During an update, the line is not added.
    If <filename>/etc/mdadm.conf</filename> contains the line
   </para>
<screen>
AUTO -all
</screen>
   <para>
    then no RAID arrays are auto-assembled unless they are explicitly listed
    in <filename>/etc/mdadm.conf</filename>.
   </para>
  </sect2>

  <sect2 xml:id="bnmss2g">
   <title>MD-SGPIO</title>
   <remark>#305886: SGPIO support for MD</remark>
   <para>
    The MD-SGPIO utility is a standalone application that monitors RAID
    arrays via <command>sysfs(2)</command>. Events trigger an LED change
    request that controls blinking for LED lights that are associated with
    each slot in an enclosure or a drive bay of a storage subsystem. It
    supports two types of LED systems:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      2-LED systems (Activity LED, Status LED)
     </para>
    </listitem>
    <listitem>
     <para>
      3-LED systems (Activity LED, Locate LED, Fail LED)
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="bnmszsy">
   <title>Resizing LVM 2 Mirrors</title>
   <remark>#306518: LVM mirror resize</remark>
   <para>
    The <command>lvresize</command>, <command>lvextend</command>, and
    <command>lvreduce</command> commands that are used to resize logical
    volumes were modified to allow the resizing of LVM 2 mirrors.
    Previously, these commands reported errors if the logical volume was a
    mirror.
   </para>
  </sect2>

  <sect2 xml:id="bnmtqql">
   <title>Updating Storage Drivers for Adapters on IBM Servers</title>
   <remark>#307414: Storage driver updates</remark>
   <para>
    Update the following storage drivers to use the latest available
    versions to support storage adapters on IBM servers:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Adaptec: <filename>aacraid</filename>, <filename>aic94xx</filename>
     </para>
    </listitem>
    <listitem>
     <para>
      Emulex: <filename>lpfc</filename>
     </para>
    </listitem>
    <listitem>
     <para>
      LSI: <filename>mptas</filename>, <filename>megaraid_sas</filename>
     </para>
     <para>
      The <filename>mptsas</filename> driver now supports native EEH
      (Enhanced Error Handler) recovery, which is a key feature for all of
      the IO devices for Power platform customers.
     </para>
    </listitem>
    <listitem>
     <para>
      qLogic: <filename>qla2xxx</filename>, <filename>qla3xxx</filename>,
      <filename>qla4xxx</filename>
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
 <sect1 xml:id="bndgyoe">
  <title>What’s New in SLES 11</title>

  <para>
   The features and behavior changes noted in this section were made for the
   &productname; 11 release.
  </para>

  <itemizedlist role="subtoc" mark="bullet" spacing="normal">
   <listitem>
    <para>
     <xref linkend="bi72tak" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bi72zf2" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="b12xr11r" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="biu3u2m" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="biu3v96" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bin8klb" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="binagtl" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="binahn3" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bin9wm3" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bmqiv07" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bmy1edt" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bn4yxd1" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="bvc111p" xrefstyle="SectTitleOnPage"/>
    </para>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="bi72tak">
   <title>EVMS2 Is Deprecated</title>
   <para>
    The Enterprise Volume Management Systems (EVMS2) storage management
    solution is deprecated. All EVMS management modules have been removed
    from the &productname; 11 packages. Your non-system EVMS-managed
    devices should be automatically recognized and managed by Linux Volume
    Manager 2 (LVM2) when you upgrade your system.
<!--
      taroth 2014-05-09: commenting because redirects only to
      http://www.suse.com/, without any specific information on the topic:
      For more information, see
     <ulink url="http://www.novell.com/linux/volumemanagement/strategy.html">
     <citetitle>Evolution of Storage and Volume Management in SUSE Linux
     Enterprise</citetitle></ulink>.-->
   </para>
   <para>
    If you have EVMS managing the system device (any device that contains
    the root (<filename>/</filename>), <filename>/boot</filename>, or
    <filename>swap</filename>), try these things to prepare the SLES 10
    server before you reboot the server to upgrade:
   </para>
   <procedure xml:id="b176hy1d">
    <step xml:id="b176hy1e">
     <para>
      In the /etc/fstab file, modify the boot and swap disks to the default
      <filename>/dev/system/sys_lx</filename> directory:
     </para>
     <substeps performance="required">
      <step xml:id="b176hy1f">
       <para>
        Remove <filename>/evms/lvm2</filename> from the path for the
        <filename>swap</filename> and root (<filename>/</filename>)
        partitions.
       </para>
      </step>
      <step xml:id="b176hy1g">
       <para>
        Remove <filename>/evms</filename> from the path for
        <filename>/boot</filename> partition.
       </para>
      </step>
     </substeps>
    </step>
    <step xml:id="b176hy1h">
     <para>
      In the <filename>/boot/grub/menu.lst</filename> file, remove
      <filename>/evms/lvm2</filename> from the path.
     </para>
    </step>
    <step xml:id="b176hy1i">
     <para>
      In the <filename>/etc/sysconfig/bootloader</filename> file, verify
      that the path for the boot device is the <filename>/dev</filename>
      directory.
     </para>
    </step>
    <step xml:id="b176hy1j">
     <para>
      Ensure that <filename>boot.lvm</filename> and
      <filename>boot.md</filename> are enabled:
     </para>
     <substeps performance="required">
      <step xml:id="b176hy1k">
       <para>
<!--<remark>taroth 2014-02-27: systemd: CAVE - the following can stay as it is
         because it refers to the preparation of a  SLE *10* machine before
         upgrading it to a newer version</remark>-->
        In &yast;, click <guimenu>System</guimenu><guimenu>Runlevel
        Editor</guimenu><guimenu>Expert Mode</guimenu>.
       </para>
      </step>
      <step xml:id="b176hy1l">
       <para>
        Select <filename>boot.lvm</filename>.
       </para>
      </step>
      <step xml:id="b176hy1m">
       <para>
        Click <guimenu>Set/Reset</guimenu><guimenu>Enable the
        Service</guimenu>.
       </para>
      </step>
      <step xml:id="b176hy1n">
       <para>
        Select <filename>boot.md</filename>.
       </para>
      </step>
      <step xml:id="b176hy1o">
       <para>
        Click <guimenu>Set/Reset</guimenu><guimenu>Enable the
        Service</guimenu>.
       </para>
      </step>
      <step xml:id="b176hy1p">
       <para>
        Click <guimenu>Finish</guimenu>, then click <guimenu>Yes</guimenu>.
       </para>
      </step>
     </substeps>
    </step>
    <step xml:id="b176hy1q">
     <para>
      Reboot and start the upgrade.
     </para>
    </step>
   </procedure>
   <para>
    For information about managing storage with EVMS2 on SUSE Linux
    Enterprise Server 10, see the
    <link xlink:href="http://www.suse.com/documentation/sles10/stor_admin/data/bookinfo.html"><citetitle>SUSE
    Linux Enterprise Server 10 SP3: Storage Administration
    Guide</citetitle></link>.
   </para>
  </sect2>

  <sect2 xml:id="bi72zf2">
   <title>Ext3 as the Default File System</title>
   <para>
    The Ext3 file system has replaced ReiserFS as the default file system
    recommended by the &yast; tools at installation time and when you
    create file systems. ReiserFS is still supported. For more information,
    see
    <link xlink:href="http://www.suse.com/products/server/technical-information/?tab=2"><citetitle>File
    System Support</citetitle></link> on the <citetitle>SUSE Linux
    Enterprise 11 Tech Specs</citetitle> Web page.
   </para>
  </sect2>

  <sect2 xml:id="b12xr11r">
   <title>Default Inode Size Increased for Ext3</title>
   <para>
    <remark>Bug 708669</remark>
    To allow space for extended attributes and ACLs for a file on Ext3 file
    systems, the default inode size for Ext3 was increased from 128 bytes on
    SLES 10 to 256 bytes on SLES11. For information, see
    <xref linkend="sec.filesystems.major.ext3.inodesize" xrefstyle="HeadingOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="biu3u2m">
   <title>JFS File System Is Deprecated</title>
   <para>
    The JFS file system is no longer supported. The JFS utilities were
    removed from the distribution.
   </para>
  </sect2>

  <sect2 xml:id="biu3v96">
   <title>OCFS2 File System Is in the High Availability Release</title>
   <para>
    The OCFS2 file system is fully supported as part of the &sle;
    &hasi;.
   </para>
  </sect2>

  <sect2 xml:id="bin8klb">
   <title>/dev/disk/by-name Is Deprecated</title>
   <para>
    The <filename>/dev/disk/by-name</filename> path is deprecated in SUSE
    Linux Enterprise Server 11 packages.
   </para>
  </sect2>

  <sect2 xml:id="binagtl">
   <title>Device Name Persistence in the /dev/disk/by-id Directory</title>
   <para>
    In &productname; 11, the default multipath setup relies on
    <command>udev</command> to overwrite the existing symbolic links in the
    <filename>/dev/disk/by-id</filename> directory when multipathing is
    started. Before you start multipathing, the link points to the SCSI
    device by using its <filename>scsi-xxx</filename> name. When
    multipathing is running, the symbolic link points to the device by using
    its <filename>dm-uuid-xxx</filename> name. This ensures that the
    symbolic links in the <filename>/dev/disk/by-id</filename> path
    persistently point to the same device regardless of whether multipathing
    is started or not. The configuration files (such as
    <filename>lvm.conf</filename> and <filename>md.conf</filename>) do not
    need to be modified because they automatically point to the correct
    device.
   </para>
   <para>
    See the following sections for more information about how this behavior
    change affects other features:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      <xref linkend="binahn3" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="bin9wm3" xrefstyle="SectTitleOnPage"/>
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="binahn3">
   <title>Filters for Multipathed Devices</title>
   <para>
    The deprecation of the <filename>/dev/disk/by-name</filename> directory
    (as described in <xref linkend="bin8klb" xrefstyle="SectTitleOnPage"/>)
    affects how you set up filters for multipathed devices in the
    configuration files. If you used the
    <filename>/dev/disk/by-name</filename> device name path for the
    multipath device filters in the <filename>/etc/lvm/lvm.conf</filename>
    file, you need to modify the file to use the
    <filename>/dev/disk/by-id</filename> path. Consider the following when
    setting up filters that use the <filename>by-id</filename> path:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      The <filename>/dev/disk/by-id/scsi-*</filename> device names are
      persistent and created for exactly this purpose.
     </para>
    </listitem>
    <listitem>
     <para>
      Do not use the <filename>/dev/disk/by-id/dm-*</filename> name in the
      filters. These are symbolic links to the Device-Mapper devices, and
      result in reporting duplicate PVs in response to a
      <filename>pvscan</filename> command. The names appear to change from
      <filename>LVM-pvuuid</filename> to <filename>dm-uuid</filename> and
      back to <filename>LVM-pvuuid</filename>.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    For information about setting up filters, see
    <xref linkend="mpiousinglvm" xrefstyle="SectTitleOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="bin9wm3">
   <title>User-Friendly Names for Multipathed Devices</title>
   <para>
    A change in how multipathed device names are handled in the
    <filename>/dev/disk/by-id</filename> directory (as described in
    <xref linkend="binagtl" xrefstyle="SectTitleOnPage"/>) affects your
    setup for user-friendly names because the two names for the device
    differ. You must modify the configuration files to scan only the device
    mapper names after multipathing is configured.
   </para>
   <para>
    For example, you need to modify the <filename>lvm.conf</filename> file
    to scan using the multipathed device names by specifying the
    <filename>/dev/disk/by-id/dm-uuid-.*-mpath-.*</filename> path instead of
    <filename>/dev/disk/by-id</filename>.
   </para>
  </sect2>

  <sect2 xml:id="bmqiv07">
   <title>Advanced I/O Load-Balancing Options for Multipath</title>
   <para>
    The following advanced I/O load-balancing options are available for
    Device Mapper Multipath, in addition to round-robin:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Least-pending
     </para>
    </listitem>
    <listitem>
     <para>
      Length-load-balancing
     </para>
    </listitem>
    <listitem>
     <para>
      Service-time
     </para>
    </listitem>
   </itemizedlist>
   <para>
    For information, see <xref linkend="b122sbgu" xrefstyle="RefNoPage"/> in
    <xref linkend="beg263n" xrefstyle="HeadingOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="bmy1edt">
   <title>Location Change for Multipath Tool Callouts</title>
   <para>
    The <filename>mpath_*</filename> prio_callouts for the Device Mapper
    Multipath tool have been moved to shared libraries
    in<filename>/lib/libmultipath/lib*</filename>. By using shared
    libraries, the callouts are loaded into memory on daemon startup. This
    helps avoid a system deadlock on an all-paths-down scenario where the
    programs need to be loaded from the disk, which might not be available
    at this point.
   </para>
  </sect2>

  <sect2 xml:id="bn4yxd1">
   <title>Change from mpath to multipath for the mkinitrd -f Option</title>
   <para>
    The option for adding Device Mapper Multipath services to the
    <filename>initrd</filename> has changed from <literal>-f mpath</literal>
    to <literal>-f multipath</literal>.
   </para>
   <para>
    To make a new <filename>initrd</filename>, the command is now:
   </para>
<screen>
mkinitrd -f multipath
</screen>
  </sect2>

  <sect2 xml:id="bvc111p">
   <title>Change from Multibus to Failover as the Default Setting for the MPIO Path Grouping Policy</title>
   <para>
    The default setting for the <literal>path_grouping_policy</literal> in
    the <filename>/etc/multipath.conf </filename>file has changed from
    <literal>multibus</literal> to <literal>failover</literal>.
   </para>
   <para>
    For information about configuring the path_grouping_policy, see
    <xref linkend="bbi89rh" xrefstyle="SectTitleOnPage"/>.
   </para>
  </sect2>
 </sect1>
</chapter>
