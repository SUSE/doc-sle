<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.multipath" xml:lang="en">
 <title>Managing Multipath I/O for Devices</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <para>
  This section describes how to manage failover and path load balancing for
  multiple paths between the servers and block storage devices by using
  Multipath I/O (MPIO).
 </para>
 <sect1 xml:id="sec.multipath.intro">
  <title>Understanding Multipath I/O</title>

  <para>
   Multipathing is the ability of a server to communicate with the same
   physical or logical block storage device across multiple physical paths
   between the host bus adapters in the server and the storage controllers for
   the device, typically in Fibre Channel (FC) or iSCSI SAN environments. You
   can also achieve multiple connections with direct attached storage when
   multiple channels are available.
  </para>

  <para>
   Linux multipathing provides connection fault tolerance and can provide load
   balancing across the active connections. When multipathing is configured and
   running, it automatically isolates and identifies device connection
   failures, and reroutes I/O to alternate connections.
  </para>

  <para>
   Typical connection problems involve faulty adapters, cables, or controllers.
   When you configure multipath I/O for a device, the multipath driver monitors
   the active connection between devices. When the multipath driver detects I/O
   errors for an active path, it fails over the traffic to the device’s
   designated secondary path. When the preferred path becomes healthy again,
   control can be returned to the preferred path.
  </para>
 </sect1>
 <sect1 xml:id="sec.multipath.hardware">
  <title>Hardware Support</title>

  <para>
   The multipathing drivers and tools support all architectures for which
   &productname; is available. They support most storage arrays. The storage
   array that houses the multipathed device must support multipathing to use
   the multipathing drivers and tools. Some storage array vendors provide their
   own multipathing management tools. Consult the vendor’s hardware
   documentation to determine what settings are required.
  </para>

  <sect2 xml:id="sec.multipath.hardware.autodetect">
   <title>Storage Arrays That Are Automatically Detected for Multipathing</title>
   <para>
    The <filename>multipath-tools</filename> package automatically detects the
    following storage arrays:
   </para>
   <simplelist>
    <member>3PARdata VV</member>
    <member>AIX NVDISK</member>
    <member>AIX VDASD</member>
    <member>APPLE Xserve RAID</member>
    <member>COMPELNT Compellent Vol</member>
    <member>COMPAQ/HP HSV101, HSV111, HSV200, HSV210, HSV300, HSV400, HSV 450</member>
    <member>COMPAQ/HP MSA, HSV</member>
    <member>COMPAQ/HP MSA VOLUME</member>
    <member>DataCore SANmelody</member>
    <member>DDN SAN DataDirector</member>
    <member>DEC HSG80</member>
    <member>DELL MD3000</member>
    <member>DELL MD3000i</member>
    <member>DELL MD32xx</member>
    <member>DELL MD32xxi</member>
    <member>DGC</member>
    <member>EMC Clariion</member>
    <member>EMC Invista</member>
    <member>EMC SYMMETRIX</member>
    <member>EUROLOGC FC2502</member>
    <member>FSC CentricStor</member>
    <member>FUJITSU ETERNUS_DX, DXL, DX400, DX8000</member>
    <member>HITACHI DF</member>
    <member>HITACHI/HP OPEN</member>
    <member>HP A6189A</member>
    <member>HP HSVX700</member>
    <member>HP LOGICAL VOLUME</member>
    <member>HP MSA2012fc, MSA 2212fc, MSA2012i</member>
    <member>HP MSA2012sa, MSA2312 fc/i/sa, MCA2324 fc/i/sa, MSA2000s VOLUME</member>
    <member>HP P2000 G3 FC|P2000G3 FC/iSCSI|P2000 G3 SAS|P2000 G3 iSCSI</member>
    <member>IBM 1722-600</member>
    <member>IBM 1724</member>
    <member>IBM 1726</member>
    <member>IBM 1742</member>
    <member>IBM 1745, 1746</member>
    <member>IBM 1750500</member>
    <member>IBM 1814</member>
    <member>IBM 1815</member>
    <member>IBM 1818</member>
    <member>IBM 1820N00</member>
    <member>IBM 2105800</member>
    <member>IBM 2105F20</member>
    <member>IBM 2107900</member>
    <member>IBM 2145</member>
    <member>IBM 2810XIV</member>
    <member>IBM 3303 NVDISK</member>
    <member>IBM 3526</member>
    <member>IBM 3542</member>
    <member>IBM IPR</member>
    <member>IBM Nseries</member>
    <member>IBM ProFibre 4000R</member>
    <member>IBM S/390 DASD ECKD</member>
    <member>IBM S/390 DASD FBA</member>
    <member>Intel Multi-Flex</member>
    <member>LSI/ENGENIO INF-01-00</member>
    <member>NEC DISK ARRAY</member>
    <member>NETAPP LUN</member>
    <member>NEXENTA COMSTAR</member>
    <member>Pillar Axiom</member>
    <member>PIVOT3 RAIGE VOLUME</member>
    <member>SGI IS</member>
    <member>SGI TP9100, TP 9300</member>
    <member>SGI TP9400, TP9500</member>
    <member>STK FLEXLINE 380</member>
    <member>STK OPENstorage D280</member>
    <member>SUN CSM200_R</member>
    <member>SUN LCSM100_[IEFS]</member>
    <member>SUN STK6580, STK6780</member>
    <member>SUN StorEdge 3510, T4</member>
    <member>SUN SUN_6180</member>
   </simplelist>
   <para>
    In general, most other storage arrays should work. When storage arrays are
    automatically detected, the default settings for multipathing apply. If you
    want non-default settings, you must manually create and configure the
    <filename>/etc/multipath.conf</filename> file. The same applies for
    hardware that is not automatically detected. For information, see
    <xref linkend="sec.multipath.conf_file" xrefstyle="SectTitleOnPage"/>.
   </para>
   <para>
    Consider the following caveats:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Not all of the storage arrays that are automatically detected have been
      tested on &productname;. Also see
      <xref linkend="sec.multipath.hardware.tested" xrefstyle="HeadingOnPage"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      Some storage arrays might require specific hardware handlers. A hardware
      handler is a kernel module that performs hardware-specific actions when
      switching path groups and dealing with I/O errors. For information, see
      <xref linkend="sec.multipath.hardware.handlers" xrefstyle="HeadingOnPage"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      After you modify the <filename>/etc/multipath.conf</filename> file, you
      must run <command>dracut</command> <option>-f</option> to re-create the
      <systemitem>initrd</systemitem> on your system, then reboot for the
      changes to take effect.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="sec.multipath.hardware.tested">
   <title>Tested Storage Arrays for Multipathing Support</title>
   <para>
    Storage arrays from the following vendors have been tested with
    &productname;:
   </para>
   <simplelist>
    <member>EMC</member>
    <member>Hitachi</member>
    <member>Hewlett-Packard/Compaq</member>
    <member>IBM</member>
    <member>NetApp</member>
    <member>SGI</member>
   </simplelist>
   <para>
    Most other vendor storage arrays should also work. Consult your vendor’s
    documentation for guidance. For a list of the default storage arrays
    recognized by the <filename>multipath-tools</filename> package, see
    <xref linkend="sec.multipath.hardware.autodetect" xrefstyle="HeadingOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.hardware.handlers">
   <title>Storage Arrays that Require Specific Hardware Handlers</title>
   <para>
    Storage arrays that require special commands on failover from one path to
    the other or that require special nonstandard error handling might require
    more extensive support. Therefore, the Device Mapper Multipath service has
    hooks for hardware handlers. For example, one such handler for the EMC
    CLARiiON CX family of arrays is already provided.
   </para>
   <important>
    <title>For More Information</title>
    <para>
     Consult the hardware vendor’s documentation to determine if its hardware
     handler must be installed for Device Mapper Multipath.
    </para>
   </important>
   <para>
    The <command>multipath -t</command> command shows an internal table of
    storage arrays that require special handling with specific hardware
    handlers. The displayed list is not an exhaustive list of supported storage
    arrays. It lists only those arrays that require special handling and that
    the <filename>multipath-tools</filename> developers had access to during
    the tool development.
   </para>
   <important>
    <title>Exceptions</title>
    <para>
     Arrays with true active/active multipath support do not require special
     handling, so they are not listed for the <command>multipath -t</command>
     command.
    </para>
   </important>
   <para>
    A listing in the <command>multipath -t</command> table does not necessarily
    mean that &productname; was tested on that specific hardware. For a list of
    tested storage arrays, see
    <xref linkend="sec.multipath.hardware.tested" xrefstyle="HeadingOnPage"/>.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.planning">
  <title>Planning for Multipathing</title>

  <para>
   Use the guidelines in this section when planning your multipath I/O
   solution.
  </para>

  <sect2 xml:id="sec.multipath.planning.prereq">
   <title>Prerequisites</title>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Multipathing is managed at the device level.
     </para>
    </listitem>
    <listitem>
     <para>
      The storage array you use for the multipathed device must support
      multipathing. For more information, see
      <xref linkend="sec.multipath.hardware" xrefstyle="SectTitleOnPage"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      You need to configure multipathing only if multiple physical paths exist
      between host bus adapters in the server and host bus controllers for the
      block storage device. You configure multipathing for the logical device
      as seen by the server.
     </para>
    </listitem>
    <listitem>
     <para>
      For some storage arrays, the vendor provides its own multipathing
      software to manage multipathing for the array’s physical and logical
      devices. In this case, you should follow the vendor’s instructions for
      configuring multipathing for those devices.
     </para>
    </listitem>
    <listitem>
     <para>
      When using multipathing in a virtualization environment, the multipathing
      is controlled in the host server environment. Configure multipathing for
      the device before you assign it to a virtual guest machine.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="sec.multipath.planning.disks">
   <title>Disk Management Tasks</title>
   <para>
    Perform the following disk management tasks before you attempt to configure
    multipathing for a physical or logical device that has multiple paths:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Use third-party tools to carve physical disks into smaller logical disks.
     </para>
    </listitem>
    <listitem>
     <para>
      Use third-party tools to partition physical or logical disks. If you
      change the partitioning in the running system, the Device Mapper
      Multipath (DM-MP) module does not automatically detect and reflect these
      changes. DM-MPIO must be re-initialized, which usually requires a reboot.
     </para>
    </listitem>
    <listitem>
     <para>
      Use third-party SAN array management tools to create and configure
      hardware RAID devices.
     </para>
    </listitem>
    <listitem>
     <para>
      Use third-party SAN array management tools to create logical devices such
      as LUNs. Logical device types that are supported for a given array depend
      on the array vendor.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="sec.multipath.planning.lvm">
   <title>Volume Managers</title>
   <para>
    Volume managers such as LVM2 and Clustered LVM2 run on top of multipathing.
    You must configure multipathing for a device before you use LVM2 or cLVM2
    to create segment managers and file systems on it. For information, see
    <xref linkend="sec.multipath.lvm" xrefstyle="SectTitleOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.planning.raid">
   <title>Software RAIDs</title>
   <para>
    The Linux software RAID management software runs on top of multipathing.
    For each device that has multiple I/O paths and that you plan to use in a
    software RAID, you must configure the device for multipathing before you
    attempt to create the software RAID device. Automatic discovery of
    multipathed devices is not available. The software RAID is not aware of the
    multipathing management running underneath.
   </para>
   <para>
    For information about setting up multipathing for existing software RAIDs,
    see <xref linkend="sec.multipath.raid" xrefstyle="SectTitleOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.planning.ha">
   <title>High-Availability Solutions</title>
   <para>
    High-availability solutions for clustering storage resources run on top of
    the multipathing service on each node. Ensure that the configuration
    settings in the <filename>/etc/multipath.conf</filename> file on each node
    are consistent across the cluster.
   </para>
   <para>
    Ensure that multipath devices have the same name across all devices. Refer
    to <xref linkend="sec.multipath.names.ha"/> for details.
   </para>
   <para>
    The Distributed Replicated Block Device (DRBD) high-availability solution
    for mirroring devices across a LAN runs on top of multipathing. For each
    device that has multiple I/O paths and that you plan to use in a DRDB
    solution, you must configure the device for multipathing before you
    configure DRBD.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.mpiotools">
  <title>Multipath Management Tools</title>

  <para>
   The multipathing support in &productname; is based on the Device Mapper
   Multipath module of the Linux kernel and the
   <systemitem>multipath-tools</systemitem> user space package. You can use the
   Multiple Devices Administration utility (MDADM, <command>mdadm</command>) to
   view the status of multipathed devices.
  </para>

  <sect2 xml:id="sec.multipath.mpiotools.dm">
   <title>Device Mapper Multipath Module</title>
   <para>
    The Device Mapper Multipath (DM-MP) module provides the multipathing
    capability for Linux. DM-MPIO is the preferred solution for multipathing on
    &productname;. It is the only multipathing option shipped with the product
    that is completely supported by &suse;.
   </para>
   <para>
    DM-MPIO features automatic configuration of the multipathing subsystem for
    a large variety of setups. Configurations of up to eight paths to each
    device are supported. Configurations are supported for active/passive (one
    path active, others passive) or active/active (all paths active with
    round-robin load balancing).
   </para>
   <para>
    The DM-MPIO framework is extensible in two ways:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Using specific hardware handlers. For information, see
      <xref linkend="sec.multipath.hardware.handlers" xrefstyle="HeadingOnPage"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      Using load-balancing algorithms that are more sophisticated than the
      round-robin algorithm.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    The user space component of DM-MPIO takes care of automatic path discovery
    and grouping, and automated path retesting, so that a previously failed
    path is automatically reinstated when it becomes healthy again. This
    minimizes the need for administrator attention in a production environment.
   </para>
   <para>
    DM-MPIO protects against failures in the paths to the device, and not
    failures in the device itself. If one of the active paths is lost (for
    example, a network adapter breaks or a fiber-optic cable is removed), I/O
    is redirected to the remaining paths. If the configuration is
    active/passive, then the path fails over to one of the passive paths. If
    you are using the round-robin load-balancing configuration, the traffic is
    balanced across the remaining healthy paths. If all active paths fail,
    inactive secondary paths must be woken up, so failover occurs with a delay
    of approximately 30 seconds.
   </para>
   <para>
    If a disk array has more than one storage processor, ensure that the SAN
    switch has a connection to the storage processor that owns the LUNs you
    want to access. On most disk arrays, all LUNs belong to both storage
    processors, so both connections are active.
   </para>
   <note>
    <title>Storage Processors</title>
    <para>
     On some disk arrays, the storage array manages the traffic through storage
     processors so that it presents only one storage processor at a time. One
     processor is active and the other one is passive until there is a failure.
     If you are connected to the wrong storage processor (the one with the
     passive path) you might not see the expected LUNs, or you might see the
     LUNs but get errors when you try to access them.
    </para>
   </note>
   <table>
    <title>Multipath I/O Features of Storage Arrays</title>
    <tgroup cols="2">
     <colspec colnum="1" colname="1" colwidth="2857*"/>
     <colspec colnum="2" colname="2" colwidth="7144*"/>
     <thead>
      <row>
       <entry>
        <para>
         Features of Storage Arrays
        </para>
       </entry>
       <entry>
        <para>
         Description
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         Active/passive controllers
        </para>
       </entry>
       <entry>
        <para>
         One controller is active and serves all LUNs. The second controller
         acts as a standby. The second controller also presents the LUNs to the
         multipath component so that the operating system knows about redundant
         paths. If the primary controller fails, the second controller takes
         over, and it serves all LUNs.
        </para>
        <para>
         In some arrays, the LUNs can be assigned to different controllers. A
         given LUN is assigned to one controller to be its active controller.
         One controller does the disk I/O for any LUN at a time, and the second
         controller is the standby for that LUN. The second controller also
         presents the paths, but disk I/O is not possible. Servers that use
         that LUN are connected to the LUN’s assigned controller. If the
         primary controller for a set of LUNs fails, the second controller
         takes over, and it serves all LUNs.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Active/active controllers
        </para>
       </entry>
       <entry>
        <para>
         Both controllers share the load for all LUNs, and can process disk I/O
         for any LUN. If one controller fails, the second controller
         automatically handles all traffic.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Load balancing
        </para>
       </entry>
       <entry>
        <para>
         The Device Mapper Multipath driver automatically load balances traffic
         across all active paths.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Controller failover
        </para>
       </entry>
       <entry>
        <para>
         When the active controller fails over to the passive, or standby,
         controller, the Device Mapper Multipath driver automatically activates
         the paths between the host and the standby, making them the primary
         paths.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Boot/Root device support
        </para>
       </entry>
       <entry>
        <para>
         Multipathing is supported for the root (<filename>/</filename>) device
         in &productname; 10 and later. The host server must be connected to
         the currently active controller and storage processor for the boot
         device.
        </para>
        <para>
         Multipathing is supported for the <filename>/boot</filename> device in
         &productname; 11 and later.
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   <para>
    Device Mapper Multipath detects every path for a multipathed device as a
    separate SCSI device. The SCSI device names take the form
    <filename>/dev/sd<replaceable>N</replaceable></filename>, where
    <filename><replaceable>N</replaceable></filename> is an autogenerated
    letter for the device, beginning with a and issued sequentially as the
    devices are created, such as <filename>/dev/sda</filename>,
    <filename>/dev/sdb</filename>, and so on. If the number of devices exceeds
    26, the letters are duplicated so that the next device after
    <filename>/dev/sdz</filename> will be named <filename>/dev/sdaa</filename>,
    <filename>/dev/sdab</filename>, and so on.
   </para>
   <para>
    If multiple paths are not automatically detected, you can configure them
    manually in the <filename>/etc/multipath.conf</filename> file. The
    <filename>multipath.conf</filename> file does not exist until you create
    and configure it. For information, see
    <xref linkend="sec.multipath.conf_file" xrefstyle="SectTitleOnPage"/>.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.mpiotools.io_management">
   <title>Multipath I/O Management Tools</title>
   <para>
    The packages <systemitem class="resource">multipath-tools</systemitem> and
    <systemitem class="resource">kpartx</systemitem> provide tools that take
    care of automatic path discovery and grouping. They automatically test the
    path periodically, so that a previously failed path is automatically
    reinstated when it becomes healthy again. This minimizes the need for
    administrator attention in a production environment.
   </para>
   <table>
    <title>Tools in the multipath-tools Package</title>
    <tgroup cols="2">
     <colspec colnum="1" colname="1" colwidth="2857*"/>
     <colspec colnum="2" colname="2" colwidth="7144*"/>
     <thead>
      <row>
       <entry>
        <para>
         Tool
        </para>
       </entry>
       <entry>
        <para>
         Description
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         <command>multipath</command>
        </para>
       </entry>
       <entry>
        <para>
         Scans the system for multipathed devices and assembles them.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         <command>multipathd</command>
        </para>
       </entry>
       <entry>
        <para>
         Waits for maps events, then executes <command>multipath</command>.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         <command>kpartx</command>
        </para>
       </entry>
       <entry>
        <para>
         Maps linear devmaps to partitions on the multipathed device, which
         makes it possible to create multipath monitoring for partitions on the
         device.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         <command>mpathpersist</command>
        </para>
       </entry>
       <entry>
        <para>
         Manages SCSI-persistent reservations on Device Mapper Multipath
         devices.ppc
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </sect2>

  <sect2 xml:id="sec.multipath.mpiotools.mdadm">
   <title>Using MDADM for Multipathed Devices</title>
   <para>
    Udev is the default device handler, and devices are automatically known to
    the system by the Worldwide ID instead of by the device node name. This
    resolves problems in previous releases of MDADM and LVM where the
    configuration files (<filename>mdadm.conf</filename> and
    <filename>lvm.conf)</filename> did not properly recognize multipathed
    devices.
   </para>
   <para>
    As with LVM2, MDADM requires that the devices be accessed by the ID rather
    than by the device node path. Therefore, the
    <systemitem>DEVICE</systemitem> entry in
    <filename>/etc/mdadm.conf</filename> should be set as follows:
   </para>
<screen>DEVICE /dev/disk/by-id/*</screen>
   <para>
    If you are using user-friendly names, specify the path as follows so that
    only the device mapper names are scanned after multipathing is configured:
   </para>
<screen>DEVICE /dev/disk/by-id/dm-uuid-.*-mpath-.*</screen>
  </sect2>

  <sect2 xml:id="sec.multipath.mpiotools.multipath">
   <title>The multipath Command</title>
   <para>
    Use the Linux <command>multipath(8)</command> command to configure and
    manage multipathed devices. The general syntax for the command looks like
    the following:
   </para>
<screen>multipath [-v verbosity_level] [-b bindings_file] [-d] [-h|-l|-ll|-f|-F|-B|-c|-q|-r|-w|-W] [-p failover|multibus|group_by_serial|group_by_prio|group_by_node_name] [<replaceable>devicename</replaceable>]</screen>
   <para>
    Refer to <command>man 8 multipath</command> for details.
   </para>
   <bridgehead>General Examples</bridgehead>
   <variablelist>
    <varlistentry>
     <term>multipath</term>
     <listitem>
      <para>
       Configures all multipath devices.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath <replaceable>devicename</replaceable>
     </term>
     <listitem>
      <para>
       Configures a specific multipath device.
      </para>
      <para>
       Replace <replaceable>devicename</replaceable> with the device node name
       such as <filename>/dev/sdb</filename> (as shown by udev in the $DEVNAME
       variable), or in the <literal>major:minor</literal> format. The device
       may alternatively be a multipath map name.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -f</term>
     <listitem>
      <para>
       Selectively suppresses a multipath map, and its device-mapped
       partitions.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -d</term>
     <listitem>
      <para>
       Dry run. Displays potential multipath devices, but does not create any
       devices and does not update device maps.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -v2 -d</term>
     <listitem>
      <para>
       Displays multipath map information for potential multipath devices in a
       dry run. The -v2 option shows only local disks. This verbosity level
       prints the created or updated multipath names only for use to feed other
       tools like kpartx.
      </para>
      <para>
       There is no output if the device already exists and there are no
       changes. Use <command>multipath -ll</command> to see the status of
       configured multipath devices.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -v2 <replaceable>devicename</replaceable>
     </term>
     <listitem>
      <para>
       Configures a specific potential multipath device and displays multipath
       map information for it. This verbosity level prints only the created or
       updated multipath names for use to feed other tools like
       <command>kpartx</command>.
      </para>
      <para>
       There is no output if the device already exists and there are no
       changes. Use <command>multipath -ll</command> to see the status of
       configured multipath devices.
      </para>
      <para>
       Replace <replaceable>devicename</replaceable> with the device node name
       such as <filename>/dev/sdb</filename> (as shown by
       <command>udev</command> in the $DEVNAME variable), or in the
       <literal>major:minor</literal> format. The device may alternatively be a
       multipath map name.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -v3</term>
     <listitem>
      <para>
       Configures potential multipath devices and displays multipath map
       information for them. This verbosity level prints all detected paths,
       multipaths, and device maps. Both WWID and <literal>devnode</literal>
       blacklisted devices are displayed.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -v3 <replaceable>devicename</replaceable>
     </term>
     <listitem>
      <para>
       Configures a specific potential multipath device and displays
       information for it. The -v3 option shows the full path list. This
       verbosity level prints all detected paths, multipaths, and device maps.
       Both WWID and <literal>devnode</literal> blacklisted devices are
       displayed.
      </para>
      <para>
       Replace <replaceable>devicename</replaceable> with the device node name
       such as <filename>/dev/sdb</filename> (as shown by
       <command>udev</command> in the $DEVNAME variable), or in the
       <literal>major:minor</literal> format. The device may alternatively be a
       multipath map name.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -ll</term>
     <listitem>
      <para>
       Displays the status of all multipath devices.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -ll <replaceable>devicename</replaceable>
     </term>
     <listitem>
      <para>
       Displays the status of a specified multipath device.
      </para>
      <para>
       Replace <replaceable>devicename</replaceable> with the device node name
       such as <filename>/dev/sdb</filename> (as shown by
       <command>udev</command> in the $DEVNAME variable), or in the
       <literal>major:minor</literal> format. The device may alternatively be a
       multipath map name.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -F</term>
     <listitem>
      <para>
       Flushes all unused multipath device maps. This unresolves the multiple
       paths; it does not delete the devices.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -F <replaceable>devicename</replaceable>
     </term>
     <listitem>
      <para>
       Flushes unused multipath device maps for a specified multipath device.
       This unresolves the multiple paths; it does not delete the device.
      </para>
      <para>
       Replace <replaceable>devicename</replaceable> with the device node name
       such as <filename>/dev/sdb</filename> (as shown by
       <command>udev</command> in the $DEVNAME variable), or in the
       <literal>major:minor</literal> format. The device may alternatively be a
       multipath map name.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipath -p [ failover | multibus | group_by_serial | group_by_prio | group_by_node_name ]</term>
     <listitem>
      <para>
       Sets the group policy by specifying one of the group policy options that
       are described in the following table:
      </para>
      <table>
       <title>Group Policy Options for the multipath -p Command</title>
       <tgroup cols="2">
        <colspec colnum="1" colname="1" colwidth="2684*"/>
        <colspec colnum="2" colname="2" colwidth="7319*"/>
        <thead>
         <row>
          <entry>
           <para>
            Policy Option
           </para>
          </entry>
          <entry>
           <para>
            Description
           </para>
          </entry>
         </row>
        </thead>
        <tbody>
         <row>
          <entry>
           <para>
            failover
           </para>
          </entry>
          <entry>
           <para>
            (Default) One path per priority group. You can use only one path at
            a time.
           </para>
          </entry>
         </row>
         <row>
          <entry>
           <para>
            multibus
           </para>
          </entry>
          <entry>
           <para>
            All paths in one priority group.
           </para>
          </entry>
         </row>
         <row>
          <entry>
           <para>
            group_by_serial
           </para>
          </entry>
          <entry>
           <para>
            One priority group per detected SCSI serial number (the controller
            node worldwide number).
           </para>
          </entry>
         </row>
         <row>
          <entry>
           <para>
            group_by_prio
           </para>
          </entry>
          <entry>
           <para>
            One priority group per path priority value. Paths with the same
            priority are in the same priority group. Priorities are determined
            by callout programs specified as a global, per-controller, or
            per-multipath option in the
            <filename>/etc/multipath.conf</filename> configuration file.
           </para>
          </entry>
         </row>
         <row>
          <entry>
           <para>
            group_by_node_name
           </para>
          </entry>
          <entry>
           <para>
            One priority group per target node name. Target node names are
            fetched in the<filename>
            /sys/class/fc_transport/target*/node_name</filename> location.
           </para>
          </entry>
         </row>
        </tbody>
       </tgroup>
      </table>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="sec.multipath.mpiotools.mpathpersist">
   <title>The mpathpersist Utility</title>
   <para>
    The <command>mpathpersist</command> utility can be used to manage SCSI
    persistent reservations on Device Mapper Multipath devices. The general
    syntax for the command looks like the following:
   </para>
<screen>mpathpersist [options] [device]</screen>
   <para>
    Refer to <command>man 8 mpathpersist</command> for details.
   </para>
   <para>
    Use this utility with the service action reservation key
    (<literal>reservation_key</literal> attribute) in the
    <filename>/etc/multipath.conf</filename> file to set persistent
    reservations for SCSI devices. The attribute is not used by default. If it
    is not set, the <command>multipathd</command> daemon does not check for
    persistent reservation for newly discovered paths or reinstated paths.
   </para>
<screen>reservation_key &lt;<replaceable>reservation key</replaceable>&gt;</screen>
   <para>
    You can add the attribute to the <literal>defaults</literal> section or the
    <literal>multipaths</literal> section. For example:
   </para>
<screen>multipaths {
  multipath {
    wwid   XXXXXXXXXXXXXXXX
    alias      yellow
    reservation_key  0x123abc
  }
}</screen>
   <para>
    Set the <literal>reservation_key</literal> parameter for all mpath devices
    applicable for persistent management, then restart the
    <systemitem class="daemon">multipathd</systemitem> daemon by running the
    following command:
   </para>
<screen>sudo systemctl restart multipathd</screen>
   <para>
    After it is set up, you can specify the reservation key in the
    <command>mpathpersist</command> commands.
   </para>
   <bridgehead>Examples</bridgehead>
   <variablelist>
    <varlistentry>
     <term>mpathpersist --out --register --param-sark=123abc --prout-type=5 -d /dev/mapper/mpath9</term>
     <listitem>
      <para>
       Register the Service Action Reservation Key for the
       <filename>/dev/mapper/mpath9</filename> device.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>mpathpersisst -i -k -d /dev/mapper/mpath9</term>
     <listitem>
      <para>
       Read the Service Action Reservation Key for the
       <filename>/dev/mapper/mpath9</filename> device.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>mpathpersist --out --reserve --param-sark=123abc --prout-type=8 -d /dev/mapper/mpath9</term>
     <listitem>
      <para>
       Reserve the Service Action Reservation Key for the
       <filename>/dev/mapper/mpath9</filename> device.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>mpathpersist -i -s -d /dev/mapper/mpath9</term>
     <listitem>
      <para>
       Read the reservation status of the
       <filename>/dev/mapper/mpath9</filename> device.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.config">
  <title>Configuring the System for Multipathing</title>

  <para/>

  <sect2 xml:id="sec.multipath.configuration.start">
   <title>Enabling, Disabling, Starting and Stopping Multipath I/O Services</title>
   <para>
    To enable multipath services to start at boot time, run the following
    command:
   </para>
<screen>sudo systemctl enable multipathd</screen>
   <para>
    To manually start the service in the running system or to check
    its status, enter one of the following commands:
   </para>
   <screen>sudo systemctl start multipathd
sudo systemctl status multipathd</screen>
   <para>
    To stop the multipath services in the current session and to disable it, so
    it will not be started next time the system is booted, run the following
    commands:
   </para>
   <screen>sudo systemctl stop multipathd
sudo systemctl disable multipathd</screen>

   <important>
    <title>Rebuilding the <systemitem>initrd</systemitem> is Required</title>
    <para>
     Whenever you enable or disable the multipath services it is also required
     to rebuild the <systemitem>initrd</systemitem>, otherwise the system may
     not boot anymore. When enabling the multipath services, proceed as
     descibed in <xref linkend="sec.multipath.configuration.initrd"/>.
    </para>
    <para>
     If disabling the services, then revert the multipath related changes
     previously made to the <literal>force_drivers</literal> line in
     <filename>/etc/dracut.conf.d/01-dist.conf</filename>. Rebuild the initrd
     as described in the section mentioned above. Additionally and optionally,
     if you also want to make sure multipath devices do not get set up when
     starting multipath manually, add the following lines to the end of
     <filename>/etc/multipath.conf</filename> before rebuilding the initrd:
    </para>
    <screen>blacklist {
    wwid ".*"
}</screen>
   </important>
  </sect2>

  <sect2 xml:id="sec.multipath.configuration.sandevs">
   <title>Preparing SAN Devices for Multipathing</title>
   <para>
    Before configuring multipath I/O for your SAN devices, prepare the SAN
    devices, as necessary, by doing the following:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Configure and zone the SAN with the vendor’s tools.
     </para>
    </listitem>
    <listitem>
     <para>
      Configure permissions for host LUNs on the storage arrays with the
      vendor’s tools.
     </para>
    </listitem>
    <listitem>
     <para>
      Install the Linux HBA driver module. Upon module installation, the driver
      automatically scans the HBA to discover any SAN devices that have
      permissions for the host. It presents them to the host for further
      configuration.
     </para>
     <note>
      <title>No Native Multipathing</title>
      <para>
       Ensure that the HBA driver you are using does not have native
       multipathing enabled.
      </para>
     </note>
     <para>
      See the vendor’s specific instructions for more details.
     </para>
    </listitem>
    <listitem>
     <para>
      After the driver module is loaded, discover the device nodes assigned to
      specific array LUNs or partitions.
     </para>
    </listitem>
    <listitem>
     <para>
      If the SAN device will be used as the root device on the server, modify
      the timeout settings for the device as described in
      <xref linkend="sec.multipath.best_practice.san_timeout" xrefstyle="SectTitleOnPage"/>.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    If the LUNs are not seen by the HBA driver, <command>lsscsi </command>can
    be used to check whether the SCSI devices are seen correctly by the
    operating system. When the LUNs are not seen by the HBA driver, check the
    zoning setup of the SAN. In particular, check whether LUN masking is active
    and whether the LUNs are correctly assigned to the server.
   </para>
   <para>
    If the LUNs are seen by the HBA driver, but there are no corresponding
    block devices, additional kernel parameters are needed to change the SCSI
    device scanning behavior, such as to indicate that LUNs are not numbered
    consecutively. For information, see <citetitle>TID 3955167: Troubleshooting
    SCSI (LUN) Scanning Issues</citetitle> in the &suse; Knowledgebase at
    <link xlink:href="https://www.suse.com/support/kb/doc.php?id=3955167"/>.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.configuration.partitioning">
   <title>Partitioning Multipath Devices</title>
   <para>
    Partitioning devices that have multiple paths is not recommended, but it is
    supported. You can use the <command>kpartx</command> tool to create
    partitions on multipath devices without rebooting. You can also partition
    the device before you attempt to configure multipathing by using the
    Partitioner function in &yast;, or by using a third-party partitioning
    tool.
   </para>
   <para>
    Multipath devices are device-mapper devices. Modifying device-mapper
    devices with command line tools (such as parted, kpartx, or fdisk) works,
    but it does not necessarily generate the udev events that are required to
    update other layers. After you partition the device-mapper device, you
    should check the multipath map to make sure the device-mapper devices were
    mapped. If they are missing, you can remap the multipath devices or reboot
    the server to pick up all of the new partitions in the multipath map.
   </para>
   <para>
    The device-mapper device for a partition on a multipath device is not the
    same as an independent device. When you create an LVM logical volume using
    the whole device, you must specify a device that contains no partitions. If
    you specify a multipath partition as the target device for the LVM logical
    volume, LVM recognizes that the underlying physical device is partitioned
    and the create fails. If you need to subdivide a SAN device, you can carve
    LUNs on the SAN device and present each LUN as a separate multipath device
    to the server.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.configuration.initrd">
   <title>Configuring the Device Drivers in initrd for Multipathing</title>
   <para>
    The server must be manually configured to automatically load the device
    drivers for the controllers to which the multipath I/O devices are
    connected within the <literal>initrd</literal>. You need to add the
    necessary driver module to the variable <envar>force_drivers</envar> in the
    file <filename>/etc/dracut.conf.d/01-dist.conf</filename>.
   </para>
   <para>
    For example, if your system contains a RAID controller accessed by the
    <filename>hpsa</filename> driver and multipathed devices connected to a
    QLogic controller accessed by the driver qla23xx, this entry would look
    like:
   </para>
<screen>force_drivers+="hpsa qla23xx"</screen>
   <para>
    After changing <filename>/etc/dracut.conf.d/01-dist.conf</filename>, you
    must re-create the <literal>initrd</literal> on your system with the
    <command>dracut</command> <option>-f</option> command, then reboot for the
    changes to take effect.
   </para>
   <para>
    There are four SCSI hardware handlers available in the SCSI layer that can
    be used with DM-Multipath:
   </para>
   <simplelist>
    <member><filename>scsi_dh_alua</filename>
    </member>
    <member><filename>scsi_dh_rdac</filename>
    </member>
    <member><literal>scsi_dh_hp_sw</literal>
    </member>
    <member><literal>scsi_dh_emc</literal>
    </member>
   </simplelist>
   <para>
    Add the modules to the <filename>initrd</filename> image, then specify them
    in the <filename>/etc/multipath.conf</filename> file as hardware handler
    types <literal>alua</literal>, <literal>rdac</literal>,
    <literal>hp_sw</literal>, and <literal>emc</literal>. For example, add one
    of these lines for a device definition:
   </para>
<screen>hardware_handler "1 alua"
hardware_handler "1 rdac"
hardware_handler "1 hp_sw"
hardware_handler "1 emc"</screen>
   <para>
    To include the modules in the <filename>initrd</filename> image:
   </para>
   <procedure>
    <step>
     <para>
      Add the device handler modules to the <envar>force_drivers</envar>
      variable in <filename>/etc/dracut.conf.d/01-dist.conf</filename>:
     </para>
<screen>force_drivers+="alua rdac hp_sw emc"</screen>
    </step>
    <step>
     <para>
      Create a new <filename>initrd</filename>:
     </para>
<screen>sudo dracut /boot/initrd-<replaceable>KERNELVERSION</replaceable>-scsi-dh \
<replaceable>KERNELVERSION</replaceable></screen>
     <para>
      Replace <replaceable>KERNEL_VERSION</replaceable> with the version of the
      Kernel you want to use for the initrd, for example:
     </para>
<screen>sudo dracut /boot/initrd-3.12.28-4-default-scsi-dh 3.12.28-4-default</screen>
    </step>
    <step>
     <para>
      Make the initrd generated in the previous step the default initrd that is
      used for booting:
     </para>
<screen>cd /boot &amp;&amp; sudo ln -sf initrd-<replaceable>KERNELVERSION</replaceable>-scsi-dh  initrd</screen>
     <para>
      For example:
     </para>
<screen>cd /boot &amp;&amp; sudo ln -sf initrd-3.12.28-4-default-scsi-dh initrd</screen>
    </step>
    <step>
     <para>
      Restart the server.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.conf_file">
  <title>Creating or Modifying the /etc/multipath.conf File</title>

  <para>
   The <filename>/etc/multipath.conf</filename> file does not exist unless you
   create it. Default multipath device settings are applied automatically when
   the <command>multipathd</command> daemon runs unless you create the
   multipath configuration file and personalize the settings.
  </para>

  <important>
   <title>
    Testing and Permanently Applying Changes from
    <filename>/etc/multipath.conf</filename>
   </title>
   <para>
    Whenever you create or modify the <filename>/etc/multipath.conf</filename>
    file, the changes are not automatically applied when you save the
    file. This allows you to perform a dry run to verify your changes
    before they are committed. When you are satisfied with the revised
    settings, you can update the multipath maps as described in <xref
    linkend="sec.multipath.conf_file.apply"/>.
   </para>
  </important>

  <sect2 xml:id="sec.multipath.conf_file.create">
   <title>Creating the /etc/multipath.conf File</title>
   <procedure>
    <step>
     <para>
      Create an empty <filename>/etc/multipath.conf</filename> file with an
      editor of your choice.
     </para>
    </step>
    <step>
     <para>
      Ensure to add an appropriate <literal>device</literal> section for
      your SAN. Most vendors provide documentation on the proper setup of the
      <command>device</command> section. Note that different SANs require
      individual <literal>device</literal> sections.
     </para>
     <para>
      If you are using a storage subsystem that is automatically detected (see
      <xref linkend="sec.multipath.hardware.autodetect"
      xrefstyle="HeadingOnPage"/>), adding a <literal>device</literal> is not
      required&mdash;the default settings for this devaice will be applied in
      this case.
     </para>
    </step>
    <step>
     <para>
      Create a <literal>blacklist</literal> section containing all non-multpath
      devices of your machine. Refer to <xref
      linkend="sec.multipath.blacklist"/> for details.
     </para>
    </step>
    <step>
     <para>
      If required, add more sections to the configuration file. Refer to <xref
      linkend="sec.multipath.conf_file.sections"/> for a brief
      introduction. More details are available when running <command>man 5
      multipath.conf</command>.
     </para>
    </step>
    <step>
     <para>
      When finished, save <filename>/etc/multipath.conf</filename> and test
      your settings as described in <xref
      linkend="sec.multipath.conf_file.verify"/>.
     </para>
    </step>
    <step>
     <para>
      When you have successfully verified the configuration, apply it as
      described in <xref linkend="sec.multipath.conf_file.apply"/>.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.multipath.conf_file.sections">
   <title>Sections in the <filename>/etc/multipath.conf</filename> File</title>
   <para>
    The <filename>/etc/multipath.conf</filename> file is organized into the
    following sections. See <command>man 5 multipath.conf</command> for
    details.
   </para>
   <variablelist>
    <varlistentry>
     <term>defaults</term>
     <listitem>
      <para>
       General default settings for multipath I/0. These values are used if no
       values are given in the appropriate device or multipath sections. For
       information, see
       <xref linkend="sec.multipath.policies_default" xrefstyle="SectTitleOnPage"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>blacklist</term>
     <listitem>
      <para>
       Lists the device names to discard as not multipath candidates. Devices
       can be identified by their device node name
       (<literal>devnode</literal>), their WWID (<literal>wwid</literal>), or
       their vendor or product strings (<literal>device</literal>). You
       typically ignore non-multipathed devices, such as hpsa, fd, hd, md, dm,
       sr, scd, st, ram, raw, loop. For more information and examples, see
       <xref linkend="sec.multipath.blacklist" xrefstyle="HeadingOnPage"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>blacklist_exceptions</term>
     <listitem>
      <para>
       Lists the device names of devices to be treated as multipath candidates
       even if they are on the blacklist. Devices can be identified by their
       device node name (<literal>devnode</literal>), their WWID
       (<literal>wwid</literal>), or their vendor or product strings
       (<literal>device</literal>). You must specify the excepted devices by
       using the same keyword that you used in the blacklist. For example, if
       you used the <literal>devnode</literal> keyword for devices in the
       blacklist, you use the <literal>devnode</literal> keyword to exclude
       some devices in the blacklist exceptions. It is not possible to
       blacklist devices by using the <literal>devnode</literal> keyword and to
       exclude some of them by using the <literal>wwid</literal> keyword. For
       more information and examples, see
       <xref linkend="sec.multipath.blacklist" xrefstyle="HeadingOnPage"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>multipaths</term>
     <listitem>
      <para>
       Specifies settings for individual multipath devices. Except for settings
       that do not support individual settings, these values overwrite what is
       specified in the <literal>defaults</literal> and
       <literal>devices</literal> sections of the configuration file.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>devices</term>
     <listitem>
      <para>
       Specifies settings for individual storage controllers. These values
       overwrite values specified in the <filename>defaults</filename> section
       of the configuration file. If you use a storage array that is not
       supported by default, you can create a <literal>devices</literal>
       subsection to specify the default settings for it. These values can be
       overwritten by settings for individual multipath devices if the keyword
       allows it.
      </para>
      <para>
       For information, see the following:
      </para>
      <itemizedlist mark="bullet" spacing="normal">
       <listitem>
        <para>
         <xref linkend="sec.multipath.names" xrefstyle="SectTitleOnPage"/>
        </para>
       </listitem>
       <listitem>
        <para>
         <xref linkend="sec.multipath.best_practice.zseries" xrefstyle="SectTitleOnPage"/>
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="sec.multipath.conf_file.verify">
   <title>Verifying the Multipath Setup in the /etc/multipath.conf File</title>
   <para>
    Whenever you create or modify the <filename>/etc/multipath.conf</filename>
    file, the changes are not automatically applied when you save the file. You
    can perform a <quote>dry run</quote> of the setup to verify the multipath
    setup before you update the multipath maps.
   </para>
   <para>
    At the server command prompt, enter
   </para>
<screen>sudo multipath -v2 -d</screen>
   <para>
    This command scans the devices, then displays what the setup would look
    like if you commit the changes. It is assumed that the
    <systemitem class="daemon">multipathd</systemitem> daemon is already
    running with the old (or default) multipath settings when you modify the
    <filename>/etc/multipath.conf</filename> file and perform the dry run. If
    the changes are acceptable, continue with the next step.
   </para>
   <para>
    The output is similar to the following:
   </para>
<screen>26353900f02796769
[size=127 GB]
[features="0"]
[hwhandler="1    emc"]

\_ round-robin 0 [first]
  \_ 1:0:1:2 sdav 66:240  [ready ]
  \_ 0:0:1:2 sdr  65:16   [ready ]

\_ round-robin 0
  \_ 1:0:0:2 sdag 66:0    [ready ]
  \_ 0:0:0:2 sdc   8:32   [ready ]
</screen>
   <para>
    Paths are grouped into priority groups. Only one priority group is in
    active use at a time. To model an active/active configuration, all paths
    end in the same group. To model an active/passive configuration, the paths
    that should not be active in parallel are placed in several distinct
    priority groups. This normally happens automatically on device discovery.
   </para>
   <para>
    The output shows the order, the scheduling policy used to balance I/O
    within the group, and the paths for each priority group. For each path, its
    physical address (host:bus:target:lun), device node name, major:minor
    number, and state is shown.
   </para>
   <para>
    By using a verbosity level of -v3 in the dry run, you can see all detected
    paths, multipaths, and device maps. Both WWID and device node blacklisted
    devices are displayed.
   </para>
   <para>
    The following is an example of -v3 output on a 64-bit &slsa; 11 SP2 server
    with two Qlogic HBAs connected to a Xiotech Magnitude 3000 SAN. Some
    multiple entries have been omitted to shorten the example.
   </para>
<screen>&prompt.user;sudo multipath -v3 d
dm-22: device node name blacklisted
&lt; content omitted &gt;
loop7: device node name blacklisted
&lt; content omitted &gt;
md0: device node name blacklisted
&lt; content omitted &gt;
dm-0: device node name blacklisted
sdf: not found in pathvec
sdf: mask = 0x1f
sdf: dev_t = 8:80
sdf: size = 105005056
sdf: subsystem = scsi
sdf: vendor = XIOtech
sdf: product = Magnitude 3D
sdf: rev = 3.00
sdf: h:b:t:l = 1:0:0:2
sdf: tgt_node_name = 0x202100d0b2028da
sdf: serial = 000028DA0014
sdf: getuid= "/lib/udev/scsi_id --whitelisted --device=/dev/%n" (config file default)
sdf: uid = 200d0b2da28001400 (callout)
sdf: prio = const (config file default)
sdf: const prio = 1
[...]
ram15: device node name blacklisted
[...]
===== paths list =====
uuid              hcil    dev dev_t pri dm_st  chk_st  vend/prod/rev
200d0b2da28001400 1:0:0:2 sdf 8:80  1   [undef][undef] XIOtech,Magnitude 3D
200d0b2da28005400 1:0:0:1 sde 8:64  1   [undef][undef] XIOtech,Magnitude 3D
200d0b2da28004d00 1:0:0:0 sdd 8:48  1   [undef][undef] XIOtech,Magnitude 3D
200d0b2da28001400 0:0:0:2 sdc 8:32  1   [undef][undef] XIOtech,Magnitude 3D
200d0b2da28005400 0:0:0:1 sdb 8:16  1   [undef][undef] XIOtech,Magnitude 3D
200d0b2da28004d00 0:0:0:0 sda 8:0   1   [undef][undef] XIOtech,Magnitude 3D
params = 0 0 2 1 round-robin 0 1 1 8:80 1000 round-robin 0 1 1 8:32 1000
status = 2 0 0 0 2 1 A 0 1 0 8:80 A 0 E 0 1 0 8:32 A 0
sdf: mask = 0x4
sdf: path checker = directio (config file default)
directio: starting new request
directio: async io getevents returns 1 (errno=Success)
directio: io finished 4096/0
sdf: state = 2
[...]</screen>
  </sect2>

  <sect2 xml:id="sec.multipath.conf_file.apply">
   <title>Applying the /etc/multipath.conf File Changes to Update the Multipath Maps</title>
   <para>
    Changes to the <filename>/etc/multipath.conf</filename> file cannot take
    effect when <command>multipathd</command> is running. After you make
    changes, save and close the file, then do the following to apply the
    changes and update the multipath maps:
   </para>
   <procedure>
    <step>
     <para>
      Stop the <systemitem class="daemon">multipathd</systemitem> service:
     </para>
<screen>sudo systemctl stop multipathd</screen>
    </step>
    <step>
     <para>
      Clear old multipath bindings by entering
     </para>
<screen>sudo /sbin/multipath -F</screen>
    </step>
    <step>
     <para>
      Create new multipath bindings by entering
     </para>
<screen>sudo /sbin/multipath -v2 -l</screen>
    </step>
    <step>
     <para>
      Restart the <systemitem class="daemon">multipathd</systemitem> service:
     </para>
<screen>sudo systemctl start multipathd</screen>
    </step>
    <step>
     <para>
      Run <command>dracut -f</command> to re-create the
      <filename>initrd</filename> image on your system, then reboot for the
      changes to take effect.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.policies_default">
  <title>Configuring Default Policies for Polling, Queuing, and Failback</title>

  <para>
   The goal of multipath I/O is to provide connectivity fault tolerance between
   the storage system and the server. The desired default behavior depends on
   whether the server is a stand-alone server or a node in a high-availability
   cluster.
  </para>

  <para>
   When you configure multipath I/O for a stand-alone server, the
   <literal>no_path_retry</literal> setting protects the server operating
   system from receiving I/O errors as long as possible. It queues messages
   until a multipath failover occurs and provides a healthy connection.
  </para>

  <para>
   When you configure multipath I/O for a node in a high-availability cluster,
   you want multipath to report the I/O failure to trigger the resource
   failover instead of waiting for a multipath failover to be resolved. In
   cluster environments, you must modify the <literal>no_path_retry
   </literal>setting so that the cluster node receives an I/O error in relation
   to the cluster verification process (recommended to be 50% of the heartbeat
   tolerance) if the connection is lost to the storage system. In addition, you
   want the multipath I/O fallback to be set to manual to avoid a ping-pong of
   resources because of path failures.
  </para>

  <para>
   The <filename>/etc/multipath.conf</filename> file should contain a
   <command>defaults</command> section where you can specify default behaviors
   for polling, queuing, and failback. If the field is not otherwise specified
   in a <command>device</command> section, the default setting is applied for
   that SAN configuration.
  </para>

  <para>
   The following are the compiled default settings. They will be used unless
   you overwrite these values by creating and configuring a personalized
   <filename>/etc/multipath.conf</filename> file.
  </para>

<screen>defaults {
  verbosity 2
#  udev_dir is deprecated in SLES 11 SP3
#  udev_dir              /dev
  polling_interval      5
#  path_selector default value is service-time in SLES 11 SP3
#  path_selector         "round-robin 0"
  path selector         "service-time 0"
  path_grouping_policy  failover
#  getuid_callout is deprecated in SLES 11 SP3 and replaced with uid_attribute
#  getuid_callout        "/lib/udev/scsi_id --whitelisted --device=/dev/%n"
#  uid_attribute is new in SLES 11 SP3
  uid_attribute         "ID_SERIAL"
  prio                  "const"
  prio_args             ""
  features              "0"
  path_checker          "directio"
  alias_prefix          "mpath"
  rr_min_io_rq          1
  max_fds               "max"
  rr_weight             "uniform"
  queue_without_daemon  "yes"
  flush_on_last_del     "no"
  user_friendly_names   "no"
  fast_io_fail_tmo      5
  bindings_file         "/etc/multipath/bindings"
  wwids_file            "/etc/multipath/wwids"
  log_checker_err       "always"

  retain_attached_hw_handler  "no"
  detect_prio           "no"
  failback              "manual"
  no_path_retry         "fail"
  }</screen>

  <para>
   For information about setting the polling, queuing, and failback policies,
   see the following parameters in
   <xref linkend="sec.multipath.policies_failover" xrefstyle="SectTitleOnPage"/>:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <xref linkend="polling_interval" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="no_path_retry" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="failback" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   If you modify the settings in the <literal>defaults</literal> section, the
   changes are not applied until you update the multipath maps, or until the
   multipathd daemon is restarted, such as at system restart.
  </para>
 </sect1>
 <sect1 xml:id="sec.multipath.blacklist">
  <title>Blacklisting Non-Multipath Devices</title>

  <para>
   The <filename>/etc/multipath.conf</filename> file should contain a
   <command>blacklist</command> section where all non-multipath devices are
   listed. You can blacklist devices by WWID (<literal>wwid</literal> keyword),
   device name (<literal>devnode</literal> keyword), or device type
   (<literal>device</literal> section). You can also use the
   <literal>blacklist_exceptions</literal> section to enable multipath for some
   devices that are blacklisted by the regular expressions used in the
   <literal>blacklist</literal> section.
  </para>

  <para>
   You typically ignore non-multipathed devices, such as hpsa, fd, hd, md, dm,
   sr, scd, st, ram, raw, and loop. For example, local IDE hard disks and flash
   disks do not normally have multiple paths. If you want
   <command>multipath</command> to ignore single-path devices, put them in the
   <command>blacklist</command> section.
  </para>

  <note>
   <title>Compatibility</title>
   <para>
    The keyword <literal>devnode_blacklist</literal> has been deprecated and
    replaced with the keyword <literal>blacklist</literal>.
   </para>
   <para>
    With &sls; 12 the glibc-provided regular expressions are used. To match an
    arbitrary string, you must now use <literal>".*"</literal> rather than
    <literal>"*"</literal>.
   </para>
  </note>

  <para>
   For example, to blacklist local devices and all arrays from the
   <filename>hpsa</filename> driver from being managed by multipath, the
   <command>blacklist</command> section looks like this:
  </para>

<screen>blacklist {
      wwid "26353900f02796769"
      devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"
      devnode "^sd[a-z][0-9]*"
}</screen>

  <para>
   You can also blacklist only the partitions from a driver instead of the
   entire array. For example, you can use the following regular expression to
   blacklist only partitions from the cciss driver and not the entire array:
  </para>

<screen>blacklist {
      devnode "^cciss!c[0-9]d[0-9]*[p[0-9]*]"
}</screen>

  <para>
   You can blacklist by specific device types by adding a
   <literal>device</literal> section in the blacklist, and using the
   <literal>vendor</literal> and <literal>product</literal> keywords.
  </para>

<screen>blacklist {
      device {
           vendor  "DELL"
           product ".*"
       }
}</screen>

  <para>
   You can use a <literal>blacklist_exceptions</literal> section to enable
   multipath for some devices that were blacklisted by the regular expressions
   used in the <literal>blacklist</literal> section. You add exceptions by WWID
   (<literal>wwid</literal> keyword), device name (<literal>devnode</literal>
   keyword), or device type (<literal>device</literal> section). You must
   specify the exceptions in the same way that you blacklisted the
   corresponding devices. That is, <literal>wwid</literal> exceptions apply to
   a <literal>wwid</literal> blacklist, <literal>devnode</literal> exceptions
   apply to a <literal>devnode</literal> blacklist, and device type exceptions
   apply to a device type blacklist.
  </para>

  <para>
   For example, you can enable multipath for a desired device type when you
   have different device types from the same vendor. Blacklist all of the
   vendor’s device types in the <literal>blacklist</literal> section, and
   then enable multipath for the desired device type by adding a
   <literal>device</literal> section in a
   <literal>blacklist_exceptions</literal> section.
  </para>

<screen>blacklist {
      devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st|sda)[0-9]*"
      device {
           vendor  "DELL"
           product ".*"
       }
}

blacklist_exceptions {
      device {
           vendor  "DELL"
           product "MD3220i"
       }
}</screen>

  <para>
   You can also use the blacklist_exceptions to enable multipath only for
   specific devices. For example:
  </para>

<screen>blacklist {
      wwid ".*"
}

blacklist_exceptions {
        wwid "3600d0230000000000e13955cc3751234"
        wwid "3600d0230000000000e13955cc3751235"
}</screen>

  <para>
   After you modify the <filename>/etc/multipath.conf</filename> file, you must
   run <command>dracut</command> <option>-f</option> to re-create the
   <filename>initrd</filename> on your system, then restart the server for the
   changes to take effect.
  </para>

  <para>
   After you do this, the local devices should no longer be listed in the
   multipath maps when you issue the <command>multipath -ll</command> command.
  </para>
 </sect1>
 <sect1 xml:id="sec.multipath.names">
  <title>Configuring User-Friendly Names or Alias Names</title>

  <para>
   A multipath device can be identified by its WWID, by a user-friendly name,
   or by an alias that you assign for it. Device node names in the form of
   <filename>/dev/sdn</filename> and <filename>/dev/dm-n</filename> can change
   on reboot and might be assigned to different devices each time. A device’s
   WWID, user-friendly name, and alias name persist across reboots, and are the
   preferred way to identify the device.
  </para>

  <important>
   <title>Using Persistent Names is Recommended</title>
   <para>
    Because device node names in the form of <filename>/dev/sdn</filename> and
    <filename>/dev/dm-n</filename> can change on reboot, referring to multipath
    devices by their WWID is preferred. You can also use a user-friendly name
    or alias that is mapped to the WWID to identify the device uniquely across
    reboots.
   </para>
  </important>

  <para>
   The following table describes the types of device names that can be used for
   a device in the <filename>/etc/multipath.conf</filename> file. For an
   example of <filename>multipath.conf</filename> settings, see the
   <filename>/usr/share/doc/packages/multipath-tools/multipath.conf.synthetic</filename>
   file.
  </para>

  <table>
   <title>Comparison of Multipath Device Name Types</title>
   <tgroup cols="2">
    <colspec colnum="1" colname="1" colwidth="1667*"/>
    <colspec colnum="2" colname="2" colwidth="8334*"/>
    <thead>
     <row>
      <entry>
       <para>
        Name Types
       </para>
      </entry>
      <entry>
       <para>
        Description
       </para>
      </entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry>
       <para>
        WWID (default)
       </para>
      </entry>
      <entry>
       <para>
        The serial WWID (Worldwide Identifier) is an identifier for the
        multipath device that is guaranteed to be globally unique and
        unchanging. The default name used in multipathing is the ID of the
        logical unit as found in the <filename>/dev/disk/by-id</filename>
        directory. For example, a device with the WWID of
        <literal>3600508e0000000009e6baa6f609e7908</literal> is listed as
        <filename>/dev/disk/by-id/scsi-3600508e0000000009e6baa6f609e7908</filename>.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        User-friendly
       </para>
      </entry>
      <entry>
       <para>
        The Device Mapper Multipath device names in the
        <filename>/dev/mapper</filename> directory also reference the ID of the
        logical unit. These multipath device names are user-friendly names in
        the form of
        <filename>/dev/mapper/mpath<replaceable>N</replaceable></filename>,
        such as <filename>/dev/mapper/mpath0</filename>. The names are unique
        and persistent because they use the
        <filename>/var/lib/multipath/bindings</filename> file to track the
        association between the UUID and user-friendly names.
       </para>
      </entry>
     </row>
     <row>
      <entry>
       <para>
        Alias
       </para>
      </entry>
      <entry>
       <para>
        An alias name is a globally unique name that the administrator provides
        for a multipath device. Alias names override the WWID and the
        user-friendly
        <filename>/dev/mapper/mpath<replaceable>N</replaceable></filename>
        names.
       </para>
       <para>
        If you are using user_friendly_names, do not set the alias to
        mpath<replaceable>N</replaceable> format. This may conflict with an
        automatically assigned user-friendly name, and give you incorrect
        device node names.
       </para>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </table>

  <para>
   The global multipath <literal>user_friendly_names</literal> option in the
   <filename>/etc/multipath.conf</filename> file is used to enable or disable
   the use of user-friendly names for multipath devices. If it is set to
   <literal>no</literal> (the default), multipath uses the WWID as the name of
   the device. If it is set to <literal>yes</literal>, multipath uses the
   <filename>/var/lib/multipath/bindings</filename> file to assign a persistent
   and unique name to the device in the form of
   <filename>mpath&lt;<replaceable>n</replaceable>&gt;</filename> in the
   <filename>/dev/mapper </filename>directory. The <literal>bindings
   file</literal> option in the <literal>/etc/multipath.conf</literal> file can
   be used to specify an alternate location for the
   <filename>bindings</filename> file.
  </para>

  <para>
   The global multipath <literal>alias</literal> option in the
   <filename>/etc/multipath.conf</filename> file is used to explicitly assign a
   name to the device. If an alias name is set up for a multipath device, the
   alias is used instead of the WWID or the user-friendly name.
  </para>

  <para>
   Using the <literal>user_friendly_names</literal> option can be problematic
   in the following situations:
  </para>

  <variablelist>
   <varlistentry>
    <term>Root Device Is Using Multipath:</term>
    <listitem>
     <para>
      If the system root device is using multipath and you use the
      <literal>user_friendly_names</literal> option, the user-friendly settings
      in the <filename>/var/lib/multipath/bindings</filename> file are included
      in the <filename>initrd</filename>. If you later change the storage
      setup, such as by adding or removing devices, there is a mismatch between
      the bindings setting inside the <filename>initrd</filename> and the
      bindings settings in <filename>/var/lib/multipath/bindings</filename>.
     </para>
     <warning>
      <title>Binding Mismatches</title>
      <para>
       A bindings mismatch between <filename>initrd</filename> and
       <filename>/var/lib/multipath/bindings</filename> can lead to a wrong
       assignment of mount points to devices, which can result in file system
       corruption and data loss.
      </para>
     </warning>
     <para>
      To avoid this problem, we recommend that you use the default WWID
      settings for the system root device. You should not use aliases for the
      system root device. Because the device name would differ, using an alias
      causes you to lose the ability to seamlessly switch off multipathing via
      the kernel command line.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Mounting /var from Another Partition:</term>
    <listitem>
     <para>
      The default location of the <literal>user_friendly_names</literal>
      configuration file is <filename>/var/lib/multipath/bindings</filename>.
      If the <filename>/var</filename> data is not located on the system root
      device but mounted from another partition, the
      <filename>bindings</filename> file is not available when setting up
      multipathing.
     </para>
     <para>
      Ensure that the <filename>/var/lib/multipath/bindings</filename> file is
      available on the system root device and multipath can find it. For
      example, this can be done as follows:
     </para>
     <orderedlist spacing="normal">
      <listitem>
       <para>
        Move the <filename>/var/lib/multipath/bindings</filename> file to
        <filename>/etc/multipath/bindings</filename>.
       </para>
      </listitem>
      <listitem>
       <para>
        Set the <literal>bindings_file</literal> option in the
        <literal>defaults</literal> section of
        /<filename>etc/multipath.conf</filename> to this new location. For
        example:
       </para>
<screen>
defaults {
               user_friendly_names yes
               bindings_file "/etc/multipath/bindings"
}
</screen>
      </listitem>
     </orderedlist>
    </listitem>
   </varlistentry>

   <varlistentry>
    <term>Multipath Is in the initrd:</term>
    <listitem>
     <para>
      Even if the system root device is not on multipath, it is possible for
      multipath to be included in the <filename>initrd</filename>. For example,
      this can happen if the system root device is on LVM. If you use the
      <literal>user_friendly_names</literal> option and multipath is in the
      <filename>initrd</filename>, you should boot with the parameter
      <command>multipath=off</command> to avoid problems.
     </para>
     <para>
      This disables multipath only in the <filename>initrd</filename> during
      system boots. After the system boots, the
      <filename>boot.multipath</filename> and <filename>multipathd</filename>
      boot scripts can activate multipathing.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Multipathing in HA Clusters:</term>
    <listitem>
     <para>
      See <xref linkend="sec.multipath.names.ha"/> for details.
     </para>
    </listitem>
    </varlistentry>
  </variablelist>

  <para>
   To enable user-friendly names or to specify aliases:
  </para>

  <procedure>
   <step>
    <para>
     Open the <filename>/etc/multipath.conf</filename> file in a text editor
     with &rootuser; privileges.
    </para>
   </step>
   <step>
    <para>
     (Optional) Modify the location of the
     <filename>/var/lib/multipath/bindings</filename> file.
    </para>
    <para>
     The alternate path must be available on the system root device where
     multipath can find it.
    </para>
    <substeps performance="required">
     <step>
      <para>
       Move the <filename>/var/lib/multipath/bindings</filename> file to
       <filename>/etc/multipath/bindings</filename>.
      </para>
     </step>
     <step>
      <para>
       Set the <literal>bindings_file</literal> option in the
       <literal>defaults</literal> section of
       /<filename>etc/multipath.conf</filename> to this new location. For
       example:
      </para>
<screen>
defaults {
          user_friendly_names yes
          bindings_file "/etc/multipath/bindings"
}
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     (Optional, not recommended) Enable user-friendly names:
    </para>
    <substeps performance="required">
     <step>
      <para>
       Uncomment the <literal>defaults</literal> section and its ending
       bracket.
      </para>
     </step>
     <step>
      <para>
       Uncomment the <literal>user_friendly_names option</literal>, then change
       its value from No to Yes.
      </para>
      <para>
       For example:
      </para>
<screen>## Use user-friendly names, instead of using WWIDs as names.
defaults {
  user_friendly_names yes
}</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     (Optional) Specify your own names for devices by using the
     <command>alias</command> option in the <command>multipath</command>
     section.
    </para>
    <para>
     For example:
    </para>
<screen>## Use alias names, instead of using WWIDs as names.
multipaths {
       multipath {
               wwid           36006048000028350131253594d303030
               alias             blue1
       }
       multipath {
               wwid           36006048000028350131253594d303041
               alias             blue2
       }
       multipath {
               wwid           36006048000028350131253594d303145
               alias             yellow1
       }
       multipath {
               wwid           36006048000028350131253594d303334
               alias             yellow2
       }
}
</screen>
    <important>
     <title>WWWID Compared to WWN</title>
     <para>
      When you define device aliases in the
      <filename>/etc/multipath.conf</filename> file, ensure that you use each
      device’s WWID (such as
      <filename>3600508e0000000009e6baa6f609e7908</filename>) and not its WWN,
      which replaces the first character of a device ID with
      <filename>0x</filename>, such as
      <filename>0x600508e0000000009e6baa6f609e7908</filename>.
     </para>
    </important>
   </step>
   <step>
    <para>
     Save your changes, then close the file.
    </para>
    <para>
     The changes are not applied until you update the multipath maps, or until
     the <systemitem class="daemon">multipathd</systemitem> daemon is
     restarted.
    </para>
   </step>
  </procedure>

  <para>
   If you want to use the entire LUN directly (for example, if you are using
   the SAN features to partition your storage), you can use the
   <filename>/dev/disk/by-id/xxx</filename> names for <command>mkfs</command>,
   <command>fstab</command>, your application, and so on. Partitioned devices
   have <filename>_part&lt;n&gt;</filename> appended to the device name, such
   as <filename>/dev/disk/by-id/xxx_part1</filename>.
  </para>

  <para>
   In the <filename>/dev/disk/by-id</filename> directory, the multipath-mapped
   devices are represented by the device’s <filename>dm-uuid*</filename> name
   or alias name (if you assign an alias for it in the
   <filename>/etc/multipath.conf</filename> file). The
   <filename>scsi-</filename> and <filename>wwn-</filename> device names
   represent physical paths to the devices.
  </para>

  <sect2 xml:id="sec.multipath.names.ha">
   <title>Multipath Device Names in HA Clusters</title>
   <para>
    Ensure that multipath devices have the same name across all devices by
    doing the following:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Use UUID and alias names to ensure that multipath device names are
      consistent across all nodes in the cluster. Alias names must be unique
      across all nodes. Copy the <filename>/etc/multipath.conf </filename>file
      from the node to the <filename>/etc/</filename> directory for all of the
      other nodes in the cluster.
     </para>
    </listitem>
    <listitem>
     <para>
      When using links to multipath-mapped devices, ensure that you specify the
      <filename>dm-uuid*</filename> name or alias name in the
      <filename>/dev/disk/by-id</filename> directory, and not a fixed path
      instance of the device. For information, see
      <xref linkend="sec.multipath.names" xrefstyle="SectTitleOnPage"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      Set the <literal>user_friendly_names</literal> configuration option to
      <literal>no</literal> to disable it. A user-friendly name is unique to a
      node, but a device might not be assigned the same user-friendly name on
      every node in the cluster.
     </para>
    </listitem>
   </itemizedlist>
   <note>
    <title>User-Friendly Names</title>
    <para>
     If you really need to use user-friendly names, you can force the
     system-defined user-friendly names to be consistent across all nodes in
     the cluster by doing the following:
    </para>
    <procedure>
     <step>
      <para>
       In the <filename>/etc/multipath.conf</filename> file on one node:
      </para>
      <substeps>
       <step>
        <para>
         Set the <literal>user_friendly_names</literal> configuration option to
         <literal>yes</literal> to enable it.
        </para>
        <para>
         Multipath uses the <filename>/var/lib/multipath/bindings</filename>
         file to assign a persistent and unique name to the device in the form
         of <filename>mpath&lt;<replaceable>n</replaceable>&gt;</filename> in
         the <filename>/dev/mapper </filename>directory.
        </para>
       </step>
       <step>
        <para>
         (Optional) Set the <literal>bindings_file</literal> option in the
         <literal>defaults</literal> section of the
         <literal>/etc/multipath.conf</literal> file to specify an alternate
         location for the <filename>bindings</filename> file.
        </para>
        <para>
         The default location is
         <filename>/var/lib/multipath/bindings</filename>.
        </para>
       </step>
      </substeps>
     </step>
     <step>
      <para>
       Set up all of the multipath devices on the node.
      </para>
     </step>
     <step>
      <para>
       Copy the <filename>/etc/multipath.conf</filename> file from the node to
       the <filename>/etc/</filename> directory of all the other nodes in the
       cluster.
      </para>
     </step>
     <step>
      <para>
       Copy the <filename>bindings</filename> file from the node to the
       <filename>bindings_file</filename> path on all of the other nodes in the
       cluster.
      </para>
     </step>
    </procedure>
   </note>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.policies_failover">
  <title>Configuring Path Failover Policies and Priorities</title>

  <para>
   In a Linux host, when there are multiple paths to a storage controller, each
   path appears as a separate block device, and results in multiple block
   devices for single LUN. The Device Mapper Multipath service detects multiple
   paths with the same LUN ID, and creates a new multipath device with that ID.
   For example, a host with two HBAs attached to a storage controller with two
   ports via a single unzoned Fibre Channel switch sees four block devices:
   <filename>/dev/sda</filename>, <filename>/dev/sdb</filename>,
   <filename>/dev/sdc</filename>, and <filename>/dev/sdd</filename>. The Device
   Mapper Multipath service creates a single block device,
   <filename>/dev/mpath/mpath1</filename>, that reroutes I/O through those four
   underlying block devices.
  </para>

  <para>
   This section describes how to specify policies for failover and configure
   priorities for the paths. Note that changes to
   <filename>/etc/multipath.conf</filename> are not applied until you update
   the multipath maps, or until the
   <systemitem class="daemon">multipathd</systemitem> daemon is restarted.
  </para>

  <sect2 xml:id="sec.multipath.policies_failover.path">
   <title>Configuring the Path Failover Policies</title>
   <para>
    Use the <command>multipath</command> command with the <option>-p</option>
    option to set the path failover policy:
   </para>
<screen>sudo multipath <replaceable>devicename</replaceable> -p <replaceable>policy</replaceable></screen>
   <para>
    Replace <replaceable>policy</replaceable> with one of the following policy
    options:
   </para>
   <table>
    <title>Group Policy Options for the multipath -p Command</title>
    <tgroup cols="2">
     <colspec colnum="1" colname="1" colwidth="2381*"/>
     <colspec colnum="2" colname="2" colwidth="7620*"/>
     <thead>
      <row>
       <entry>
        <para>
         Policy Option
        </para>
       </entry>
       <entry>
        <para>
         Description
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         failover
        </para>
       </entry>
       <entry>
        <para>
         (Default) One path per priority group.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         multibus
        </para>
       </entry>
       <entry>
        <para>
         All paths in one priority group.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         group_by_serial
        </para>
       </entry>
       <entry>
        <para>
         One priority group per detected serial number.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         group_by_prio
        </para>
       </entry>
       <entry>
        <para>
         One priority group per path priority value. Priorities are determined
         by callout programs specified as a global, per-controller, or
         per-multipath option in the <filename>/etc/multipath.conf</filename>
         configuration file.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         group_by_node_name
        </para>
       </entry>
       <entry>
        <para>
         One priority group per target node name. Target node names are fetched
         in the<filename> /sys/class/fc_transport/target*/node_name</filename>
         location.
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </sect2>

  <sect2 xml:id="sec.multipath.policies_failover.prio">
   <title>Configuring Failover Priorities</title>
   <para>
    You must manually enter the failover priorities for the device in the
    <filename>/etc/multipath.conf</filename> file. Examples for all settings
    and options can be found in the
    <filename>/usr/share/doc/packages/multipath-tools/multipath.conf.annotated</filename>
    file.
   </para>
   <sect3 xml:id="sec.multipath.policies_failover.prio.info">
    <title>Understanding Priority Groups and Attributes</title>
    <para>
     A <emphasis>priority group</emphasis> is a collection of paths that go to
     the same physical LUN. By default, I/O is distributed in a round-robin
     fashion across all paths in the group. The <command>multipath</command>
     command automatically creates priority groups for each LUN in the SAN
     based on the <literal>path_grouping_policy</literal> setting for that SAN.
     The <command>multipath</command> command multiplies the number of paths in
     a group by the group’s priority to determine which group is the primary.
     The group with the highest calculated value is the primary. When all paths
     in the primary group are failed, the priority group with the next highest
     value becomes active.
    </para>
    <para>
     A <emphasis>path priority</emphasis> is an integer value assigned to a
     path. The higher the value, the higher the priority. An external program
     is used to assign priorities for each path. For a given device, the paths
     with the same priorities belong to the same priority group.
    </para>
    <para>
     The <literal>prio</literal> setting is used in the
     <literal>defaults{}</literal> or <literal>devices{}</literal> section of
     the <filename>/etc/multipath.conf</filename> file. It is silently ignored
     when it is specified for an individual <literal>multipath</literal>
     definition in the <literal>multipaths{)</literal> section. The
     <literal>prio</literal> line specifies the prioritizer. If the prioritizer
     requires an argument, you specify the argument by using the
     <literal>prio_args</literal> keyword on a second line.
    </para>
    <bridgehead>PRIO Settings for the Defaults or Devices Sections</bridgehead>
    <variablelist>
     <varlistentry>
      <term>prio</term>
      <listitem>
       <para>
        Specifies the prioritizer program to call to obtain a path priority
        value. Weights are summed for each path group to determine the next
        path group to use in case of failure.
       </para>
       <para>
        Use the <literal>prio_args</literal> keyword to specify arguments if
        the specified prioritizer requires arguments.
       </para>
       <para>
        If no <literal>prio</literal> keyword is specified, all paths are
        equal. The default setting is <literal>const</literal> with a
        <literal>prio_args</literal> setting with no value.
       </para>
<screen>prio "const"
prio_args ""</screen>
       <para>
        Example prioritizer programs include:
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="2907*"/>
         <colspec colnum="2" colname="2" colwidth="7096*"/>
         <thead>
          <row>
           <entry>
            <para>
             Prioritizer Program
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal>alua</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates path priorities based on the SCSI-3 ALUA settings.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>const</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates the same priority for all paths.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>emc</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates the path priority for EMC arrays.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>hdc</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates the path priority for Hitachi HDS Modular storage
             arrays.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>hp_sw</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates the path priority for Compaq/HP controller in
             active/standby mode.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>ontap</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates the path priority for NetApp arrays.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>random</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates a random priority for each path.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>rdac</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates the path priority for LSI/Engenio RDAC controller.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>weightedpath</literal>
            </para>
           </entry>
           <entry>
            <para>
             Generates the path priority based on the weighted values you
             specify in the arguments for <literal>prio_args</literal>, such
             as:
            </para>
<screen>[hbtl|devname] <replaceable>regex1</replaceable> <replaceable>prio1</replaceable> <replaceable>regex2</replaceable> <replaceable>prio2</replaceable>...</screen>
            <para>
             The <literal>hbtl regex</literal> argument format uses the SCSI
             <literal>H:B:T:L</literal> notation (such as
             <literal>1:0:.:.</literal> and <literal>*:0:0:.</literal>) with a
             weight value, where H, B, T, L are the host, bus, target, and LUN
             IDs for a device. For example:
            </para>
<screen>prio "weightedpath"
prio_args "hbtl 1:.:.:. 2 4:.:.:. 4"</screen>
            <para>
             The <literal>devname</literal> regular expression argument format
             uses a device node name with a weight value for each device. For
             example:
            </para>
<screen>prio "weightedpath"
prio_args "devname sda 50 sde 10 sdc 50 sdf 10"</screen>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><literal>prio_args</literal>
      </term>
      <listitem>
       <para>
        Specifies the arguments for the specified prioritizer program that
        requires arguments. Most <literal>prio</literal> programs do not need
        arguments.
       </para>
       <para>
        There is no default. The value depends on the <literal>prio</literal>
        setting and whether the prioritizer requires arguments.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <bridgehead>Multipath Attributes</bridgehead>
    <para>
     Multipath attributes are used to control the behavior of multipath I/O for
     devices. You can specify attributes as defaults for all multipath devices.
     You can also specify attributes that apply only to a given multipath
     device by creating an entry for that device in the
     <literal>multipaths</literal> section of the multipath configuration file.
    </para>
    <variablelist>
     <varlistentry>
      <term><literal>user_friendly_names</literal>
      </term>
      <listitem>
       <para>
        Specifies whether to use world-wide IDs (WWIDs) or to use the
        <filename>/var/lib/multipath/bindings</filename> file to assign a
        persistent and unique alias to the multipath devices in the form of
        <filename>/dev/mapper/mpathN</filename>.
       </para>
       <para>
        This option can be used in the <literal>devices</literal> section and
        the <literal>multipaths</literal> section.
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="2642*"/>
         <colspec colnum="2" colname="2" colwidth="7360*"/>
         <thead>
          <row>
           <entry>
            <para>
             Value
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal>no</literal>
            </para>
           </entry>
           <entry>
            <para>
             (Default) Use the WWIDs shown in the
             <filename>/dev/disk/by-id/</filename> location.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>yes</literal>
            </para>
           </entry>
           <entry>
            <para>
             Autogenerate user-friendly names as aliases for the multipath
             devices instead of the actual ID.
            </para>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
      </listitem>
     </varlistentry>
     <varlistentry xml:id="failback">
      <term><literal>failback</literal>
      </term>
      <listitem>
       <para>
        Specifies whether to monitor the failed path recovery, and indicates
        the timing for group failback after failed paths return to service.
       </para>
       <para>
        When the failed path recovers, the path is added back into the
        multipath-enabled path list based on this setting. Multipath evaluates
        the priority groups, and changes the active priority group when the
        priority of the primary path exceeds the secondary group.
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="2642*"/>
         <colspec colnum="2" colname="2" colwidth="7360*"/>
         <thead>
          <row>
           <entry>
            <para>
             Value
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal>manual</literal>
            </para>
           </entry>
           <entry>
            <para>
             (Default) The failed path is not monitored for recovery. The
             administrator runs the <command>multipath</command> command to
             update enabled paths and priority groups.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>immediate</literal>
            </para>
           </entry>
           <entry>
            <para>
             When a path recovers, enable the path immediately.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal><replaceable>N</replaceable></literal>
            </para>
           </entry>
           <entry>
            <para>
             When the path recovers, wait <replaceable>N</replaceable> seconds
             before enabling the path. Specify an integer value greater than 0.
            </para>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
       <para>
        We recommend failback setting of <literal>manual</literal> for
        multipath in cluster environments to prevent multipath failover
        ping-pong.
       </para>
<screen>failback "manual"</screen>
       <important>
        <title>Verification</title>
        <para>
         Ensure that you verify the failback setting with your storage system
         vendor. Different storage systems can require different settings.
        </para>
       </important>
      </listitem>
     </varlistentry>
     <varlistentry xml:id="no_path_retry">
      <term><literal>no_path_retry</literal>
      </term>
      <listitem>
       <para>
        Specifies the behaviors to use on path failure.
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="2642*"/>
         <colspec colnum="2" colname="2" colwidth="7360*"/>
         <thead>
          <row>
           <entry>
            <para>
             Value
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal><replaceable>N</replaceable></literal>
            </para>
           </entry>
           <entry>
            <para>
             Specifies the number of retries until <command>multipath</command>
             stops the queuing and fails the path. Specify an integer value
             greater than 0.
            </para>
            <para>
             In a cluster, you can specify a value of “0” to prevent
             queuing and allow resources to fail over.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>fail</literal>
            </para>
           </entry>
           <entry>
            <para>
             Specifies immediate failure (no queuing).
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>queue</literal>
            </para>
           </entry>
           <entry>
            <para>
             Never stop queuing (queue forever until the path comes alive).
            </para>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
       <para>
        We recommend a retry setting of <literal>fail</literal> or
        <literal>0</literal> in the <filename>/etc/multipath.conf</filename>
        file when working in a cluster. This causes the resources to fail over
        when the connection is lost to storage. Otherwise, the messages queue
        and the resource failover cannot occur.
       </para>
<screen>no_path_retry "fail"
no_path_retry "0"</screen>
       <important>
        <title>Verification</title>
        <para>
         Ensure that you verify the retry settings with your storage system
         vendor. Different storage systems can require different settings.
        </para>
       </important>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><literal>path_checker</literal>
      </term>
      <listitem>
       <para>
        Determines the state of the path.
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="30%"/>
         <colspec colnum="2" colname="2" colwidth="70%"/>
         <thead>
          <row>
           <entry>
            <para>
             Value
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal>directio</literal>
            </para>
           </entry>
           <entry>
            <para>
             Reads the first sector that has direct I/O. This is useful for
             DASD devices. Logs failure messages in the &systemd; journal (see
             <xref linkend="cha.journalctl"/>).
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>tur</literal>
            </para>
           </entry>
           <entry>
            <para>
             Issues an SCSI test unit ready command to the device. This is the
             preferred setting if the LUN supports it. On failure, the command
             does not fill up the &systemd; log journal with messages.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <replaceable>custom_vendor_value</replaceable>
            </para>
           </entry>
           <entry>
            <para>
             Some SAN vendors provide custom path_checker options:
            </para>
            <itemizedlist mark="bullet" spacing="normal">
             <listitem>
              <formalpara>
               <title><literal>cciss_tur</literal>:</title>
               <para>
                Checks the path state for HP Smart Storage Arrays.
               </para>
              </formalpara>
             </listitem>
             <listitem>
              <formalpara>
               <title><literal>emc_clariion</literal>:</title>
               <para>
                Queries the EMC Clariion EVPD page 0xC0 to determine the path
                state.
               </para>
              </formalpara>
             </listitem>
             <listitem>
              <formalpara>
               <title><literal>hp_sw</literal>:</title>
               <para>
                Checks the path state (Up, Down, or Ghost) for HP storage
                arrays with Active/Standby firmware.
               </para>
              </formalpara>
             </listitem>
             <listitem>
              <formalpara>
               <title><literal>rdac</literal>:</title>
               <para>
                Checks the path state for the LSI/Engenio RDAC storage
                controller.
               </para>
              </formalpara>
             </listitem>
            </itemizedlist>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><literal>path_grouping_policy</literal>
      </term>
      <listitem>
       <para>
        Specifies the path grouping policy for a multipath device hosted by a
        given controller.
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="2642*"/>
         <colspec colnum="2" colname="2" colwidth="7360*"/>
         <thead>
          <row>
           <entry>
            <para>
             Value
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal>failover</literal>
            </para>
           </entry>
           <entry>
            <para>
             (Default) One path is assigned per priority group so that only one
             path at a time is used.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>multibus</literal>
            </para>
           </entry>
           <entry>
            <para>
             All valid paths are in one priority group. Traffic is
             load-balanced across all active paths in the group.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>group_by_prio</literal>
            </para>
           </entry>
           <entry>
            <para>
             One priority group exists for each path priority value. Paths with
             the same priority are in the same priority group. Priorities are
             assigned by an external program.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>group_by_serial</literal>
            </para>
           </entry>
           <entry>
            <para>
             Paths are grouped by the SCSI target serial number (controller
             node WWN).
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>group_by_node_name</literal>
            </para>
           </entry>
           <entry>
            <para>
             One priority group is assigned per target node name. Target node
             names are fetched in
             <filename>/sys/class/fc_transport/target*/node_name</filename>.
            </para>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><literal>path_selector</literal>
      </term>
      <listitem>
       <para>
        Specifies the path-selector algorithm to use for load balancing.
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="2642*"/>
         <colspec colnum="2" colname="2" colwidth="7360*"/>
         <thead>
          <row>
           <entry>
            <para>
             Value
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal>round-robin 0</literal>
            </para>
           </entry>
           <entry>
            <para>
             The load-balancing algorithm used to balance traffic across all
             active paths in a priority group.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>queue-length 0</literal>
            </para>
           </entry>
           <entry>
            <para>
             A dynamic load balancer that balances the number of in-flight I/O
             on paths similar to the least-pending option.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>service-time 0</literal>
            </para>
           </entry>
           <entry>
            <para>
             (Default) A service-time oriented load balancer that balances I/O
             on paths according to the latency.
            </para>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>pg_timeout</term>
      <listitem>
       <para>
        Specifies path group timeout handling. No value can be specified; an
        internal default is set.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry xml:id="polling_interval">
      <term><literal>polling_interval</literal>
      </term>
      <listitem>
       <para>
        Specifies the time in seconds between the end of one path checking
        cycle and the beginning of the next path checking cycle.
       </para>
       <para>
        Specify an integer value greater than 0. The default value is 5. Ensure
        that you verify the polling_interval setting with your storage system
        vendor. Different storage systems can require different settings.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><literal>rr_min_io_rq</literal>
      </term>
      <listitem>
       <para>
        Specifies the number of I/O requests to route to a path before
        switching to the next path in the current path group, using
        request-based device-mapper-multipath.
       </para>
       <para>
        Specify an integer value greater than 0. The default value is 1.
       </para>
<screen>rr_min_io_rq "1"</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><literal>rr_weight</literal>
      </term>
      <listitem>
       <para>
        Specifies the weighting method to use for paths.
       </para>
       <informaltable>
        <tgroup cols="2">
         <colspec colnum="1" colname="1" colwidth="2642*"/>
         <colspec colnum="2" colname="2" colwidth="7360*"/>
         <thead>
          <row>
           <entry>
            <para>
             Value
            </para>
           </entry>
           <entry>
            <para>
             Description
            </para>
           </entry>
          </row>
         </thead>
         <tbody>
          <row>
           <entry>
            <para>
             <literal>uniform</literal>
            </para>
           </entry>
           <entry>
            <para>
             (Default) All paths have the same round-robin weights.
            </para>
           </entry>
          </row>
          <row>
           <entry>
            <para>
             <literal>priorities</literal>
            </para>
           </entry>
           <entry>
            <para>
             Each path’s weight is determined by the path’s priority times
             the rr_min_io_rq setting.
            </para>
           </entry>
          </row>
         </tbody>
        </tgroup>
       </informaltable>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><literal>uid_attribute</literal>
      </term>
      <listitem>
       <para>
        A udev attribute that provides a unique path identifier. The default
        value is <literal>ID_SERIAL</literal>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="sec.multipath.policies_failover.rr">
    <title>Configuring for Round-Robin Load Balancing</title>
    <para>
     All paths are active. I/O is configured for some number of seconds or some
     number of I/O transactions before moving to the next open path in the
     sequence.
    </para>
   </sect3>
   <sect3 xml:id="sec.multipath.policies_failover.prio.single">
    <title>Configuring for Single Path Failover</title>
    <para>
     A single path with the highest priority (lowest value setting) is active
     for traffic. Other paths are available for failover, but are not used
     unless failover occurs.
    </para>
   </sect3>
   <sect3 xml:id="sec.multipath.policies_failover.prio.rr_grouping">
    <title>Grouping I/O Paths for Round-Robin Load Balancing</title>
    <para>
     Multiple paths with the same priority fall into the active group. When all
     paths in that group fail, the device fails over to the next highest
     priority group. All paths in the group share the traffic load in a
     round-robin load balancing fashion.
    </para>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.multipath.policies_failover.rtpg">
   <title>Reporting Target Path Groups</title>
   <para>
    Use the SCSI Report Target Port Groups (<command>sg_rtpg(8)</command>)
    command. For information, see the man page for
    <command>sg_rtpg(8)</command>.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.root">
  <title>Configuring Multipath I/O for the Root Device</title>

  <para>
   Device Mapper Multipath I/O (DM-MPIO) is available and supported for
   <filename>/boot</filename> and <filename>/root</filename> in &productname;.
   In addition, the &yast; partitioner in the &yast; installer supports
   enabling multipath during the install.
  </para>

  <sect2 xml:id="sec.multipath.root.install">
   <title>Enabling Multipath I/O at Install Time</title>
   <para>
    The multipath software must be running at install time if you want to
    install the operating system on a multipath device. The
    <systemitem class="daemon">multipathd</systemitem> daemon is not
    automatically active during the system installation. You can start it by
    using the <guimenu>Configure Multipath</guimenu> option in the &yast;
    Partitioner.
   </para>
   <sect3 xml:id="sec.multipath.root.install.aa_lun">
    <title>Enabling Multipath I/O at Install Time on an Active/Active Multipath Storage LUN</title>
    <procedure>
     <step>
      <para>
       Choose <guimenu>Expert Partitioner</guimenu> on the <guimenu>Suggested
       Partitioning</guimenu> screen during the installation.
      </para>
     </step>
     <step>
      <para>
       Select the <guimenu>Hard Disks</guimenu> main icon, click the
       <guimenu>Configure</guimenu> button, then select <guimenu>Configure
       Multipath</guimenu>.
      </para>
     </step>
     <step>
      <para>
       Start multipath.
      </para>
      <para>
       &yast; starts to rescan the disks and shows available multipath devices
       (such as
       <filename>/dev/disk/by-id/dm-uuid-mpath-3600a0b80000f4593000012ae4ab0ae65</filename>).
       This is the device that should be used for all further processing.
      </para>
     </step>
     <step>
      <para>
       Click <guimenu>Next</guimenu> to continue with the installation.
      </para>
     </step>
    </procedure>
   </sect3>
   <sect3 xml:id="sec.multipath.root.install.ap_lun">
    <title>Enabling Multipath I/O at Install Time on an Active/Passive Multipath Storage LUN</title>
    <para>
     The <systemitem class="daemon">multipathd</systemitem> daemon is not
     automatically active during the system installation. You can start it by
     using the <guimenu>Configure Multipath</guimenu> option in the &yast;
     Partitioner.
    </para>
    <para>
     To enable multipath I/O at install time for an active/passive multipath
     storage LUN:
    </para>
    <procedure>
     <step>
      <para>
       Choose <guimenu>Expert Partitioner</guimenu> on the <guimenu>Suggested
       Partitioning</guimenu> screen during the installation.
      </para>
     </step>
     <step>
      <para>
       Select the <guimenu>Hard Disks</guimenu> main icon, click the
       <guimenu>Configure</guimenu> button, then select <guimenu>Configure
       Multipath</guimenu>.
      </para>
     </step>
     <step>
      <para>
       Start multipath.
      </para>
      <para>
       &yast; starts to rescan the disks and shows available multipath devices
       (such as
       <filename>/dev/disk/by-id/dm-uuid-mpath-3600a0b80000f4593000012ae4ab0ae65</filename>).
       This is the device that should be used for all further processing. Write
       down the device path and UUID; you will need it later.
      </para>
     </step>
     <step>
      <para>
       Click <guimenu>Next</guimenu> to continue with the installation.
      </para>
     </step>
     <step>
      <para>
       After all settings are done and the installation is finished, &yast;
       starts to write the boot loader information, and displays a countdown to
       restart the system. Stop the counter by clicking the
       <guimenu>Stop</guimenu> button and press
       <keycombo><keycap function="control"/><keycap function="alt"/><keycap>F5</keycap></keycombo>
       to access a console.
      </para>
     </step>
     <step>
      <para>
       Use the console to determine if a passive path was entered in the
       <filename>/boot/grub2/device.map</filename> file for the
       <filename>hd0</filename> entry.
      </para>
      <para>
       This is necessary because the installation does not distinguish between
       active and passive paths.
      </para>
      <substeps performance="required">
       <step>
        <para role="intro">
         Mount the root device to <filename>/mnt</filename> by entering
        </para>
<screen>mount /dev/disk/by-id/<replaceable>UUID</replaceable>;_part2 /mnt</screen>
        <para>
         For example, enter
        </para>
<screen>mount /dev/disk/by-id/dm-uuid-mpath-3600a0b80000f4593000012ae4ab0ae65_part2 /mnt</screen>
       </step>
       <step>
        <para>
         Mount the boot device to <filename>/mnt/boot</filename> by entering
        </para>
<screen>mount /dev/disk/by-id/<replaceable>UUID</replaceable>_part1 /mnt/boot</screen>
        <para>
         For example, enter
        </para>
<screen>mount /dev/disk/by-id/dm-uuid-mpath-3600a0b80000f4593000012ae4ab0ae65_part2 /mnt/boot</screen>
       </step>
       <step>
        <para>
         In the <filename>/mnt/boot/grub2/device.map</filename> file, determine
         if the <filename>hd0</filename> entry points to a passive path, then
         do one of the following:
        </para>
        <itemizedlist mark="bullet" spacing="normal">
         <listitem>
          <formalpara>
           <title>Active path:</title>
           <para>
            No action is needed. Skip all remaining steps and return to the
            &yast; graphical environment by pressing
            <keycombo><keycap function="control"/><keycap function="alt"/><keycap>F7</keycap></keycombo>
            and continue with the installation.
           </para>
          </formalpara>
         </listitem>
         <listitem>
          <formalpara>
           <title>Passive path:</title>
           <para>
            The configuration must be changed and the boot loader must be
            reinstalled.
           </para>
          </formalpara>
         </listitem>
        </itemizedlist>
       </step>
      </substeps>
     </step>
     <step>
      <para role="intro">
       If the <filename>hd0</filename> entry points to a passive path, change
       the configuration and reinstall the boot loader:
      </para>
      <substeps performance="required">
       <step>
        <para role="intro">
         Enter the following commands at the console prompt:
        </para>
<screen>
          mount -o bind /dev /mnt/dev
          mount -o bind /sys /mnt/sys
          mount -o bind /proc /mnt/proc
          chroot /mnt</screen>
       </step>
       <step>
        <para role="intro">
         At the console, run <command>multipath -ll</command>, then check the
         output to find the active path.
        </para>
        <para>
         Passive paths are flagged as <literal>ghost</literal>.
        </para>
       </step>
       <step>
        <para>
         In the <filename>/boot/grub2/device.map</filename> file, change the
         <literal>hd0</literal> entry to an active path, save the changes, and
         close the file.
        </para>
       </step>
       <step>
        <para>
         Reinstall the boot loader by entering
        </para>
<screen>
          grub-install /dev/disk/by-id/<replaceable>UUID</replaceable>_part1 /mnt/boot</screen>
        <para>
         For example, enter
        </para>
<screen>grub-install /dev/disk/by-id/dm-uuid-mpath-3600a0b80000f4593000012ae4ab0ae65_part2 /mnt/boot</screen>
       </step>
       <step>
        <para>
         Enter the following commands:
        </para>
<screen>exit
umount /mnt/*
umount /mnt</screen>
       </step>
      </substeps>
     </step>
     <step>
      <para>
       Return to the &yast; graphical environment by pressing
       <keycombo><keycap function="control"/><keycap function="alt"/><keycap>F7</keycap></keycombo>.
      </para>
     </step>
     <step>
      <para>
       Click <guimenu>OK</guimenu> to continue with the installation reboot.
      </para>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.multipath.root.enable_existing">
   <title>Enabling Multipath I/O for an Existing Root Device</title>
   <procedure>
    <step>
     <para>
      Install Linux with only a single path active, preferably one where the
      <filename>by-id</filename> symbolic links are listed in the partitioner.
     </para>
    </step>
    <step>
     <para>
      Mount the devices by using the <filename>/dev/disk/by-id</filename> path
      used during the install.
     </para>
    </step>
    <step>
     <para>
      Add dm-multipath to <filename>/etc/dracut.conf.d/01-dist.conf</filename>
      by adding the following line:
     </para>
<screen>force_drivers+="dm-multipath"</screen>
    </step>
    <step>
     <para>
      <remark condition="clarity">
       2014-09-05 - fs: Check if the following is still true
      </remark>
      For IBM &zseries;, before running <command>dracut</command>, edit the
      <filename>/etc/zipl.conf</filename> file to change the by-path
      information in <filename>zipl.conf</filename> with the same by-id
      information that was used in <filename>/etc/fstab</filename>.
     </para>
    </step>
    <step>
     <para>
      Run <command>dracut</command> <option>-f</option> to update the
      <filename>initrd</filename> image.
     </para>
    </step>
    <step>
     <para>
      For IBM &zseries;, after running <command>dracut</command>, run
      <command>zipl</command>.
     </para>
    </step>
    <step>
     <para>
      Reboot the server.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.multipath.root.disable">
   <title>Disabling Multipath I/O on the Root Device</title>
   <para>
    Add <literal>multipath=off</literal> to the kernel command line. This can
    be done with the &yast; Boot Loader module. Open <menuchoice> <guimenu>Boot
    Loader Installation</guimenu> <guimenu>Kernel Parameters</guimenu>
    </menuchoice> and add the parameter to both command lines.
   </para>
   <para>
    This affects only the root device. All other devices are not affected.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.lvm">
  <title>Using LVM2 on Multipath Devices</title>

  <para>
   Ensure that the configuration file for <filename>lvm.conf</filename> points
   to the multipath-device names instead of fixed path names. This should
   happen automatically if <filename>boot.multipath</filename> is enabled and
   loads before <filename>boot.lvm</filename>.
  </para>

  <sect2 xml:id="sec.multipath.lvm.filter">
   <title>Adding a Multipath Device Filter in the /etc/lvm/lvm.conf File</title>
   <para>
    By default, LVM2 does not recognize multipathed devices. To make LVM2
    recognize the multipathed devices as possible physical volumes, you must
    modify <filename>/etc/lvm/lvm.conf</filename> to scan multipathed devices
    through the multipath I/O layer.
   </para>
   <para>
    Adding a multipath filter prevents LVM from scanning and using the physical
    paths for raw device nodes that represent individual paths to the SAN
    (/dev/sd*). Ensure that you specify the filter path so that LVM scans only
    the device mapper names for the device
    (<filename>/dev/disk/by-id/dm-uuid-.*-mpath-.*</filename>) after
    multipathing is configured.
   </para>
   <para>
    To modify<filename> /etc/lvm/lvm.conf</filename> for multipath use:
   </para>
   <procedure>
    <step>
     <para>
      Open the <filename>/etc/lvm/lvm.conf</filename> file in a text editor.
     </para>
     <para>
      If <filename>/etc/lvm/lvm.conf</filename> does not exist, you can create
      one based on your current LVM configuration by entering the following at
      a terminal console prompt:
     </para>
<screen>sudo lvm dumpconfig &gt; /etc/lvm/lvm.conf</screen>
    </step>
    <step>
     <para>
      Change the <literal>filter</literal> and <literal>types</literal> entries
      in <filename>/etc/lvm/lvm.conf</filename> as follows:
     </para>
<screen>filter = [ "a|/dev/disk/by-id/.*|", "r|.*|" ]
types = [ "device-mapper", 1 ]</screen>
     <para>
      This allows LVM2 to scan only the by-id paths and reject everything else.
     </para>
     <para>
      If you are using user-friendly names, specify the filter path so that
      only the Device Mapper names are scanned after multipathing is
      configured. The following filter path accepts only partitions on a
      multipathed device:
     </para>
<screen>filter = [ "a|/dev/disk/by-id/dm-uuid-.*-mpath-.*|", "r|.*|" ]</screen>
     <para>
      To accept both raw disks and partitions for Device Mapper names, specify
      the path as follows, with no hyphen (-) before
      <filename>mpath</filename>:
     </para>
<screen>filter = [ "a|/dev/disk/by-id/dm-uuid-.*mpath-.*|", "r|.*|" ]</screen>
    </step>
    <step>
     <para>
      If you are also using LVM2 on non-multipathed devices, make the necessary
      adjustments in the <literal>filter</literal> and <literal>types</literal>
      entries to suit your setup. Otherwise, the other LVM devices are not
      visible with a <command>pvscan</command> after you modify the
      <filename>lvm.conf</filename> file for multipathing.
     </para>
     <para>
      You want only those devices that are configured with LVM to be included
      in the LVM cache, so ensure that you are specific about which other
      non-multipathed devices are included by the filter.
     </para>
     <para>
      For example, if your local disk is <filename>/dev/sda</filename> and all
      SAN devices are <filename>/dev/sdb</filename> and above, specify the
      local and multipathing paths in the filter as follows:
     </para>
<screen>filter = [ "a|/dev/sda.*|", "a|/dev/disk/by-id/.*|", "r|.*|" ]
types = [ "device-mapper", 253 ]</screen>
    </step>
    <step>
     <para>
      Save the file.
     </para>
    </step>
    <step>
     <para>
      Add dm-multipath to <filename>/etc/dracut.conf.d/01-dist.conf</filename>
      by adding the following line:
     </para>
<screen>force_drivers+="dm-multipath"</screen>
    </step>
    <step>
     <para>
      Make a new <filename>initrd</filename> to ensure that the Device Mapper
      Multipath services are loaded with the changed settings. Running
      <command>dracut</command> is needed only if the root (/) device or any
      parts of it (such as <filename>/var</filename>,
      <filename>/etc</filename>, <filename>/log</filename>) are on the SAN and
      multipath is needed to boot.
     </para>
     <para>
      Enter the following at a terminal console prompt:
     </para>
<screen>dracut -f --add-drivers multipath</screen>
    </step>
    <step>
     <para>
      Reboot the server to apply the changes.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.raid">
  <title>Configuring Multipath I/O for an Existing Software RAID</title>

  <para>
   Ideally, you should configure multipathing for devices before you use them
   as components of a software RAID device. If you add multipathing after
   creating any software RAID devices, the DM-MPIO service might be starting
   after the <command>multipath</command> service on reboot, which makes
   multipathing appear not to be available for RAIDs. You can use the procedure
   in this section to get multipathing running for a previously existing
   software RAID.
  </para>

  <para>
   For example, you might need to configure multipathing for devices in a
   software RAID under the following circumstances:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     If you create a new software RAID as part of the Partitioning settings
     during a new install or upgrade.
    </para>
   </listitem>
   <listitem>
    <para>
     If you did not configure the devices for multipathing before using them in
     the software RAID as a member device or spare.
    </para>
   </listitem>
   <listitem>
    <para>
     If you grow your system by adding new HBA adapters to the server or
     expanding the storage subsystem in your SAN.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>Assumptions</title>
   <para>
    The following instructions assume the software RAID device is
    <filename>/dev/mapper/mpath0</filename>, which is its device name as
    recognized by the kernel. It assumes you have enabled user-friendly names
    in the <filename>/etc/multipath.conf</filename> file as described in
    <xref linkend="sec.multipath.names" xrefstyle="HeadingOnPage"/>.
   </para>
   <para>
    Ensure that you modify the instructions for the device name of your
    software RAID.
   </para>
  </note>

  <procedure>
   <step>
    <para role="intro">
     Open a terminal console.
    </para>
    <para>
     Except where otherwise directed, use this console to enter the commands in
     the following steps.
    </para>
   </step>
   <step>
    <para>
     If any software RAID devices are currently mounted or running, enter the
     following commands for each device to unmount the device and stop it.
    </para>
<screen>sudo umount /dev/mapper/mpath0
sudo mdadm --misc --stop /dev/mapper/mpath0</screen>
   </step>
   <step>
    <para>
     Stop the <command>md</command> service by entering
    </para>
<screen>sudo systemctl stop mdmonitor</screen>
   </step>
   <step>
    <para>
     Start the <systemitem class="daemon">multipathd</systemitem> daemon by
     entering the following command:
    </para>
<screen>systemctl start multipathd</screen>
   </step>
   <step>
    <para>
     After the multipathing service has been started, verify that the software
     RAID’s component devices are listed in the
     <filename>/dev/disk/by-id</filename> directory. Do one of the following:
    </para>
    <itemizedlist mark="bullet" spacing="normal">
     <listitem>
      <formalpara>
       <title>Devices Are Listed:</title>
       <para>
        The device names should now have symbolic links to their Device Mapper
        Multipath device names, such as <filename>/dev/dm-1</filename>.
       </para>
      </formalpara>
     </listitem>
     <listitem>
      <formalpara>
       <title>Devices Are Not Listed:</title>
       <para>
        Force the multipath service to recognize them by flushing and
        rediscovering the devices by entering
       </para>
      </formalpara>
<screen>sudo multipath -F
sudo multipath -v0</screen>
      <para>
       The devices should now be listed in
       <filename>/dev/disk/by-id</filename>, and have symbolic links to their
       Device Mapper Multipath device names. For example:
      </para>
<screen>lrwxrwxrwx 1 root root 10 2011-01-06 11:42 dm-uuid-mpath-36006016088d014007e0d0d2213ecdf11 -&gt; ../../dm-1</screen>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Restart the <filename>mdmonitor</filename> service and the RAID device by
     entering
    </para>
<screen>systemctl start mdmonitor</screen>
   </step>
   <step>
    <para>
     Check the status of the software RAID by entering
    </para>
<screen>mdadm --detail /dev/mapper/mpath0</screen>
    <para>
     The RAID’s component devices should match their Device Mapper Multipath
     device names that are listed as the symbolic links of devices in the
     <filename>/dev/disk/by-id</filename> directory.
    </para>
   </step>
   <step>
    <para>
     Make a new <filename>initrd</filename> to ensure that the Device Mapper
     Multipath services are loaded before the RAID services on reboot. Running
     <command>dracut</command> is needed only if the root (/) device or any
     parts of it (such as <filename>/var</filename>, <filename>/etc</filename>,
     <filename>/log</filename>) are on the SAN and multipath is needed to boot.
    </para>
    <para>
     Enter
    </para>
<screen>dracut -f --add-drivers multipath</screen>
   </step>
   <step>
    <para>
     Reboot the server to apply these post-install configuration settings.
    </para>
   </step>
   <step>
    <para>
     Verify that the software RAID array comes up properly on top of the
     multipathed devices by checking the RAID status. Enter
    </para>
<screen>mdadm --detail /dev/mapper/mpath0</screen>
    <para>
     For example:
    </para>
    <simplelist>
     <member><literal>Number Major Minor RaidDevice State</literal>
     </member>
     <member><literal>0 253 0 0 active sync /dev/dm-0</literal>
     </member>
     <member><literal>1 253 1 1 active sync /dev/dm-1</literal>
     </member>
     <member><literal>2 253 2 2 active sync /dev/dm-2</literal>
     </member>
    </simplelist>
   </step>
  </procedure>

  <note>
   <title>Using mdadm with Multipath Devices</title>
   <para>
    The <command>mdadm</command> tool requires that the devices be accessed by
    the ID rather than by the device node path. Refer to
    <xref linkend="sec.multipath.mpiotools.mdadm"/> for details.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="sec.multipath.best_practice">
  <title>Best Practice</title>

  <para/>

  <sect2 xml:id="sec.multipath.best_practice.scandev">
   <title>Scanning for New Devices without Rebooting</title>
   <para>
    If your system has already been configured for multipathing and you later
    need to add more storage to the SAN, you can use the
    <command>rescan-scsi-bus.sh</command> script to scan for the new devices.
    By default, this script scans all HBAs with typical LUN ranges. The general
    syntax for the command looks like the following:
   </para>
<screen>rescan-scsi-bus.sh [options] [host [host ...]]</screen>
   <para>
    For most storage subsystems, the script can be run successfully without
    options. However, some special cases might need to use one or more options.
    Run <command>rescan-scsi-bus.sh --help</command> for details.
   </para>
   <warning>
    <title>EMC PowerPath Environments</title>
    <para>
     In EMC PowerPath environments, do not use the
     <filename>rescan-scsi-bus.sh</filename> utility provided with the
     operating system or the HBA vendor scripts for scanning the SCSI buses. To
     avoid potential file system corruption, EMC requires that you follow the
     procedure provided in the vendor documentation for EMC PowerPath for
     Linux.
    </para>
   </warning>
   <para>
    Use the following procedure to scan the devices and make them available to
    multipathing without rebooting the system.
   </para>
   <procedure>
    <step>
     <para>
      On the storage subsystem, use the vendor’s tools to allocate the device
      and update its access control settings to allow the Linux system access
      to the new storage. Refer to the vendor’s documentation for details.
     </para>
    </step>
    <step>
     <para>
      Scan all targets for a host to make its new device known to the middle
      layer of the Linux kernel’s SCSI subsystem. At a terminal console
      prompt, enter
     </para>
<screen>sudo rescan-scsi-bus.sh</screen>
     <para>
      Depending on your setup, you might need to run
      <command>rescan-scsi-bus.sh</command> with optional parameters. Refer to
      <command>rescan-scsi-bus.sh --help</command> for details.
     </para>
    </step>
    <step>
     <para>
      Check for scanning progress in the &systemd; journal (see
      <xref linkend="cha.journalctl"/> for details). At a terminal console
      prompt, enter
     </para>
<screen>sudo journalctl -r</screen>
     <para>
      This command displays the last lines of the log. For example:
     </para>
<screen>&prompt.user;sudo journalctl -r
Feb 14 01:03 kernel: SCSI device sde: 81920000
Feb 14 01:03 kernel: SCSI device sdf: 81920000
Feb 14 01:03 multipathd: sde: path checker registered
Feb 14 01:03 multipathd: sdf: path checker registered
Feb 14 01:03 multipathd: mpath4: event checker started
Feb 14 01:03 multipathd: mpath5: event checker started
Feb 14 01:03:multipathd: mpath4: remaining active paths: 1
Feb 14 01:03 multipathd: mpath5: remaining active paths: 1
[...]</screen>
    </step>
    <step>
     <para>
      Repeat the previous steps to add paths through other HBA adapters on the
      Linux system that are connected to the new device.
     </para>
    </step>
    <step>
     <para>
      Run the <command>multipath</command> command to recognize the devices for
      DM-MPIO configuration. At a terminal console prompt, enter
     </para>
<screen>sudo multipath</screen>
     <para>
      You can now configure the new device for multipathing.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.scanpart">
   <title>Scanning for New Partitioned Devices without Rebooting</title>
   <para>
    Use the example in this section to detect a newly added multipathed LUN
    without rebooting.
   </para>
   <warning>
    <title>EMC PowerPath Environments</title>
    <para>
     In EMC PowerPath environments, do not use the
     <filename>rescan-scsi-bus.sh</filename> utility provided with the
     operating system or the HBA vendor scripts for scanning the SCSI buses. To
     avoid potential file system corruption, EMC requires that you follow the
     procedure provided in the vendor documentation for EMC PowerPath for
     Linux.
    </para>
   </warning>
   <procedure>
    <step>
     <para>
      Open a terminal console.
     </para>
    </step>
    <step>
     <para>
      Scan all targets for a host to make its new device known to the middle
      layer of the Linux kernel’s SCSI subsystem. At a terminal console
      prompt, enter
     </para>
<screen>rescan-scsi-bus.sh</screen>
     <para>
      Depending on your setup, you might need to run
      <command>rescan-scsi-bus.sh</command> with optional parameters. Refer to
      <command>rescan-scsi-bus.sh --help</command> for details.
     </para>
    </step>
    <step>
     <para>
      Verify that the device is seen (such as if the link has a new time stamp)
      by entering
     </para>
<screen>ls -lrt /dev/dm-*</screen>
     <para>
      You can also verify the devices in <filename>/dev/disk/by-id</filename>
      by entering
     </para>
<screen>ls -l /dev/disk/by-id/</screen>
    </step>
    <step>
     <para>
      Verify the new device appears in the log by entering
     </para>
<screen>sudo journalctl -r</screen>
    </step>
    <step>
     <para>
      Use a text editor to add a new alias definition for the device in the
      <filename>/etc/multipath.conf</filename> file, such as
      <filename>data_vol3</filename>.
     </para>
     <para>
      For example, if the UUID is
      <filename>36006016088d014006e98a7a94a85db11</filename>, make the
      following changes:
     </para>
<screen>defaults {
     user_friendly_names   yes
  }
multipaths {
     multipath {
          wwid    36006016088d014006e98a7a94a85db11
          alias  data_vol3
          }
  }</screen>
    </step>
    <step>
     <para>
      Create a partition table for the device by entering
     </para>
<screen>fdisk /dev/disk/by-id/dm-uuid-mpath-&lt;UUID&gt;</screen>
     <para>
      Replace UUID with the device WWID, such as
      <filename>36006016088d014006e98a7a94a85db11</filename>.
     </para>
    </step>
    <step>
     <para>
      Trigger udev by entering
     </para>
<screen>sudo echo 'add' &gt; /sys/block/<replaceable>dm_device</replaceable>/uevent</screen>
     <para>
      For example, to generate the device-mapper devices for the partitions on
      <filename>dm-8</filename>, enter
     </para>
<screen>sudo echo 'add' &gt; /sys/block/dm-8/uevent</screen>
    </step>
    <step>
     <para>
      Create a file system on the device
      <filename>/dev/disk/by-id/dm-uuid-mpath-<replaceable>UUID_partN</replaceable></filename>.
      Depending on your choice for the file system, you may use one of the
      following commands for this purpose: <command>mkfs.btrfs</command>
      <command>mkfs.ext3</command>, <command>mkfs.ext4</command>, or
      <command>mkfs.xfs</command>. Refer to the respective man pages for
      details. Replace <filename>UUID_partN</filename> with the actual UUID and
      partition number, such as 36006016088d014006e98a7a94a85db11_part1.
     </para>
    </step>
    <step>
     <para>
      Create a label for the new partition by entering the following command:
     </para>
<screen>sudo tune2fs -L <replaceable>LABELNAME</replaceable> /dev/disk/by-id/dm-uuid-<replaceable>UUID_partN</replaceable>
</screen>
     <para>
      Replace <filename>UUID_partN</filename> with the actual UUID and
      partition number, such as 36006016088d014006e98a7a94a85db11_part1.
      Replace <replaceable>LABELNAME</replaceable> with a label of your choice.
     </para>
    </step>
    <step>
     <para>
      Reconfigure DM-MPIO to let it read the aliases by entering
     </para>
<screen>sudo multipathd -k'reconfigure'</screen>
    </step>
    <step>
     <para>
      Verify that the device is recognized by
      <systemitem class="daemon">multipathd</systemitem> by entering
     </para>
<screen>sudo multipath -ll</screen>
    </step>
    <step>
     <para>
      Use a text editor to add a mount entry in the
      <filename>/etc/fstab</filename> file.
     </para>
     <para>
      At this point, the alias you created in a previous step is not yet in the
      <filename>/dev/disk/by-label</filename> directory. Add a mount entry for
      the <filename>/dev/dm-9</filename> path, then change the entry before the
      next time you reboot to
     </para>
<screen>LABEL=<replaceable>LABELNAME</replaceable></screen>
    </step>
    <step>
     <para>
      Create a directory to use as the mount point, then mount the device.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.status">
   <title>Viewing Multipath I/O Status</title>
   <para>
    Querying the multipath I/O status outputs the current status of the
    multipath maps.
   </para>
   <para>
    The <command>multipath -l</command> option displays the current path status
    as of the last time that the path checker was run. It does not run the path
    checker.
   </para>
   <para>
    The <command>multipath -ll</command> option runs the path checker, updates
    the path information, then displays the current status information. This
    command always displays the latest information about the path status.
   </para>
<screen>&prompt.user;sudo multipath -ll
3600601607cf30e00184589a37a31d911
[size=127 GB][features="0"][hwhandler="1 emc"]

\_ round-robin 0 [active][first]
  \_ 1:0:1:2 sdav 66:240  [ready ][active]
  \_ 0:0:1:2 sdr  65:16   [ready ][active]

\_ round-robin 0 [enabled]
  \_ 1:0:0:2 sdag 66:0    [ready ][active]
  \_ 0:0:0:2 sdc  8:32    [ready ][active]</screen>
   <para>
    For each device, it shows the device’s ID, size, features, and hardware
    handlers.
   </para>
   <para>
    Paths to the device are automatically grouped into priority groups on
    device discovery. Only one priority group is active at a time. For an
    active/active configuration, all paths are in the same group. For an
    active/passive configuration, the passive paths are placed in separate
    priority groups.
   </para>
   <para>
    The following information is displayed for each group:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Scheduling policy used to balance I/O within the group, such as
      round-robin
     </para>
    </listitem>
    <listitem>
     <para>
      Whether the group is active, disabled, or enabled
     </para>
    </listitem>
    <listitem>
     <para>
      Whether the group is the first (highest priority) group
     </para>
    </listitem>
    <listitem>
     <para>
      Paths contained within the group
     </para>
    </listitem>
   </itemizedlist>
   <para>
    The following information is displayed for each path:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      The physical address as <replaceable>host:bus:target:lun</replaceable>,
      such as 1:0:1:2
     </para>
    </listitem>
    <listitem>
     <para>
      Device node name, such as <filename>sda</filename>
     </para>
    </listitem>
    <listitem>
     <para>
      Major:minor numbers
     </para>
    </listitem>
    <listitem>
     <para>
      Status of the device
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.io_error">
   <title>Managing I/O in Error Situations</title>
   <para>
    You might need to configure multipathing to queue I/O if all paths fail
    concurrently by enabling queue_if_no_path. Otherwise, I/O fails immediately
    if all paths are gone. In certain scenarios, where the driver, the HBA, or
    the fabric experience spurious errors, DM-MPIO should be configured to
    queue all I/O where those errors lead to a loss of all paths, and never
    propagate errors upward.
   </para>
   <para>
    When you use multipathed devices in a cluster, you might choose to disable
    queue_if_no_path. This automatically fails the path instead of queuing the
    I/O, and escalates the I/O error to cause a failover of the cluster
    resources.
   </para>
   <para>
    Because enabling queue_if_no_path leads to I/O being queued indefinitely
    unless a path is reinstated, ensure that <command>multipathd</command> is
    running and works for your scenario. Otherwise, I/O might be stalled
    indefinitely on the affected multipathed device until reboot or until you
    manually return to failover instead of queuing.
   </para>
   <para>
    To test the scenario:
   </para>
   <procedure>
    <step>
     <para>
      Open a terminal console.
     </para>
    </step>
    <step>
     <para>
      Activate queuing instead of failover for the device I/O by entering
     </para>
<screen>sudo dmsetup message <replaceable>device_ID</replaceable> 0 queue_if_no_path</screen>
     <para>
      Replace the <replaceable>device_ID</replaceable> with the ID for your
      device. The 0 value represents the sector and is used when sector
      information is not needed.
     </para>
     <para>
      For example, enter:
     </para>
<screen>sudo dmsetup message 3600601607cf30e00184589a37a31d911 0 queue_if_no_path</screen>
    </step>
    <step>
     <para>
      Return to failover for the device I/O by entering
     </para>
<screen>sudo dmsetup message <replaceable>device_ID</replaceable> 0 fail_if_no_path</screen>
     <para>
      This command immediately causes all queued I/O to fail.
     </para>
     <para>
      Replace the <replaceable>device_ID</replaceable> with the ID for your
      device. For example, enter
     </para>
<screen>sudo dmsetup message 3600601607cf30e00184589a37a31d911 0 fail_if_no_path</screen>
    </step>
   </procedure>
   <para>
    To set up queuing I/O for scenarios where all paths fail:
   </para>
   <procedure>
    <step>
     <para>
      Open a terminal console.
     </para>
    </step>
    <step>
     <para>
      Open the <filename>/etc/multipath.conf</filename> file in a text editor.
     </para>
    </step>
    <step>
     <para>
      Uncomment the defaults section and its ending bracket, then add the
      <literal>default_features</literal> setting, as follows:
     </para>
<screen>defaults {
  default_features "1 queue_if_no_path"
}</screen>
    </step>
    <step>
     <para>
      After you modify the <filename>/etc/multipath.conf</filename> file, you
      must run <command>dracut</command> <option>-f</option> to re-create the
      <filename>initrd</filename> on your system, then reboot for the changes
      to take effect.
     </para>
    </step>
    <step>
     <para>
      When you are ready to return to failover for the device I/O, enter
     </para>
<screen>sudo dmsetup message <replaceable>mapname</replaceable> 0 fail_if_no_path</screen>
     <para>
      Replace the <replaceable>mapname</replaceable> with the mapped alias name
      or the device ID for the device. The 0 value represents the sector and is
      used when sector information is not needed.
     </para>
     <para>
      This command immediately causes all queued I/O to fail and propagates the
      error to the calling application.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.io_stalled">
   <title>Resolving Stalled I/O</title>
   <para>
    If all paths fail concurrently and I/O is queued and stalled, do the
    following:
   </para>
   <procedure>
    <step>
     <para>
      Enter the following command at a terminal console prompt:
     </para>
<screen>sudo dmsetup message <replaceable>mapname</replaceable> 0 fail_if_no_path</screen>
     <para>
      Replace <literal><replaceable>mapname</replaceable></literal> with the
      correct device ID or mapped alias name for the device. The 0 value
      represents the sector and is used when sector information is not needed.
     </para>
     <para>
      This command immediately causes all queued I/O to fail and propagates the
      error to the calling application.
     </para>
    </step>
    <step>
     <para>
      Reactivate queuing by entering the following command:
     </para>
<screen>sudo dmsetup message <replaceable>mapname</replaceable> 0 queue_if_no_path</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.zseries">
   <title>Configuring Default Settings for IBM &zseries; Devices</title>
   <para>
    Testing of the IBM &zseries; device with multipathing has shown that the
    <literal>dev_loss_tmo</literal> parameter should be set to 90 seconds, and
    the <literal>fast_io_fail_tmo</literal> parameter should be set to 5
    seconds. If you are using &zseries; devices, modify the
    <filename>/etc/multipath.conf</filename> file to specify the values as
    follows:
   </para>
<screen>defaults {
       dev_loss_tmo 90
       fast_io_fail_tmo 5
}</screen>
   <para>
    The <literal>dev_loss_tmo</literal> parameter sets the number of seconds to
    wait before marking a multipath link as bad. When the path fails, any
    current I/O on that failed path fails. The default value varies according
    to the device driver being used. The valid range of values is 0 to 600
    seconds. To use the driver’s internal timeouts, set the value to zero (0)
    or to any value greater than 600.
   </para>
   <para>
    The <literal>fast_io_fail_tmo</literal> parameter sets the length of time
    to wait before failing I/O when a link problem is detected. I/O that
    reaches the driver fails. If I/O is in a blocked queue, the I/O does not
    fail until the <literal>dev_loss_tmo</literal> time elapses and the queue
    is unblocked.
   </para>
   <para>
    If you modify the <filename>/etc/multipath.conf</filename> file, the
    changes are not applied until you update the multipath maps, or until the
    <systemitem class="daemon">multipathd</systemitem> daemon is restarted
    (<command>systemctl restart multipathd</command>).
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.netapp">
   <title>Using Multipath with NetApp Devices</title>
   <para>
    When using multipath for NetApp devices, we recommend the following
    settings in the <filename>/etc/multipath.conf</filename> file:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Set the default values for the following parameters globally for NetApp
      devices:
     </para>
<screen>max_fds max
queue_without_daemon no</screen>
    </listitem>
    <listitem>
     <para>
      Set the default values for the following parameters for NetApp devices in
      the hardware table:
     </para>
<screen>dev_loss_tmo infinity
fast_io_fail_tmo 5
features "3 queue_if_no_path pg_init_retries 50"</screen>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.noflush">
   <title>Using --noflush with Multipath Devices</title>
   <para>
    The <option>--noflush</option> option should always be used when running on
    multipath devices.
   </para>
   <para>
    For example, in scripts where you perform a table reload, you use the
    <literal>--noflush</literal> option on resume to ensure that any
    outstanding I/O is not flushed, because you need the multipath topology
    information.
   </para>
<screen>load
resume --noflush</screen>
  </sect2>

  <sect2 xml:id="sec.multipath.best_practice.san_timeout">
   <title>SAN Timeout Settings When the Root Device Is Multipathed</title>
<!-- Bug 492469 - FC boot lun with device mapper multipath, server died
    when no path available for short time, comment 42 -->
   <para>
    A system with root (<filename>/</filename>) on a multipath device might
    stall when all paths have failed and are removed from the system because a
    <literal>dev_loss_tmo</literal> timeout is received from the storage
    subsystem (such as Fibre Channel storage arrays).
   </para>
   <para>
    If the system device is configured with multiple paths and the multipath
    <literal>no_path_retry</literal> setting is active, you should modify the
    storage subsystem’s <literal>dev_loss_tmo</literal> setting accordingly
    to ensure that no devices are removed during an all-paths-down scenario. We
    strongly recommend that you set the <literal>dev_loss_tmo</literal> value
    to be equal to or higher than the <literal>no_path_retry</literal> setting
    from multipath.
   </para>
   <para>
    The recommended setting for the storage subsystem’s
    <literal>dev_los_tmo</literal> is
   </para>
<screen>&lt;dev_loss_tmo&gt; = &lt;no_path_retry&gt; * &lt;polling_interval&gt;</screen>
   <para>
    where the following definitions apply for the multipath values:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      <literal>no_path_retry</literal> is the number of retries for multipath
      I/O until the path is considered to be lost, and queuing of IO is
      stopped.
     </para>
    </listitem>
    <listitem>
     <para>
      <literal>polling_interval</literal> is the time in seconds between path
      checks.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Each of these multipath values should be set from the
    <filename>/etc/multipath.conf</filename> configuration file. For
    information, see
    <xref linkend="sec.multipath.conf_file" xrefstyle="SectTitleOnPage"/>.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.multipath.trouble">
  <title>Troubleshooting MPIO</title>

  <para>
   This section describes some known issues and possible solutions for MPIO.
  </para>

  <sect2 xml:id="sec.multipath.trouble.root">
   <title>The System Exits to Emergency Shell at Boot When Multipath Is Enabled</title>
   <para>
    During boot the system exits into the emergency shell with messages similar
    to the following:
   </para>
<screen>[  OK  ] Listening on multipathd control socket.
         Starting Device-Mapper Multipath Device Controller...
[  OK  ] Listening on Device-mapper event daemon FIFOs.
         Starting Device-mapper event daemon...
         Expecting device dev-disk-by\x2duuid-34be48b2\x2dc21...32dd9.device...
         Expecting device dev-sda2.device...
[  OK  ] Listening on udev Kernel Socket.
[  OK  ] Listening on udev Control Socket.
         Starting udev Coldplug all Devices...
         Expecting device dev-disk-by\x2duuid-1172afe0\x2d63c...5d0a7.device...
         Expecting device dev-disk-by\x2duuid-c4a3d1de\x2d4dc...ef77d.device...
[  OK  ] Started Create list of required static device nodes ...current kernel.
         Starting Create static device nodes in /dev...
[  OK  ] Started Collect Read-Ahead Data.
[  OK  ] Started Device-mapper event daemon.
[  OK  ] Started udev Coldplug all Devices.
         Starting udev Wait for Complete Device Initialization...
[  OK  ] Started Replay Read-Ahead Data.
         Starting Load Kernel Modules...
         Starting Remount Root and Kernel File Systems...
[  OK  ] Started Create static devices
[   13.682489] floppy0: no floppy controllers found
[*     ] (1 of 4) A start job is running for dev-disk-by\x2du...(7s / 1min 30s)
[*     ] (1 of 4) A start job is running for dev-disk-by\x2du...(7s / 1min 30s)

...

Timed out waiting for device dev-disk-by\x2duuid-c4a...cfef77d.device.
[DEPEND] Dependency failed for /opt.
[DEPEND] Dependency failed for Local File Systems.
[DEPEND] Dependency failed for Postfix Mail Transport Agent.
Welcome to emergency shell
Give root password for maintenance
(or press Control-D to continue):</screen>
   <para>
    This issue is a logical consequence of the multipath integration in systemd
    and occurs if the root file system is not on multipath but multipath is
    enabled. In such a setup, multipath tries to set its paths for all devices
    that are not blacklisted. Since the device with the root file system is
    already mounted, it is inaccessible for multipath and causes it to fail.
   </para>
   <para>
    Fix this issue by configuring multipath correctly by blacklisting the root
    device in <filename>/etc/multipath.conf</filename>:
   </para>
   <procedure>
    <step>
     <para>
      Run <command>multipath -v2</command> in the emergency shell and identify
      the device for the root file system. It will result in an output similar
      to:
     </para>
<screen>&prompt.root;multipath -v2
Dec 18 10:10:03 | 3600508b1001030343841423043300400: ignoring map</screen>
     <para>
      The string between <literal>| </literal> and <literal>:</literal> is the
      WWID needed for blacklisting.
     </para>
    </step>
    <step>
     <para>
      Open <filename>/etc/multipath.conf</filename> and add the following:
     </para>
<screen>blacklist {
  wwid "<replaceable>WWWID</replaceable>"
}</screen>
     <para>
      Replace <replaceable>WWWID</replaceable> with the ID you retrieved in the
      previous step. For more information see
      <xref linkend="sec.multipath.blacklist"/>.
     </para>
    </step>
    <step>
     <para>
      Exit the emergency shell and reboot the server by pressing <keycombo>
      <keycap function="control"/> <keycap>D</keycap> </keycombo>.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.multipath.lvm.boot">
   <title>Enabling boot.multipath</title>
   <para>
    Multipath must be loaded before LVM to ensure that multipath maps are built
    correctly. Loading multipath after LVM can result in incomplete device maps
    for a multipath device because LVM locks the device, and MPIO cannot create
    the maps properly.
   </para>
   <para>
    If the system device is a local device that does not use MPIO and LVM, you
    can disable both <filename>boot.multipath</filename> and
    <filename>boot.lvm</filename>. After the server starts, you can manually
    start multipath before you start LVM, then run a <command>pvscan</command>
    command to recognize the LVM objects.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.trouble.lvm">
   <title>Troubleshooting MPIO Mapping for LVM Devices</title>
   <para>
    Timing is important for starting the LVM process. If LVM starts before MPIO
    maps are done, LVM might use a fixed path for the device instead of its
    multipath. The device works, so you might not be aware that the device’s
    MPIO map is incomplete until that fixed path fails. You can help prevent
    the problem by enabling <filename>boot.multipath</filename> and following
    the instructions in
    <xref linkend="sec.multipath.lvm.boot" xrefstyle="HeadingOnPage"/>.
   </para>
   <para>
    To troubleshoot a mapping problem, you can use <command>dmsetup</command>
    to check that the expected number of paths are present for each multipath
    device. As the &rootuser; user, enter the following at a command prompt:
   </para>
<screen>sudo dmsetup ls --tree</screen>
   <para>
    In the following sample response, the first device has four paths. The
    second device is a local device with a single path. The third device has
    two paths. The distinction between active and passive paths is not reported
    through this tool.
   </para>
<screen>&prompt.user;sudo dmsetup ls --tree
  vg910-lv00 (253:23)
    └─ 360a980006465576657346d4b6c593362 (253:10)
      |- (65:96)
      |- (8:128)
      |- (8:240)
      └─ (8:16)
  vg00-lv08 (253:9)
    └─ (8:3)
  system_vg-data_lv (253:1)
    └─36006016088d014007e0d0d2213ecdf11 (253:0)
      ├─ (8:32)
      └─ (8:48)</screen>
   <para>
    An incorrect mapping typically returns too few paths and does not have a
    major number of 253. For example, the following shows what an incorrect
    mapping looks like for the third device:
   </para>
<screen>  system_vg-data_lv (8:31)
     └─ (8:32)</screen>
  </sect2>

  <sect2 xml:id="sec.multipath.trouble.prio_fail">
   <title>PRIO Settings for Individual Devices Fail After Upgrading to Multipath 0.4.9 or Later</title>
   <para>
    Multipath Tools from version 0.4.9 onward uses the <literal>prio</literal>
    setting in the <literal>defaults{}</literal> or
    <literal>devices{}</literal> section of the
    <filename>/etc/multipath.conf</filename> file. It silently ignores the
    keyword <literal>prio</literal> when it is specified for an individual
    <literal>multipath</literal> definition in the
    <literal>multipaths{)</literal> section.
   </para>
   <para>
    Multipath Tools 0.4.8 allowed the prio setting in the individual
    <literal>multipath</literal> definition in the
    <literal>multipaths{)</literal> section to override the
    <literal>prio</literal> settings in the <literal>defaults{}</literal> or
    <literal>devices{}</literal> section.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.trouble.prio_argument_fail">
   <title>PRIO Settings with Arguments Fail After Upgrading to multipath-tools-0.4.9 or Later</title>
   <para>
    When you upgrade from <filename>multipath-tools-0.4.8</filename> to
    <filename>multipath-tools-0.4.9</filename>, the <literal>prio</literal>
    settings in the <filename>/etc/multipath.conf</filename> file are broken
    for prioritizers that require an argument. In multipath-tools-0.4.9, the
    <literal>prio</literal> keyword is used to specify the prioritizer, and the
    <literal>prio_args</literal> keyword is used to specify the argument for
    prioritizers that require an argument. Previously, both the prioritizer and
    its argument were specified on the same <literal>prio</literal> line.
   </para>
   <para>
    For example, in multipath-tools-0.4.8, the following line was used to
    specify a prioritizer and its arguments on the same line.
   </para>
<screen>prio "weightedpath hbtl [1,3]:.:.+:.+ 260 [0,2]:.:.+:.+ 20"</screen>
   <para>
    After upgrading to multipath-tools-0.4.9 or later, the command causes an
    error. The message is similar to the following:
   </para>
<screen>&lt;Month day hh:mm:ss&gt; | Prioritizer 'weightedpath hbtl [1,3]:.:.+:.+ 260
[0,2]:.:.+:.+ 20' not found in /lib64/multipath</screen>
   <para>
    To resolve this problem, use a text editor to modify the
    <literal>prio</literal> line in the
    <filename>/etc/multipath.conf</filename> file. Create two lines with the
    prioritizer specified on the <filename>prio</filename> line, and the
    prioritizer argument specified on the <filename>prio_args</filename> line
    below it:
   </para>
<screen>prio "weightedpath"
prio_args "hbtl [1,3]:.:.+:.+ 260 [0,2]:.:.+:.+ 20"</screen>
   <para>
    Restart the <systemitem class="daemon">multipathd</systemitem> daemon for
    the changes to become active by running <command>sudo systemctl restart
    multipathd</command>.
   </para>
  </sect2>

  <sect2 xml:id="sec.multipath.trouble.tids">
   <title>Technical Information Documents</title>
   <para>
    For information about troubleshooting multipath I/O issues on SUSE Linux
    Enterprise Server, see the following Technical Information Documents (TIDs)
    in the &suse; Knowledgebase:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      <link xlink:href="http://www.suse.com/support/kb/doc.php?id=3617600"><citetitle>Using
      LVM on local and SAN attached devices</citetitle></link>
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="http://www.suse.com/support/kb/doc.php?id=7007498"><citetitle>Using
      LVM on Multipath (DM MPIO) Devices</citetitle></link>
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/support/kb/doc.php?id=7009660"><citetitle>HOWTO:
      Add, Resize and Remove LUN without restarting SLES</citetitle></link>
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
</chapter>
