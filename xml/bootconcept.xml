<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>

<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.boot">
 <title>Introduction to the Boot Process</title>
 <info>
  <abstract>
   <para>
    Booting a Linux system involves different components and tasks. After a
    firmware and hardware initialization process, which depends on the
    machine's architecture, the kernel is started by means of the boot loader
    &grub;. After this point, the boot process is completely controlled by the
    operating system and handled by &systemd;.  &systemd; provides a set of
    <quote>targets</quote> that boot configurations for everyday usage,
    maintenance or emergencies.
   </para>
  </abstract>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>


 <sect1 xml:id="sec.boot.terminology">
  <title>Terminology</title>
  <para>
   This chapter uses terms that can be interpreted ambiguously. To
   understand how they are used here, read the definitions below:
  </para>
  <variablelist>
   <varlistentry>
    <term><systemitem>init</systemitem></term>
    <listitem>
     <para>
      Two different processes are commonly named <quote>init</quote>:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        The <systemitem>initramfs</systemitem> process mounting the root
        file system
       </para>
      </listitem>
      <listitem>
       <para>
        The operating system process that starts all other processes that is
        executed from the real root file system
       </para>
      </listitem>
     </itemizedlist>
     <para>
      In both cases, the &systemd; program is taking care of this task. It is
      first executed from the <systemitem>initramfs</systemitem> to mount the
      root file system. Once that has succeeded, it is re-executed from the
      root file system as the initial process. To avoid confusing these two
      &systemd; processes, we refer to the first process as <emphasis>init on
      initramfs</emphasis> and to the second one as
      <emphasis>systemd</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>
     <systemitem>initrd</systemitem>/<systemitem>initramfs</systemitem>
    </term>
    <listitem>
     <para>
      An <systemitem>initrd</systemitem> (initial RAM disk) is an image file
      containing a root file system image which is loaded by the kernel and
      mounted from <filename>/dev/ram</filename> as the temporary root file
      system. Mounting this file system requires a file system driver.
     </para>
     <para>
      Beginning with kernel 2.6.13, the initrd has been replaced by the
      <systemitem>initramfs</systemitem> (initial RAM file system), which does
      not require a file system driver to be mounted. &productname; exclusively
      uses an <systemitem>initramfs</systemitem>. However, since the
      <systemitem>initramfs</systemitem> is stored as
      <filename>/boot/initrd</filename>, it is often called
      <quote>initrd</quote>. In this chapter we exclusively use the name
      <systemitem>initramfs</systemitem>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.boot.proc">
  <title>The Linux Boot Process</title>
  <para>
   The Linux boot process consists of several stages, each represented by a
   different component:
  </para>
  <orderedlist>
   <listitem>
    <para>
     <xref linkend="sec.boot.proc.initialization" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.boot.proc.kernel" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.boot.initramfs" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.boot.systemd" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
  </orderedlist>

  <sect2 xml:id="sec.boot.proc.initialization">
   <title>The Initialization and Boot Loader Phase</title>
   <para>
    During the initialization phase the machine's hardware is set up and the
    devices are prepared. This process differs significantly between hardware
    architectures.
   </para>
   <para>
    &productname; uses the boot loader &grub; on all architectures. Depending
    on the architecture and firmware, starting the &grub; boot loader can be a
    multi-step process. The purpose of the boot loader is to load the kernel
    and the initial, RAM-based file system (initramfs). For more information
    about &grub;, refer to <xref linkend="cha.grub2"/>.
   </para>
   <sect3 xml:id="sec.boot.proc.initialization.x86_aarch" arch="x86_64;aarch64">
    <title>Initialization and Boot Loader Phase on &aarch64; and &x86-64;</title>
    <para>
     After turning on the computer, the BIOS or the UEFI initializes the screen
     and keyboard, and tests the main memory. Up to this stage, the machine
     does not access any mass storage media. Subsequently, the information
     about the current date, time, and the most important peripherals are
     loaded from the CMOS values. When the boot media and its geometry are
     recognized, the system control passes from the BIOS/UEFI to the boot
     loader.
    </para>
    <para>
     On a machine equipped with a traditional BIOS, only code from the first
     physical 512-byte data sector (the Master Boot Record, MBR) of the boot
     disk can be loaded. Only a minimal &grub; fits into the MBR. Its sole
     purpose is to load a &grub; core image containing file system drivers from
     the gap between the MBR and the first partition (MBR partition table) or
     from the BIOS boot partition (GPT partition table). This image contains
     file system drivers and therefore is able to access
     <filename>/boot</filename> located on the root file
     system. <filename>/boot</filename> contains additional modules for &grub;
     core as well as the kernel and the initramfs image. Once it has access to
     this partition, &grub; loads the kernel and the initramfs image into
     memory and hands control over to the kernel.
    </para>
    <para>
     When booting a BIOS system from an encrypted file system that includes an
     encrypted <filename>/boot</filename> partition, you need to enter the
     password for decryption twice. It is first needed by &grub; to decrypt
     <filename>/boot</filename> and then for &systemd; to mount the encrypted
     volumes.
    </para>
    <para>
     On machines with UEFI the boot process is much simpler than on machines
     with a traditional BIOS. The firmware is able to read from a FAT formatted
     system partition of disks with a GPT partition table. This EFI
     system-partition (in the running system mounted as
     <filename>/boot/efi</filename>) holds enough space to host a fully-fledged
     &grub; which is directly loaded and executed by the firmware.
    </para>
    <para>
     If the BIOS/UEFI supports network booting, it is also possible to
     configure a boot server that provides the boot loader. The system can then
     be booted via PXE. The BIOS/UEFI acts as the boot loader. It gets the boot
     image from the boot server and starts the system. This is completely
     independent of local hard disks.
    </para>
   </sect3>
   <sect3 xml:id="sec.boot.proc.initialization.zsystems" arch="zseries">
    <title>
     Initialization and Boot Loader Phase on IBM &zseries;
    </title>
    <para>
     On IBM &zseries; the boot process must be initialized by a boot loader
     called <command>zipl</command> (z initial program load). Although
     <command>zipl</command> supports reading from various file systems, it
     does not support the &slea; default file system (Btrfs) or booting from
     snapshots. &productname; therefore uses a two-stage boot process that
     ensures full Btrfs support at boot-time:
    </para>
    <procedure>
     <step>
      <para>
       <command>zipl</command> boots from the ext2-formatted partition
       <filename>/boot/zipl</filename>. This partition contains a minimal
       kernel and an initramfs that are loaded into memory. The initramfs
       contains a Btrfs driver (among others) and the boot loader &grub;. The
       kernel is started with a parameter <literal>initgrub</literal>, which
       tells it to start &grub;.
      </para>
     </step>
     <step>
      <para>
       The kernel mounts the root file system, so <filename>/boot</filename>
       becomes accessible. Now &grub; is started from the initramfs. It reads
       its configuration from <filename>/boot/grub2/grub.cfg</filename> and
       loads the final kernel and initramfs from
       <filename>/boot</filename>. The new kernel now gets loaded via &kexec;.
      </para>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.boot.proc.kernel">
   <title>The Kernel Phase</title>
   <para>
    When the boot loader has passed on system control, the boot process is the
    same on all architectures. The boot loader loads both the kernel and an
    initial RAM-based file system (<systemitem>initramfs</systemitem>) into
    memory and the kernel takes over.
   </para>
   <para>
    After the kernel has set up memory management and has detected the CPU type
    and its features, it initializes the hardware and mounts the temporary root
    file system from the memory that was loaded with the
    <systemitem>initramfs</systemitem>.
   </para>

   <sect3 xml:id="sec.boot.initrd">
    <title>The <systemitem>initramfs</systemitem> file</title>
    <para>
     <systemitem>initramfs</systemitem> (initial RAM file system) is a small
     cpio archive that the kernel can load into a RAM disk. It is located at
     <filename>/boot/initrd</filename>. It can be created with a tool called
     <command>dracut</command>&mdash;refer to <command>man 8 dracut</command>
     for details.
    </para>
    <para>
     The <systemitem>initramfs</systemitem> provides a minimal Linux
     environment that enables the execution of programs before the actual root
     file system is mounted. This minimal Linux environment is loaded into
     memory by BIOS or UEFI routines and does not have specific hardware
     requirements other than sufficient memory. The
     <systemitem>initramfs</systemitem> archive must always provide an
     executable named <systemitem>init</systemitem> that executes the &systemd;
     daemon on the root file system for the boot process to proceed.
    </para>
    <para>
     Before the root file system can be mounted and the operating system can be
     started, the kernel needs the corresponding drivers to access the device
     on which the root file system is located. These drivers may include
     special drivers for certain kinds of hard disks or even network drivers to
     access a network file system. The needed modules for the root file system
     are loaded by <systemitem>init</systemitem> on
     <systemitem>initramfs</systemitem>. After the modules are loaded,
     <systemitem class="service">udev</systemitem> provides the
     <systemitem>initramfs</systemitem> with the needed devices. Later in the
     boot process, after changing the root file system, it is necessary to
     regenerate the devices. This is done by the &systemd; unit
     <filename>systemd-udev-trigger.service</filename>.
    </para>

    <sect4 xml:id="sec.boot.initrd.regenerate">
     <title>Regenerating the initramfs</title>
     <para>
      Because the <systemitem>initramfs</systemitem> contains drivers, it needs
      to be updated whenever a new version of one of its drivers is
      available. This is done automatically when installing the package
      containing the driver update. &yast; or zypper will inform you about
      this by showing the output of the command that generates the
      <systemitem>initramfs</systemitem>. However, there are some occasions
      when you need to regenerate an <systemitem>initramfs</systemitem>
      manually:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        <!-- Adding Drivers Because of Hardware Changes -->
        <xref xrefstyle="select:title" linkend="var.initrd.regenerate.drivers"/>
       </para>
      </listitem>
      <listitem>
       <para>
        <!-- Moving System Directories to a RAID or LVM -->
        <xref xrefstyle="select:title" linkend="var.initrd.regenerate.raidroot"/>
       </para>
      </listitem>
      <listitem>
       <para>
        <!--
         Adding Physical Volumes to a LVM Group Containg the Root File System
        -->
        <xref xrefstyle="select:title" linkend="var.initrd.regenerate.lvmadd"/>
       </para>
      </listitem>
      <listitem>
       <para>
        <!-- Changing Kernel Variables -->
        <xref xrefstyle="select:title" linkend="var.initrd.regenerate.kernelvars"/>
       </para>
      </listitem>
     </itemizedlist>

     <variablelist>
      <varlistentry xml:id="var.initrd.regenerate.drivers">
       <term>Adding Drivers Because of Hardware Changes</term>
       <listitem>
        <para>
         If you need to change hardware (for example, hard disks), and this
         hardware requires different drivers to be in the kernel at boot time,
         you must update the <systemitem>initramfs</systemitem> file.
        </para>
        <para>
         Open or create
         <filename>/etc/dracut.conf.d/10-<replaceable>DRIVER</replaceable>.conf</filename>
         and add the following line (mind the leading whitespace):
        </para>
        <screen>force_drivers+=" <replaceable>DRIVER1</replaceable>"</screen>
        <para>
         Replace <replaceable>DRIVER1</replaceable> with the module name of the
         driver. If you need to add more than one driver, list them
         space-separated:
        </para>
        <screen>force_drivers+=" <replaceable>DRIVER1</replaceable> <replaceable>DRIVER2</replaceable>"</screen>
        <para>
         Proceed with <xref linkend="pro.generate.initramfs"/>.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry xml:id="var.initrd.regenerate.raidroot">
       <term>Moving System Directories to a RAID or LVM</term>
       <listitem>
        <para>
         Whenever you move swap files, or system directories like
         <filename>/usr</filename> in a running system to a RAID or logical
         volume, you need to create an <systemitem>initramfs</systemitem> that
         contains support for software RAID or LVM drivers.
        </para>
        <para>
         To do so, create the respective entries in
         <filename>/etc/fstab</filename> and mount the new entries (for example
         with <command>mount -a</command> and/or <command>swapon -a</command>).
        </para>
        <para>
         Proceed with <xref linkend="pro.generate.initramfs"/>.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry xml:id="var.initrd.regenerate.lvmadd">
       <term>Adding Disks to an LVM Group or Btrfs RAID Containing the Root
        File System</term>
       <listitem>
        <para>
         Whenever you add (or remove) a disk to a logical volume group
         or a Btrfs RAID containing the root file system, you need to create an
         <systemitem>initramfs</systemitem> that contains support for the
         enlarged volume. Follow the instructions at <xref
         linkend="pro.generate.initramfs"/>.
        </para>
        <para>
         Proceed with <xref linkend="pro.generate.initramfs"/>.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry xml:id="var.initrd.regenerate.kernelvars">
       <term>Changing Kernel Variables</term>
       <listitem>
        <para>
         If you change the values of kernel variables via the
         <command>sysctl</command> interface by editing related files
         (<filename>/etc/sysctl.conf</filename> or
         <filename>/etc/sysctl.d/*.conf</filename>), the change will be lost on
         the next system reboot. Even if you load the values with <command>sysctl
         --system</command> at runtime, the changes are not saved into the
         <systemitem>initramfs</systemitem> file. You need to update it by
         proceeding as outlined in <xref linkend="pro.generate.initramfs"/>.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>

     <procedure xml:id="pro.generate.initramfs">
      <title>Generate an initramfs</title>
      <para>
       Note that all commands in the following procedure need to be executed as
       user &rootuser;.
      </para>
      <step>
       <para>
        Generate a new <systemitem>initramfs</systemitem> file by running
       </para>
       <screen>dracut <replaceable>MY_INITRAMFS</replaceable></screen>
       <para>
        Replace <replaceable>MY_INITRAMFS</replaceable> with a file name of
        your choice. The new <systemitem>initramfs</systemitem> will be created
        as <filename>/boot/<replaceable>MY_INITRAMFS</replaceable></filename>.
       </para>
       <para>
        Alternatively, run <command>dracut -f</command>. This will overwrite
        the currently used, existing file.
       </para>
      </step>
      <step>
       <para>
        (Skip this step if you ran <command>dracut -f</command> in the previous
        step.) Create a link to the <systemitem>initramfs</systemitem> file you
        created in the previous step:
       </para>
       <screen>(cd /boot &amp;&amp; ln -sf <replaceable>MY_INITRAMFS</replaceable> initrd)</screen>
      </step>
      <step arch="zseries">
       <para>
        On the IBM &zseries; architecture, additionally run
        <command>grub2-install</command>.
       </para>
      </step>
     </procedure>
    </sect4>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.boot.initramfs">
   <title>The init on initramfs Phase</title>
   <para>
    The temporary root file system mounted by the kernel from the
    <systemitem>initramfs</systemitem> contains the executable &systemd; (which
    is called <systemitem>init</systemitem> on
    <systemitem>initramfs</systemitem> in the following, also see <xref
    linkend="sec.boot.terminology"/>. This program performs all actions needed
    to mount the proper root file system. It provides kernel functionality for
    the needed file system and device drivers for mass storage controllers with
    <systemitem class="service">udev</systemitem>.
   </para>

   <para>
    The main purpose of <systemitem>init</systemitem> on
    <systemitem>initramfs</systemitem> is to prepare the mounting of and access
    to the real root file system. Depending on your system configuration,
    <systemitem>init</systemitem> on <systemitem>initramfs</systemitem> is
    responsible for the following tasks.
   </para>

   <variablelist>
    <varlistentry>
     <term>Loading Kernel Modules</term>
     <listitem>
      <para>
       Depending on your hardware configuration, special drivers may be needed
       to access the hardware components of your computer (the most important
       component being your hard disk). To access the final root file system,
       the kernel needs to load the proper file system drivers.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Providing Block Special Files</term>
     <listitem>
      <para>
       The kernel generates device events depending on loaded modules.
       <systemitem class="service">udev</systemitem> handles these events and
       generates the required special block files on a RAM file system in
       <filename>/dev</filename>. Without those special files, the file system
       and other devices would not be accessible.
      </para>
    </listitem>
    </varlistentry>
    <varlistentry>
     <term>Managing RAID and LVM Setups</term>
     <listitem>
      <para>
       If you configured your system to hold the root file system under RAID or
       LVM, <systemitem>init</systemitem> on <systemitem>initramfs</systemitem>
       sets up LVM or RAID to enable access to the root file system later.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Managing the Network Configuration</term>
     <listitem>
      <para>
       If you configured your system to use a network-mounted root file system
       (mounted via NFS), <systemitem>init</systemitem> must make sure that the
       proper network drivers are loaded and that they are set up to allow
       access to the root file system.
      </para>
      <para>
       If the file system resides on a network block device like iSCSI or SAN,
       the connection to the storage server is also set up by
       <systemitem>init</systemitem> on <systemitem>initramfs</systemitem>.
       &productname; supports booting from a secondary iSCSI target if the
       primary target is not available. <phrase os="sles">For more details
       regarding configuration of the booting iSCSI target refer to <xref
       linkend="sec.iscsi.initiator.yast"/></phrase>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>

   <note>
    <title>Handling of Mount Failures</title>
    <para>
     If the root file system fails to mount from within the boot environment,
     it must be checked and repaired before the boot can continue. The file
     system checker will be automatically started for Ext3 and Ext4 file
     systems. The repair process is not automated for XFS and Btrfs file
     systems, and the user is presented with information describing the
     options available to repair the file system. When the file system has been
     successfully repaired, exiting the boot environment will cause the system
     to retry mounting the root file system. If successful, the boot will
     continue normally.
    </para>
   </note>

   <sect3 xml:id="sec.boot.linuxrc.initramfs">
    <title>The init on initramfs Phase in the Installation Process</title>
    <para>
     When <systemitem>init</systemitem> on <systemitem>initramfs</systemitem>
     is called during the initial boot as part of the installation process, its
     tasks differ from those mentioned above. Note that the installation system
     also does not start &systemd; from
     <systemitem>initramfs</systemitem>&mdash;these tasks are performed by
     <command>linuxrc</command>.
    </para>

    <variablelist>
     <varlistentry>
      <term>Finding the Installation Medium</term>
      <listitem>
       <para>
        When starting the installation process, your machine loads an
        installation kernel and a special <systemitem>init</systemitem>
        containing the &yast; installer. The &yast; installer is running in a
        RAM file system and needs to have information about the location of the
        installation medium to access it for installing the operating system.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>
       Initiating Hardware Recognition and Loading Appropriate Kernel Modules
      </term>
      <listitem>
       <para>
        As mentioned in <xref linkend="sec.boot.initrd"/>, the boot process
        starts with a minimum set of drivers that can be used with most
        hardware configurations. On &aarch64;, &power;, and &x86-64; machines,
        <command>linuxrc</command> starts an initial hardware scanning process
        that determines the set of drivers suitable for your hardware
        configuration. On IBM &zseries;, a list of drivers and their parameters
        needs to be provided, for example via linuxrc or a parmfile.
       </para>
       <para>
        These drivers are used to generate a custom
        <systemitem>initramfs</systemitem> that is needed to boot the
        system. If the modules are not needed for boot but for coldplug, the
        modules can be loaded with &systemd;; for more information, see <xref
        linkend="sec.boot.systemd.advanced.kernel_modules"/>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Loading the Installation System</term>
      <listitem>
       <para>
        When the hardware is properly recognized, the appropriate drivers are
        loaded. The <systemitem class="service">udev</systemitem> program
        creates the special device files and <command>linuxrc</command>
        starts the installation system with the &yast; installer.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Starting &yast;</term>
      <listitem>
       <para>
        Finally, <command>linuxrc</command> starts &yast;, which starts
        the package installation and the system configuration.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>


  <sect2 xml:id="sec.boot.systemd">
   <title>The systemd Phase</title>
   <para>
    After the <quote>real</quote> root file system has been found, it is
    checked for errors and mounted. If this is successful, the
    <systemitem>initramfs</systemitem> is cleaned and the &systemd; daemon on
    the root file system is executed. &systemd; is Linux's system and service
    manager. It is the parent process that is started as PID 1 and acts as an
    init system which brings up and maintains user space services. See <xref
    linkend="cha.systemd"/> for details.
   </para>
  </sect2>
 </sect1>
</chapter>
