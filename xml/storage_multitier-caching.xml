<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-multitiercache" xml:lang="en">
 <title>Multi-tier Caching for Block Device Operations</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <para>
  A multi-tier cache is a replicated/distributed cache that consists of at
  least two tiers: one is represented by slower but cheaper rotational block
  devices (hard disks), while the other is more expensive but performs faster
  data operations (for example SSD flash disks).
 </para>
 <para>
  &sls; implements two different solutions for caching between flash and
  rotational devices: &bcache; and &lvmcache;.
 </para>
 <sect1 xml:id="sec-multitiercache-terminology">
  <title>General Terminology</title>

  <para>
   This section explains several terms often used when describing cache related
   features:
  </para>

  <variablelist>
   <varlistentry>
    <term>Migration</term>
    <listitem>
     <para>
      Movement of the primary copy of a logical block from one device to the
      other.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Promotion</term>
    <listitem>
     <para>
      Migration from the slow device to the fast device.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Demotion</term>
    <listitem>
     <para>
      Migration from the fast device to the slow device.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Origin device</term>
    <listitem>
     <para>
      The big and slower block device. It always contains a copy of the logical
      block, which may be out of date or kept in synchronization with the copy
      on the cache device (depending on policy).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Cache device</term>
    <listitem>
     <para>
      The small and faster block device.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Metadata device</term>
    <listitem>
     <para>
      A small device that records which blocks are in the cache, which are
      dirty, and extra hints for use by the policy object. This information
      could be put on the cache device as well, but having it separate allows
      the volume manager to configure it differently, for example as a mirror
      for extra robustness. The metadata device may only be used by a single
      cache device.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Dirty block</term>
    <listitem>
     <para>
      If some process writes to a block of data which is placed in the cache,
      the cached block is marked as <emphasis>dirty</emphasis> because it was
      overwritten in the cache and needs to be written back to the original
      device.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Cache miss</term>
    <listitem>
     <para>
      A request for I/O operations is pointed to the cached device's cache
      first. If it cannot find the requested values, it looks in the device
      itself, which is slow. This is called a <emphasis>cache miss</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Cache hit</term>
    <listitem>
     <para>
      When a requested value is found in the cached device's cache, it is
      served fast. This is called a <emphasis>cache hit</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Cold cache</term>
    <listitem>
     <para>
      Cache that holds no values (is empty) and causes <emphasis>cache
      misses</emphasis>. As the cached block device operations progress, it
      gets filled with data and becomes <emphasis>warm</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Warm cache</term>
    <listitem>
     <para>
      Cache that already holds some values and is likely to result in
      <emphasis>cache hits</emphasis>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec-multitiercache-caching-modes">
  <title>Caching Modes</title>

  <para>
   Following are the basic caching modes that multi-tier caches use:
   <emphasis>write-back</emphasis>, <emphasis>write-through</emphasis>,
   <emphasis>write-around</emphasis> and <emphasis>pass-through</emphasis>.
  </para>

  <variablelist>
   <varlistentry>
    <term>write-back</term>
    <listitem>
     <para>
      Data written to a block that is cached go to the cache only, and the
      block is marked dirty. This is the default caching mode.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>write-through</term>
    <listitem>
     <para>
      Writing to a cached block will not complete until it has hit both the
      origin and cache devices. Clean blocks remain clean with
      <emphasis>write-through</emphasis> cache.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>write-around</term>
    <listitem>
     <para>
      A similar technique to write-through cache, but write I/O is written
      directly to a permanent storage, bypassing the cache. This can prevent
      the cache being flooded with write I/O that will not subsequently be
      re-read, but the disadvantage is that a read request for recently written
      data will create a 'cache miss' and needs to be read from slower bulk
      storage and experience higher latency.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>pass-through</term>
    <listitem>
     <para>
      To enable the <emphasis>pass-through</emphasis> mode, the cache needs to
      be clean. Reading is served from the origin device bypassing the cache.
      Writing is forwarded to the origin device and 'invalidates' the cache
      block. <emphasis>Pass-through</emphasis> allows a cache device activation
      without having to care about data coherency, which is maintained. The
      cache will gradually become cold as writing takes place. If you can
      verify the coherency of the cache later, or establish it by using the
      <literal>invalidate_cblocks</literal> message, you can switch the cache
      device to <emphasis>write-through</emphasis> or
      <emphasis>write-back</emphasis> mode while it is still warm. Otherwise,
      you can discard the cache contents before switching to the desired
      caching mode.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec-multitiercache-bcache">
  <title>&bcache;</title>

<!-- https://bcache.evilpiepirate.org/ -->

  <para>
   &bcache; is a Linux kernel block layer cache. It allows one or more fast
   disk drives (such as SSDs) to act as a cache for one or more slower hard
   disks. &bcache; supports write-through and write-back, and is independent of
   the file system used. By default it caches random reads and writes only,
   which SSDs excel at. It is suitable for desktops, servers, and high end
   storage arrays as well.
  </para>

  <sect2 xml:id="sec-multitiercache-bcache-features">
   <title>Main Features</title>
   <itemizedlist>
    <listitem>
     <para>
      A single cache device can be used to cache an arbitrary number of backing
      devices. Backing devices can be attached and detached at runtime, while
      mounted and in use.
     </para>
    </listitem>
    <listitem>
     <para>
      Recovers from unclean shutdowns&mdash;writes are not completed until the
      cache is consistent with regard to the backing device.
     </para>
    </listitem>
    <listitem>
     <para>
      Throttles traffic to the SSD if it becomes congested.
     </para>
    </listitem>
    <listitem>
     <para>
      Highly efficient write-back implementation. Dirty data is always written
      out in sorted order.
     </para>
    </listitem>
    <listitem>
     <para>
      Stable and reliable&mdash;in production use.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

<!-- https://wiki.archlinux.org/index.php/Bcache#Setting_up_a_bcache_device_on_an_existing_system -->

  <sect2 xml:id="sec-multitiercache-bcache-setting-bcache-device">
   <title>Setting Up a &bcache; Device</title>
   <para>
    This section describes steps to set up and manage a &bcache; device.
   </para>
   <procedure>
    <step>
     <para>
      Install the <systemitem>bcache-tools</systemitem> package:
     </para>
<screen>&prompt.sudo;zypper in bcache-tools</screen>
    </step>
    <step>
     <para>
      Create a backing device (typically a mechanical drive). The backing
      device can be a whole device, a partition, or any other standard block
      device.
     </para>
<screen>&prompt.sudo;make-bcache -B /dev/sdb</screen>
    </step>
    <step>
     <para>
      Create a cache device (typically an SSD disk).
     </para>
<screen>&prompt.sudo;make-bcache -C /dev/sdc</screen>
     <para>
      In this example, the default block and bucket sizes of 512 B and 128 KB
      are used. The block size should match the backing device's sector size
      which will usually be either 512 or 4k. The bucket size should match the
      erase block size of the caching device with the intention of reducing
      write amplification. For example, using a hard disk with 4k sectors and
      an SSD with an erase block size of 2 MB this command would look as
      follows:
     </para>
<screen>sudo make-bcache --block 4k --bucket 2M -C /dev/sdc</screen>
     <tip>
      <title>Multi-Device Support</title>
      <para>
       <command>make-bcache</command> can prepare and register multiple backing
       devices and a cache device at the same time. In this case you do not
       need to manually attach the cache device to the backing device
       afterward:
      </para>
<screen>&prompt.sudo;make-bcache -B /dev/sda /dev/sdb -C /dev/sdc</screen>
     </tip>
    </step>
    <step>
     <para>
      &bcache; devices show up as
     </para>
<screen>/dev/bcache<replaceable>N</replaceable></screen>
     <para>
      and as
     </para>
<screen>/dev/bcache/by-uuid/<replaceable>UUID</replaceable>
/dev/bcache/by-label/<replaceable>LABEL</replaceable></screen>
     <para>
      You can normally format and mount &bcache; devices as usual:
     </para>
<screen>&prompt.sudo;mkfs.ext4 /dev/bcache0
&prompt.sudo;mount /dev/bcache0 /mnt</screen>
     <para>
      You can control &bcache; devices through <systemitem>sysfs</systemitem>
      at
      <filename>/sys/block/bcache<replaceable>N</replaceable>/bcache</filename>.
     </para>
    </step>
    <step>
     <para>
      After both the cache and backing devices are registered, you need to
      attach the backing device to the related cache set to enable caching:
     </para>
<screen>&prompt.user;echo <replaceable>CACHE_SET_UUID</replaceable> > /sys/block/bcache0/bcache/attach</screen>
     <para>
      where <replaceable>CACHE_SET_UUID</replaceable> is found in
      <filename>/sys/fs/bcache</filename>.
     </para>
    </step>
    <step>
     <para>
      By default &bcache; uses a pass-through caching mode. To change it to for
      example write-back, run
     </para>
<screen>&prompt.user;echo writeback > /sys/block/bcache0/bcache/cache_mode</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec-multitiercache-bcache-sysfs">
   <title>&bcache; Configuration Using <systemitem>sysfs</systemitem></title>
   <para>
    &bcache; devices use the <systemitem>sysfs</systemitem> interface to store
    their runtime configuration values. This way you can change &bcache;
    backing and cache disks' behavior or see their usage statistics.
   </para>
   <para>
    For the complete list of &bcache; <systemitem>sysfs</systemitem>
    parameters, see the contents of the
    <filename>/usr/src/linux/Documentation/bcache.txt</filename> file, mainly
    the <literal>SYSFS - BACKING DEVICE</literal>, <literal>SYSFS - BACKING
    DEVICE STATS</literal>, and <literal>SYSFS - CACHE DEVICE</literal>
    sections.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-multitiercache-lvmcache">
  <title>&lvmcache;</title>

  <para>
   &lvmcache; is a caching mechanism consisting of logical volumes (LVs). It
   uses the <literal>dm-cache</literal> kernel driver and supports
   write-through (default) and write-back caching modes. &lvmcache; improves
   performance of a large and slow LV by dynamically migrating some of its data
   to a faster and smaller LV. For more information on LVM, see
   <xref linkend="part-lvm"/>.
  </para>

  <para>
   LVM refers to the small, fast LV as a <emphasis>cache pool LV</emphasis>.
   The large, slow LV is called the <emphasis>origin LV</emphasis>. Because of
   requirements from dm-cache, LVM further splits the cache pool LV into two
   devices: the <emphasis>cache data LV</emphasis> and <emphasis>cache
   metadata LV</emphasis>. The cache data LV is where copies of data blocks
   are kept from the origin LV to increase speed. The cache metadata LV holds
   the accounting information that specifies where data blocks are stored.
  </para>

  <sect2 xml:id="sec-multitiercache-lvmcache-configure">
   <title>Configuring &lvmcache;</title>
   <para>
    This section describes steps to create and configure LVM based caching.
   </para>
   <procedure>
    <step>
     <para>
      <emphasis>Create the origin LV.</emphasis> Create a new LV or use an
      existing LV to become the origin LV:
     </para>
<screen>&prompt.sudo;lvcreate -n <replaceable>ORIGIN_LV</replaceable> -L 100G vg <replaceable>/dev/SLOW_DEV</replaceable></screen>
    </step>
    <step>
     <para>
      <emphasis>Create the cache data LV.</emphasis> This LV will hold data
      blocks from the origin LV. The size of this LV is the size of the cache
      and will be reported as the size of the cache pool LV.
     </para>
<screen>&prompt.sudo;lvcreate -n <replaceable>CACHE_DATA_LV</replaceable> -L 10G vg <replaceable>/dev/FAST</replaceable></screen>
    </step>
    <step>
     <para>
      <emphasis>Create the cache metadata LV.</emphasis> This LV will hold
      cache pool metadata. The size of this LV should be approximately 1000
      times smaller than the cache data LV, with a minimum size of 8MB.
     </para>
<screen>&prompt.sudo;lvcreate -n <replaceable>CACHE_METADATA_LV</replaceable> -L 12M vg <replaceable>/dev/FAST</replaceable></screen>
     <para>
      List the volumes you have created so far:
     </para>
<screen>&prompt.sudo;lvs -a vg
LV                VG   Attr        LSize   Pool Origin
cache_data_lv     vg   -wi-a-----  10.00g
cache_metadata_lv vg   -wi-a-----  12.00m
origin_lv         vg   -wi-a----- 100.00g</screen>
    </step>
    <step>
     <para>
      <emphasis>Create a cache pool LV.</emphasis> Combine the data and
      metadata LVs into a cache pool LV. You can set the cache pool LV's
      behavior at the same time.
     </para>
     <para>
      <replaceable>CACHE_POOL_LV</replaceable> takes the name of
      <replaceable>CACHE_DATA_LV</replaceable>.
     </para>
     <para>
      <replaceable>CACHE_DATA_LV</replaceable> is renamed to
      <replaceable>CACHE_DATA_LV</replaceable>_cdata and becomes hidden.
     </para>
     <para>
      <replaceable>CACHE_META_LV</replaceable> is renamed to
      <replaceable>CACHE_DATA_LV</replaceable>_cmeta and becomes hidden.
     </para>
<screen>&prompt.sudo;lvconvert --type cache-pool \
 --poolmetadata vg/cache_metadata_lv vg/cache_data_lv</screen>
<screen>&prompt.sudo;lvs -a vg
LV                     VG   Attr       LSize   Pool Origin
cache_data_lv          vg   Cwi---C---  10.00g
[cache_data_lv_cdata]  vg   Cwi-------  10.00g
[cache_data_lv_cmeta]  vg   ewi-------  12.00m
origin_lv              vg   -wi-a----- 100.00g</screen>
    </step>
    <step>
     <para>
      <emphasis>Create a cache LV.</emphasis> Create a cache LV by linking the
      cache pool LV to the origin LV.
     </para>
     <para>
      The user accessible cache LV takes the name of the origin LV, while the
      origin LV becomes a hidden LV renamed to
      <replaceable>ORIGIN_LV</replaceable>_corig.
     </para>
     <para>
      CacheLV takes the name of <replaceable>ORIGIN_LV</replaceable>.
     </para>
     <para>
      <replaceable>ORIGIN_LV</replaceable> is renamed to
      <replaceable>ORIGIN_LV</replaceable>_corig and becomes hidden.
     </para>
<screen>&prompt.sudo;lvconvert --type cache --cachepool vg/cache_data_lv vg/origin_lv</screen>
<screen>&prompt.sudo;lvs -a vg
LV              VG   Attr       LSize   Pool   Origin
cache_data_lv          vg   Cwi---C---  10.00g
[cache_data_lv_cdata]  vg   Cwi-ao----  10.00g
[cache_data_lv_cmeta]  vg   ewi-ao----  12.00m
origin_lv              vg   Cwi-a-C--- 100.00g cache_data_lv [origin_lv_corig]
[origin_lv_corig]      vg   -wi-ao---- 100.00g</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec-multitiercache-lvmcache-remove">
   <title>Removing a Cache Pool</title>
   <para>
    There are several ways to turn off the LV cache.
   </para>
   <sect3 xml:id="sec-multitiercache-lvmcache-remove-detach">
    <title>Detach a Cache Pool LV from a Cache LV</title>
    <para>
     You can disconnect a cache pool LV from a cache LV, leaving an unused
     cache pool LV and an uncached origin LV. Data are written back from the
     cache pool to the origin LV when necessary.
    </para>
<screen>&prompt.sudo;lvconvert --splitcache vg/origin_lv</screen>
   </sect3>
   <sect3 xml:id="sec-multitiercache-lvmcache-remove-wo-origin">
    <title>Removing a Cache Pool LV without Removing its Origin LV</title>
    <para>
     This writes back data from the cache pool to the origin LV when necessary,
     then removes the cache pool LV, leaving the uncached origin LV.
    </para>
<screen>&prompt.sudo;lvremove vg/cache_data_lv</screen>
    <para>
     An alternative command that also disconnects the cache pool from the cache
     LV, and deletes the cache pool:
    </para>
<screen>&prompt.sudo;lvconvert --uncache vg/origin_lv</screen>
   </sect3>
   <sect3 xml:id="sec-multitiercache-lvmcache-remove-both">
    <title>Removing Both the Origin LV and the Cache Pool LV</title>
    <para>
     Removing a cache LV removes both the origin LV and the linked cache pool
     LV.
    </para>
<screen>&prompt.sudo;lvremove vg/origin_lv</screen>
   </sect3>
   <sect3 xml:id="sec-multitiercache-lvmcache-remove-info">
    <title>For More Information</title>
    <para>
     You can find more &lvmcache; related topics, such as supported cache
     modes, redundant sub-logical volumes, cache policy, or converting existing
     LVs to cache types, in the &lvmcache; manual page (<command>man 7
     lvmcache</command>).
    </para>
   </sect3>
  </sect2>
 </sect1>
</chapter>
