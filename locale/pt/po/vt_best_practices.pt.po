msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2018-10-15 19:45+0200\n"
"PO-Revision-Date: 2018-09-30 01:09+0200\n"
"Last-Translator: Automatically generated\n"
"Language-Team: none\n"
"Language: pt\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#. Put one translator per line, in the form NAME <EMAIL>, YEAR1, YEAR2
msgctxt "_"
msgid "translator-credits"
msgstr ""

#. (itstool) path: article/title
#: xml/vt_best_practices.xml:12
msgid "Virtualization Best Practices"
msgstr ""

#. (itstool) path: article/subtitle
#: xml/vt_best_practices.xml:13
msgid ""
"<phrase role=\"productname\"><phrase os=\"osuse\">openSUSE Leap</"
"phrase><phrase os=\"sles\">SUSE Linux Enterprise Server</phrase><phrase os="
"\"sled\">SUSE Linux Enterprise Desktop</phrase></phrase> <phrase role="
"\"productnumber\"><phrase os=\"osuse\">15.0</phrase><phrase os=\"sles;sled"
"\">15</phrase></phrase>"
msgstr ""

#. (itstool) path: info/productname
#: xml/vt_best_practices.xml:19
msgid ""
"<phrase role=\"productname\"><phrase os=\"osuse\">openSUSE Leap</"
"phrase><phrase os=\"sles\">SUSE Linux Enterprise Server</phrase><phrase os="
"\"sled\">SUSE Linux Enterprise Desktop</phrase></phrase>"
msgstr ""

#. (itstool) path: info/productnumber
#: xml/vt_best_practices.xml:20
msgid ""
"<phrase role=\"productnumber\"><phrase os=\"osuse\">15.0</phrase><phrase os="
"\"sles;sled\">15</phrase></phrase>"
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:33
msgid "Virtualization Scenarios"
msgstr ""

#. (itstool) path: sect1/para
#: xml/vt_best_practices.xml:35
msgid ""
"Virtualization offers a lot of capabilities to your environment. It can be "
"used in multiple scenarios. To get more details about <link xlink:href="
"\"https://www.suse.com/documentation/sles-12/book_virt/data/"
"sec_virtualization_introduction_capabilities.html\">Virtualization "
"Capabilities</link> and <link xlink:href=\"https://www.suse.com/"
"documentation/sles-12/book_virt/data/"
"sec_virtualization_introduction_benefits.html\">Virtualization Benefits</"
"link>, refer to the <link xlink:href=\"https://www.suse.com/documentation/"
"sles-12/book_virt/data/book_virt.html\">Virtualization Guide</link>."
msgstr ""

#. (itstool) path: sect1/para
#: xml/vt_best_practices.xml:46
msgid ""
"This best practice guide will provide advice for making the right choice in "
"your environment. It will recommend or discourage the usage of options "
"depending on your workload. Fixing configuration issues and performing "
"tuning tasks will increase the performance of VM Guest's near to bare metal."
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:131
msgid "Before You Apply Modifications"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:134
msgid "Back Up First"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:135
msgid ""
"Changing the configuration of the VM Guest or the VM Host Server can lead to "
"data loss or an unstable state. It is really important that you do backups "
"of files, data, images, etc. before making any changes. Without backups you "
"cannot restore the original state after a data loss or a misconfiguration. "
"Do not perform tests or experiments on production systems."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:145
msgid "Test Your Workloads"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:146
msgid ""
"The efficiency of a virtualization environment depends on many factors. This "
"guide provides a reference for helping to make good choices when configuring "
"virtualization in a production environment. Nothing is <emphasis>carved in "
"stone</emphasis>. Hardware, workloads, resource capacity, etc. should all be "
"considered when planning, testing, and deploying your virtualization infra-"
"structure. Testing your virtualized workloads is vital to a successful "
"virtualization implementation."
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:158
msgid "Recommendations"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:160
msgid "Prefer the <systemitem class=\"library\">libvirt</systemitem> Framework"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:163
msgid ""
"SUSE strongly recommends using the <systemitem class=\"library\">libvirt</"
"systemitem> framework to configure, manage, and operate VM Host Servers, "
"containers and VM Guest. It offers a single interface (GUI and shell) for "
"all supported virtualization technologies and therefore is easier to use "
"than the hypervisor-specific tools."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:169
msgid ""
"We do not recommend using libvirt and hypervisor-specific tools at the same "
"time, because changes done with the hypervisor-specific tools may not be "
"recognized by the libvirt tool set. See <link xlink:href=\"https://www.suse."
"com/documentation/sles-12/book_virt/data/cha_libvirt_overview.html\"/> for "
"more information on libvirt."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:180
msgid "qemu-system-i386 Compared to qemu-system-x86_64"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:183
msgid ""
"Similar to real 64-bit PC hardware, <command>qemu-system-x86_64</command> "
"supports VM Guests running a 32-bit or a 64-bit operating system. Because "
"<command>qemu-system-x86_64</command> usually also provides better "
"performance for 32-bit guests, SUSE generally recommends using <command>qemu-"
"system-x86_64</command> for both 32-bit and 64-bit VM Guests on KVM. "
"Scenarios where <command>qemu-system-i386</command> is known to perform "
"better are not supported by SUSE."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:192
msgid ""
"Xen also uses binaries from the qemu package but prefers <command>qemu-"
"system-i386</command>, which can be used for both 32-bit and 64-bit Xen VM "
"Guests. To maintain compatibility with the upstream Xen Community, SUSE "
"encourages using <command>qemu-system-i386</command> for Xen VM Guests."
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:203
msgid "VM Host Server Configuration and Resource Allocation"
msgstr ""

#. (itstool) path: sect1/para
#: xml/vt_best_practices.xml:205
msgid ""
"Allocation of resources for VM Guests is a crucial point when administrating "
"virtual machines. When assigning resources to VM Guests, be aware that "
"overcommitting resources may affect the performance of the VM Host Server "
"and the VM Guests. If all VM Guests request all their resources "
"simultaneously, the host needs to be able to provide all of them. If not, "
"the host's performance will be negatively affected and this will in turn "
"also have negative effects on the VM Guest's performance."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:216
msgid "Memory"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:217
msgid ""
"Linux manages memory in units called pages. On most systems the default page "
"size is 4 KB. Linux and the CPU need to know which pages belong to which "
"process. That information is stored in a page table. If a lot of processes "
"are running, it takes more time to find where the memory is mapped, because "
"of the time required to search the page table. To speed up the search, the "
"TLB (Translation Lookaside Buffer) was invented. But on a system with a lot "
"of memory, the TLB is not enough. To avoid any fallback to normal page table "
"(resulting in a cache miss, which is time consuming), huge pages can be "
"used. Using huge pages will reduce TLB overhead and TLB misses (pagewalk). A "
"host with 32 GB (32*1014*1024 = 33,554,432 KB) of memory and a 4 KB page "
"size has a TLB with <emphasis>33,554,432/4 = 8,388,608</emphasis> entries. "
"Using a 2 MB (2048 KB) page size, the TLB only has <emphasis>33554432/2048 = "
"16384</emphasis> entries, considerably reducing TLB misses."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:234
msgid "Configuring the VM Host Server and the VM Guest to use Huge Pages"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:235
msgid ""
"Current CPU architectures support larger pages than 4 KB: huge pages. To "
"determine the size of huge pages available on your system (could be 2 MB or "
"1 GB), check the <literal>flags</literal> line in the output of <filename>/"
"proc/cpuinfo</filename> for occurrences of <literal>pse</literal> and/or "
"<literal>pdpe1gb</literal>."
msgstr ""

#. (itstool) path: table/title
#: xml/vt_best_practices.xml:243
msgid "Determine the Available Huge Pages Size"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:250
msgid "CPU flag"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:255
msgid "Huge pages size available"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:264
msgid "Empty string"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:269
msgid "No huge pages available"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:276
msgid "pse"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:281
msgid "2 MB"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:288
msgid "pdpe1gb"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:293
msgid "1 GB"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:301
msgid ""
"Using huge pages improves performance of VM Guests and reduces host memory "
"consumption."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:305
msgid ""
"By default the system uses THP. To make huge pages available on your system, "
"activate it at boot time with <option>hugepages=1</option>, and—optionally—"
"add the huge pages size with, for example, <option>hugepagesz=2MB</option>."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:312
msgid "1 GB huge pages"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:313
msgid ""
"1 GB pages can only be allocated at boot time and cannot be freed afterward."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:318
msgid ""
"To allocate and use the huge page table (HugeTlbPage) you need to mount "
"<filename>hugetlbfs</filename> with correct permissions."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:323
msgid "Restrictions of Huge Pages"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:324
msgid ""
"Even if huge pages provide the best performance, they do come with some "
"drawbacks. You lose features such as Memory ballooning (see <xref linkend="
"\"sec.vt.best.vmguests.virtio.balloon\"/>), KSM (see <xref linkend=\"sec.vt."
"best.perf.ksm\"/>), and huge pages cannot be swapped."
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:332
msgid "Configuring the use of huge pages"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:334
msgid ""
"Mount <literal>hugetlbfs</literal> to <filename>/dev/hugepages</filename>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:338
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> mount -t hugetlbfs hugetlbfs /dev/hugepages"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:341
msgid ""
"To reserve memory for huge pages use the <command>sysctl</command> command. "
"If your system has a huge page size of 2 MB (2048 KB), and you want to "
"reserve 1 GB (1,048,576 KB) for your VM Guest, you need "
"<emphasis>1,048,576/2048=512</emphasis> pages in the pool:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:347
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> sysctl vm.nr_hugepages=<replaceable>512</replaceable>"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:348
msgid ""
"The value is written to <filename>/proc/sys/vm/nr_hugepages</filename> and "
"represents the current number of <emphasis>persistent</emphasis> huge pages "
"in the kernel's huge page pool. <emphasis>Persistent</emphasis> huge pages "
"will be returned to the huge page pool when freed by a task."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:357
msgid ""
"Add the <literal>memoryBacking</literal> element in the VM Guest "
"configuration file (by running <command>virsh edit "
"<replaceable>CONFIGURATION</replaceable></command>)."
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:362
#, no-wrap
msgid ""
"&lt;memoryBacking&gt;\n"
"  &lt;hugepages/&gt;\n"
"&lt;/memoryBacking&gt;"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:367
msgid "Start your VM Guest and check on the host whether it uses hugepages:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:370
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>cat /proc/meminfo | grep HugePages_\n"
"HugePages_Total:<co xml:id=\"co.hp.total\"/>     512\n"
"HugePages_Free:<co xml:id=\"co.hp.free\"/>       92\n"
"HugePages_Rsvd:<co xml:id=\"co.hp.rsvd\"/>        0\n"
"HugePages_Surp:<co xml:id=\"co.hp.surp\"/>        0"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:377
msgid "Size of the pool of huge pages"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:382
msgid "Number of huge pages in the pool that are not yet allocated"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:387
msgid ""
"Number of huge pages for which a commitment to allocate from the pool has "
"been made, but no allocation has yet been made"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:393
msgid ""
"Number of huge pages in the pool above the value in <filename>/proc/sys/vm/"
"nr_hugepages</filename>. The maximum number of surplus huge pages is "
"controlled by <filename>/proc/sys/vm/nr_overcommit_hugepages</filename>"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:405
msgid "Transparent Huge Pages"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:406
msgid ""
"Transparent huge pages (THP) provide a way to dynamically allocate huge "
"pages with the <command>khugepaged</command> kernel thread, rather than "
"manually managing their allocation and use. Workloads with contiguous memory "
"access patterns can benefit greatly from THP. A 1000 fold decrease in page "
"faults can be observed when running synthetic workloads with contiguous "
"memory access patterns. Conversely, workloads with sparse memory access "
"patterns (like databases) may perform poorly with THP. In such cases it may "
"be preferable to disable THP by adding the kernel parameter "
"<option>transparent_hugepage=never</option>, rebuild your grub2 "
"configuration, and reboot. Verify if THP is disabled with:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:419
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>cat /sys/kernel/mm/transparent_hugepage/enabled\n"
"always madvise [never]"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:421
msgid ""
"If disabled, the value <literal>never</literal> is shown in square brackets "
"like in the example above."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:426
msgid "Xen"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:427
msgid "THP is not available under Xen."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:433
msgid "Xen-specific Memory Notes"
msgstr ""

#. (itstool) path: sect4/title
#: xml/vt_best_practices.xml:435
msgid "Managing Domain-0 Memory"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:436
msgid ""
"When using the Xen hypervisor, by default a small percentage of system "
"memory is reserved for the hypervisor. All remaining memory is automatically "
"allocated to Domain-0. When virtual machines are created, memory is "
"ballooned out of Domain-0 to provide memory for the virtual machine. This "
"process is called \"autoballooning\"."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:443
msgid "Autoballooning has several limitations:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:448
msgid ""
"Reduced performance while dom0 is ballooning down to free memory for the new "
"domain."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:454
msgid ""
"Memory freed by ballooning is not confined to a specific NUMA node. This can "
"result in performance problems in the new domain because of using a non-"
"optimal NUMA configuration."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:461
msgid ""
"Failure to start large domains because of delays while ballooning large "
"amounts of memory from dom0."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:467
msgid ""
"For these reasons, we strongly recommend to disable autoballooning and give "
"Domain-0 the memory needed for its workload. Determining Domain-0 memory and "
"vCPU sizing should follow a similar process as any other virtual machine."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:473
msgid ""
"Autoballooning is controlled by the toolstack used to manage your Xen "
"installation. For the xl/libxl toolstack, autoballooning is controlled by "
"the <option>autoballoon</option> setting in <filename>/etc/xen/xl.conf</"
"filename>. For the libvirt+libxl toolstack, autoballooning is controlled by "
"the <option>autoballoon</option> setting in <filename>/etc/libvirt/libxl."
"conf</filename>."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:481
msgid ""
"The amount of memory initially allocated to Domain-0 is controlled by the "
"Xen hypervisor dom0_mem parameter. For example, to set the initial memory "
"allocation of Domain-0 to 8GB, add <option>dom0_mem=8G</option> to the Xen "
"hypervisor parameters. The dom0_mem parameter can also be used to specify "
"the minimum and maximum memory allocations for Domain-0. For example, to set "
"the initial memory of Domain-0 to 8GB, but allow it to be changed "
"(ballooned) anywhere between 4GB and 16GB, add the following to the Xen "
"hypervisor parameters: <option>dom0_mem=8G,min:4G,max:8G</option>."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:493
msgid ""
"To set dom0_mem on SLE 11 products, modify <filename>/boot/grub/menu.lst</"
"filename>, adding <option>dom0_mem=XX</option> to the Xen hypervisor (xen."
"gz) parameters. The change will be applied at next reboot."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:501
msgid ""
"To set dom0_mem on SLE 12 products, modify <filename>/etc/default/grub</"
"filename>, adding <option>dom0_mem=XX</option> to "
"<option>GRUB_CMDLINE_XEN_DEFAULT</option>. See <xref linkend=\"sec.vt.best."
"kernel.parameter\"/> for more information."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:510
msgid ""
"Autoballooning is enabled by default since it is extremely difficult to "
"determine a predefined amount of memory required by Domain-0. Memory needed "
"by Domain-0 is heavily dependent on the number of hosted virtual machines "
"and their configuration. Users must ensure Domain-0 has sufficient memory "
"resources to accommodate virtual machine workloads."
msgstr ""

#. (itstool) path: sect4/title
#: xml/vt_best_practices.xml:520
msgid "xenstore in <systemitem>tmpfs</systemitem>"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:521
msgid ""
"When using Xen, we recommend to place the xenstore database on "
"<systemitem>tmpfs</systemitem>. xenstore is used as a control plane by the "
"xm/xend and xl/libxl toolstacks and the front-end and back-end drivers "
"servicing domain I/O devices. The load on xenstore increases linearly as the "
"number of running domains increase. If you anticipate hosting many VM Guest "
"on a Xen host, move the xenstore database onto tmpfs to improve overall "
"performance of the control plane. Mount the <filename>/var/lib/xenstored</"
"filename> directory on tmpfs:"
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:531
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> mount -t tmpfs tmpfs /var/lib/xenstored/"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:535
msgid "KSM and Page Sharing"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:536
msgid ""
"Kernel Samepage Merging is a kernel feature that allows for lesser memory "
"consumption on the VM Host Server by sharing data VM Guests have in common. "
"The KSM daemon <systemitem class=\"daemon\">ksmd</systemitem> periodically "
"scans user memory looking for pages of identical content which can be "
"replaced by a single write-protected page. To enable KSM, run:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:543
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> echo 1 &gt; /sys/kernel/mm/ksm/run"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:544
msgid ""
"One advantage of using KSM from a VM Guest's perspective is that all guest "
"memory is backed by host anonymous memory. You can share "
"<emphasis>pagecache</emphasis>, <emphasis>tmpfs</emphasis> or any kind of "
"memory allocated in the guest."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:550
msgid ""
"KSM is controlled by <systemitem>sysfs</systemitem>. You can check KSM's "
"values in <filename>/sys/kernel/mm/ksm/</filename>:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:556
msgid ""
"<literal>pages_shared</literal>: The number of shared pages that are being "
"used (read-only)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:562
msgid ""
"<literal>pages_sharing</literal>: The number of sites sharing the pages "
"(read-only)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:568
msgid ""
"<literal>pages_unshared</literal>: The number of pages that are unique and "
"repeatedly checked for merging (read-only)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:574
msgid ""
"<literal>pages_volatile</literal>: The number of pages that are changing too "
"fast to be considered for merging (read-only)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:580
msgid ""
"<literal>full_scans</literal>: The number of times all mergeable areas have "
"been scanned (read-only)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:586
msgid ""
"<literal>sleep_millisecs</literal>: The number of milliseconds <systemitem "
"class=\"daemon\">ksmd</systemitem> should sleep before the next scan. A low "
"value will overuse the CPU, consuming CPU time that could be used for other "
"tasks. We recommend a value greater than <literal>1000</literal>."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:595
msgid ""
"<literal>pages_to_scan</literal>: The number of present pages to scan before "
"ksmd goes to sleep. A high value will overuse the CPU. We recommend to start "
"with a value of <literal>1000</literal>, and then adjust as necessary based "
"on the KSM results observed while testing your deployment."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:604
msgid ""
"<literal>merge_across_nodes</literal>: By default the system merges pages "
"across NUMA nodes. Set this option to <literal>0</literal> to disable this "
"behavior."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:612
msgid "Use Cases"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:613
msgid ""
"KSM is a good technique to over-commit host memory when running multiple "
"instances of the same application or VM Guest. When applications and VM "
"Guest are heterogeneous and do not share any common data, it is preferable "
"to disable KSM. In a mixed heterogeneous and homogeneous environment, KSM "
"can be enabled on the host but disabled on a per VM Guest basis. Use "
"<command>virsh edit</command> to disable page sharing of a VM Guest by "
"adding the following to the guest's XML configuration:"
msgstr ""

#. (itstool) path: note/screen
#: xml/vt_best_practices.xml:623
#, no-wrap
msgid ""
"&lt;memoryBacking&gt;\n"
"   &lt;nosharepages/&gt;\n"
"&lt;/memoryBacking&gt;"
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:628
msgid "Avoid Out-of-Memory Conditions"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:629
msgid ""
"KSM can free up some memory on the host system, but the administrator should "
"reserve enough swap to avoid out-of-memory conditions if that shareable "
"memory decreases. If the amount of shareable memory decreases, the use of "
"physical memory is increased."
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:637
msgid "Memory Access Latencies"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:638
msgid ""
"By default, KSM will merge common pages across NUMA nodes. If the merged, "
"common page is now located on a distant NUMA node (relative to the node "
"running the VM Guest vCPUs), this may degrade VM Guest performance. If "
"increased memory access latencies are noticed in the VM Guest, disable cross-"
"node merging with the <literal>merge_across_nodes</literal> sysfs control:"
msgstr ""

#. (itstool) path: warning/screen
#: xml/vt_best_practices.xml:646
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> echo 0 &gt; /sys/kernel/mm/ksm/merge_across_nodes"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:650
msgid "VM Guest: Memory Hotplug"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:651
msgid ""
"To optimize the usage of your host memory, it may be useful to hotplug more "
"memory for a running VM Guest when required. To support memory hotplugging, "
"you must first configure the <literal>&lt;maxMemory&gt;</literal> tag in the "
"VM Guest's configuration file:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:658
#, no-wrap
msgid ""
"&lt;maxMemory<co xml:id=\"co.mem.hot.max\"/> slots='16'<co xml:id=\"co.mem.hot.slots\"/> unit='KiB'&gt;20971520<co xml:id=\"co.mem.hot.size\"/>&lt;/maxMemory&gt;\n"
"  &lt;memory<co xml:id=\"co.mem.hot.mem\"/> unit='KiB'&gt;1048576&lt;/memory&gt;\n"
"&lt;currentMemory<co xml:id=\"co.mem.hot.curr\"/> unit='KiB'&gt;1048576&lt;/currentMemory&gt;"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:663
msgid "Runtime maximum memory allocation of the guest."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:668
msgid "Number of slots available for adding memory to the guest"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:673
msgid "Valid units are:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:678
msgid "\"KB\" for kilobytes (1,000 bytes)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:683
msgid "\"k\" or \"KiB\" for kibibytes (1,024 bytes)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:688
msgid "\"MB\" for megabytes (1,000,000 bytes)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:693
msgid "\"M\" or \"MiB\" for mebibytes (1,048,576 bytes)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:698
msgid "\"GB\" for gigabytes (1,000,000,000 bytes)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:703
msgid "\"G\" or \"GiB\" for gibibytes (1,073,741,824 bytes)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:708
msgid "\"TB\" for terabytes (1,000,000,000,000 bytes)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:713
msgid "\"T\" or \"TiB\" for tebibytes (1,099,511,627,776 bytes)"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:720
msgid "Maximum allocation of memory for the guest at boot time"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:725
msgid "Actual allocation of memory for the guest"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:730
msgid ""
"To hotplug memory devices into the slots, create a file <filename>mem-dev."
"xml</filename> like the following:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:734
#, no-wrap
msgid ""
"&lt;memory model='dimm'&gt;\n"
"  &lt;target&gt;\n"
"  &lt;size unit='KiB'&gt;524287&lt;/size&gt;\n"
"  &lt;node&gt;0&lt;/node&gt;\n"
"  &lt;/target&gt;\n"
"&lt;/memory&gt;"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:740
msgid "And attach it with the following command:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:743
#, no-wrap
msgid "<prompt>tux &gt; </prompt>virsh attach-device vm-name mem-dev.xml"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:744
msgid ""
"For memory device hotplug, the guest must have at least 1 NUMA cell defined "
"(see <xref linkend=\"sec.vt.best.perf.numa.vmguest.topo\"/>)."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:752
msgid "Swap"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:753
msgid ""
"<emphasis>Swap</emphasis> is usually used by the system to store underused "
"physical memory (low usage, or not accessed for a long time). To prevent the "
"system running out of memory, setting up a minimum swap is highly "
"recommended."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:760
msgid "<literal>swappiness</literal>"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:761
msgid ""
"The <literal>swappiness</literal> setting controls your system's swap "
"behavior. It defines how memory pages are swapped to disk. A high value of "
"<emphasis>swappiness</emphasis> results in a system that swaps more often. "
"Available values range from <literal>0</literal> to <literal>100</literal>. "
"A value of <literal>100</literal> tells the system to find inactive pages "
"and put them in swap. A value of <option>0</option> disables swapping."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:773
msgid ""
"To do some testing on a live system, change the value of <filename>/proc/sys/"
"vm/swappiness</filename> on the fly and check the memory usage afterward:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:778
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> echo 35 &gt; /proc/sys/vm/swappiness"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:779
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>free -h\n"
"total       used       free     shared    buffers     cached\n"
"Mem:      24616680    4991492   19625188     167056     144340    2152408\n"
"-/+ buffers/cache:    2694744   21921936\n"
"Swap:      6171644          0    6171644"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:784
msgid ""
"To permanently set a swappiness value, add a line in <filename>/etc/systcl."
"conf</filename>, for example:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:788
#, no-wrap
msgid "vm.swappiness = 35"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:789
msgid ""
"You can also control the swap by using the <literal>swap_hard_limit</"
"literal> element in the XML configuration of your VM Guest. Before setting "
"this parameter and using it in a production environment, do some testing "
"because the host can terminate the domain if the value is too low."
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:796
#, no-wrap
msgid ""
"&lt;memtune&gt;<co xml:id=\"co.mem.1\"/>\n"
"  &lt;hard_limit unit='G'&gt;1&lt;/hard_limit&gt;<co xml:id=\"co.mem.hard\"/>\n"
"  &lt;soft_limit unit='M'&gt;128&lt;/soft_limit&gt;<co xml:id=\"co.mem.soft\"/>\n"
"  &lt;swap_hard_limit unit='G'&gt;2&lt;/swap_hard_limit&gt;<co xml:id=\"co.mem.swap\"/>\n"
"&lt;/memtune&gt;"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:803
msgid ""
"This element provides memory tunable parameters for the domain. If this is "
"omitted, it defaults to the defaults provided b the operating system."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:810
msgid ""
"Maximum memory the guest can use. To avoid any problems on the VM Guest it "
"is strongly recommended not to use this parameter."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:816
msgid "The memory limit to enforce during memory contention."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:821
msgid "The maximum memory plus swap the VM Guest can use."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:830
msgid "I/O"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:833
msgid "I/O Scheduler"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:834
msgid ""
"The default I/O scheduler is Completely Fair Queuing (CFQ). The main aim of "
"the CFQ scheduler is to provide a fair allocation of the disk I/O bandwidth "
"for all processes that request an I/O operation. You can have different I/O "
"schedulers for different devices."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:840
msgid ""
"To get better performance in host and VM Guest, use <literal>noop</literal> "
"in the VM Guest (disable the I/O scheduler) and the <literal>deadline</"
"literal> scheduler for a virtualization host."
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:846
msgid "Checking and Changing the I/O Scheduler at Runtime"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:848
msgid ""
"To check your current I/O scheduler for your disk (replace <replaceable>sdX</"
"replaceable> by the disk you want to check), run:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:852
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>cat /sys/block/<replaceable>sdX</replaceable>/queue/scheduler\n"
"noop deadline [cfq]"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:854
msgid ""
"The value in square brackets is the one currently selected (<literal>cfq</"
"literal> in the example above)."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:860
msgid "You can change the scheduler at runtime with the following command:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:863
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> echo deadline &gt; /sys/block/<replaceable>sdX</replaceable>/queue/scheduler"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:867
msgid ""
"To permanently set an I/O scheduler for all disks of a system, use the "
"kernel parameter <literal>elevator</literal>. The respective values are "
"<option>elevator=deadline</option> for the VM Host Server and "
"<option>elevator=noop</option> for VM Guests. See <xref linkend=\"sec.vt."
"best.kernel.parameter\"/> for further instructions."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:874
msgid ""
"If you need to specify different I/O schedulers for each disk, create the "
"file <filename>/usr/lib/tmpfiles.d/IO_ioscheduler.conf</filename> with a "
"content similar to the following example. It defines the <literal>deadline</"
"literal> scheduler for <filename>/dev/sda</filename> and the <literal>noop</"
"literal> scheduler for <filename>/dev/sdb</filename>. This feature is "
"available on SLE 12 only."
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:883
#, no-wrap
msgid ""
"w /sys/block/sda/queue/scheduler - - - - deadline\n"
"w /sys/block/sdb/queue/scheduler - - - - noop"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:887
msgid "Asynchronous I/O"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:888
msgid ""
"Many of the virtual disk backends use Linux Asynchronous I/O (aio) in their "
"implementation. By default, the maximum number aio contexts is set to 65536, "
"which can be exceeded when running hundreds of VM Guests using virtual disks "
"serviced by Linux Asynchronous I/O. When running large numbers of VM Guests "
"on a VM Host Server, consider increasing /proc/sys/fs/aio-max-nr."
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:897
msgid "Checking and Changing aio-max-nr at Runtime"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:899
msgid "To check your current aio-max-nr setting run:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:902
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>cat /proc/sys/fs/aio-max-nr\n"
"65536"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:906
msgid "You can change aio-max-nr at runtime with the following command:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:909
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> echo 131072 &gt; /proc/sys/fs/aio-max-nr"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:912
msgid ""
"To permanently set aio-max-nr, add an entry to a local sysctl file. For "
"example, append the following to <filename>/etc/sysctl.d/99-sysctl.conf</"
"filename>:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:916
#, no-wrap
msgid "fs.aio-max-nr = 1048576"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:919
msgid "I/O Virtualization"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:920
msgid ""
"SUSE products support various I/O virtualization technologies. The following "
"table lists advantages and disadvantages of each technology. For more "
"information about I/O in virtualization refer to the <link xlink:href="
"\"https://www.suse.com/documentation/sles-12/book_virt/data/sec_vt_io.html"
"\">I/O in Virtualization</link> chapter in the <citetitle><phrase role="
"\"productname\"><phrase os=\"osuse\">openSUSE Leap</phrase><phrase os=\"sles"
"\">SUSE Linux Enterprise Server</phrase><phrase os=\"sled\">SUSE Linux "
"Enterprise Desktop</phrase></phrase> <phrase role=\"productnumber\"><phrase "
"os=\"osuse\">15.0</phrase><phrase os=\"sles;sled\">15</phrase></phrase> "
"Virtualization Guide</citetitle>."
msgstr ""

#. (itstool) path: table/title
#: xml/vt_best_practices.xml:930
msgid "I/O Virtualization Solutions"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:938 xml/vt_best_practices.xml:1094
msgid "Technology"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:943
msgid "Advantage"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:948
msgid "Disadvantage"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:957
msgid "Device Assignment (pass-through)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:963
msgid "Device accessed directly by the guest"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:968
msgid "No sharing among multiple guests"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:975
msgid "High performance"
msgstr ""

#. (itstool) path: entry/para
#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:980 xml/vt_best_practices.xml:1139
msgid "Live migration is complex"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:990
msgid "PCI device limit is 8 per guest"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1000
msgid "Limited number of slots on a server"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1007
msgid "Full virtualization (IDE, SATA, SCSI, e1000)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1013
msgid "VM Guest compatibility"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1018
msgid "Bad performance"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1025 xml/vt_best_practices.xml:1055
msgid "Easy for live migration"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1030
msgid "Emulated operation"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1037
msgid "Para-virtualization (virtio-blk, virtio-net, virtio-scsi)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1043
msgid "Good performance"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1048
msgid "Modified guest (PV drivers)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1065
msgid "Efficient host communication with VM Guest"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:1080
msgid "Storage and File System"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1081
msgid ""
"Storage space for VM Guests can either be a block device (for example, a "
"partition on a physical disk), or an image file on the file system:"
msgstr ""

#. (itstool) path: table/title
#: xml/vt_best_practices.xml:1086
msgid "Block Devices Compared to Disk Images"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1099
msgid "Advantages"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1104
msgid "Disadvantages"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1113
msgid "Block devices"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1120
msgid "Better performance"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1125
msgid "Use standard tools for administration/disk modification"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1130
msgid "Accessible from host (pro and con)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1144
msgid "Impossible to increase capacity"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:1153
msgid "Image files"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1160
msgid "Easier system management"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1165
msgid "Easily move, clone, expand, back up domains"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1170
msgid "Comprehensive toolkit (guestfs) for image manipulation"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1175
msgid "Reduce overhead through sparse files"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1180
msgid "Fully allocate for best performance"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1189
msgid "Lower performance than block devices"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1217
msgid ""
"For detailed information about image formats and maintaining images refer to "
"<xref linkend=\"sec.vt.best.img\"/>."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1222
msgid ""
"If your image is stored on an NFS share, you should check some server and "
"client parameters to improve access to the VM Guest image."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1227
msgid "NFS Read/Write (Client)"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1228
msgid ""
"Options <option>rsize</option> and <option>wsize</option> specify the size "
"of the chunks of data that the client and server pass back and forth to each "
"other. You should ensure NFS read/write sizes are sufficiently large, "
"especially for large I/O. Change the <option>rsize</option> and "
"<option>wsize</option> parameter in your <filename>/etc/fstab</filename> by "
"increasing the value to 16 KB. This will ensure that all operations can be "
"frozen if there is any instance of hanging."
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:1237
#, no-wrap
msgid "nfs_server:/exported/vm_images<co xml:id=\"co.nfs.server\"/> /mnt/images<co xml:id=\"co.nfs.mnt\"/> nfs<co xml:id=\"co.nfs.nfs\"/> rw<co xml:id=\"co.nfs.rw\"/>,hard<co xml:id=\"co.nfs.hard\"/>,sync<co xml:id=\"co.nfs.sync\"/>, rsize=8192<co xml:id=\"co.nfs.rsize\"/>,wsize=8192<co xml:id=\"co.nfs.wsize\"/> 0 0"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1240
msgid "NFS server's host name and export path name."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1245
msgid "Where to mount the NFS exported share."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1250
msgid "This is an <option>nfs</option> mount point."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1255
msgid "This mount point will be accessible in read/write."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1260
msgid ""
"Determines the recovery behavior of the NFS client after an NFS request "
"times out. <option>hard</option> is the best option to avoid data corruption."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1267
msgid ""
"Any system call that writes data to files on that mount point causes that "
"data to be flushed to the server before the system call returns control to "
"user space."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1274
msgid ""
"Maximum number of bytes in each network READ request that the NFS client can "
"receive when reading data from a file on an NFS server."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1280
msgid ""
"Maximum number of bytes per network WRITE request that the NFS client can "
"send when writing data to a file on an NFS server."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1288
msgid "NFS Threads (Server)"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1289
msgid ""
"Your NFS server should have enough NFS threads to handle multi-threaded "
"workloads. Use the <command>nfsstat</command> tool to get some RPC "
"statistics on your server:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:1294
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt><command>sudo</command> nfsstat -rc\n"
"Client rpc stats:\n"
"calls      retrans    authrefrsh\n"
"6401066    198          0          0"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1298
msgid ""
"If the <literal>retrans</literal> is equal to 0, everything is fine. "
"Otherwise, the client needs to retransmit, so increase the "
"<envar>USE_KERNEL_NFSD_NUMBER</envar> variable in <filename>/etc/sysconfig/"
"nfs</filename>, and adjust accordingly until <literal>retrans</literal> is "
"equal to <literal>0</literal>."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:1309
msgid "CPUs"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1310
msgid ""
"Host CPU <quote>components</quote> will be <quote>translated</quote> to "
"virtual CPUs in a VM Guest when being assigned. These components can either "
"be:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1317
msgid ""
"<emphasis>CPU processor</emphasis>: this describes the main CPU unit, which "
"usually has multiple cores and may support Hyper-Threading."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1323
msgid ""
"<emphasis>CPU core</emphasis>: a main CPU unit can provide more than one "
"core, and the proximity of cores speeds up the computation process and "
"reduces energy costs."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1330
msgid ""
"<emphasis>CPU Hyper-Threading</emphasis>: this implementation is used to "
"improve parallelization of computations, but this is not as efficient as a "
"dedicated core."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1339
msgid "Assigning CPUs"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1340
msgid ""
"You should avoid overcommitting CPUs. Unless you know exactly how many "
"virtual CPUs are required for a VM Guest, you should start with a single "
"virtual CPU per VM Guest. Each virtual CPU should match one hardware "
"processor or core on the VM Host Server."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1346
msgid ""
"You should target a CPU workload of approximately 70% inside your VM (see "
"<link xlink:href=\"https://www.suse.com/documentation/sles-12/"
"book_sle_tuning/data/sec_util_processes.html\"/> for information on "
"monitoring tools). If you allocate more processors than needed in the VM "
"Guest, this will negatively affect the performance of host and guest: cycle "
"efficiency will be degraded, the unused vCPU will consume timer interrupts "
"and will idle-loop. In case you primarily run single threaded applications "
"on a VM Guest, a single virtual CPU is the best choice."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1357
msgid "VM Guest CPU Configuration"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1358
msgid ""
"This section describes how to choose and configure a CPU type for a VM "
"Guest. You will also learn how to pin virtual CPUs to physical CPUs on the "
"host system. For more information about virtual CPU configuration and tuning "
"parameters refer to the libvirt documentation at <link xlink:href=\"https://"
"libvirt.org/formatdomain.html#elementsCPU\"/>."
msgstr ""

#. (itstool) path: sect4/title
#: xml/vt_best_practices.xml:1366
msgid "Virtual CPU Models and Features"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1367
msgid ""
"The CPU model and topology can be specified individually for each VM Guest. "
"Configuration options range from selecting specific CPU models to excluding "
"certain CPU features. Predefined CPU models are listed in the <filename>/usr/"
"share/libvirt/cpu_map.xml</filename>. A CPU model and topology that is "
"similar to the host generally provides the best performance. The host system "
"CPU model and topology can be displayed by running <command>virsh "
"capabilities</command>."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1376
msgid ""
"Note that changing the default virtual CPU configuration will require a VM "
"Guest shutdown when migrating it to a host with different hardware. More "
"information on VM Guest migration is available at <link xlink:href=\"https://"
"www.suse.com/documentation/sles-12/book_virt/data/sec_libvirt_admin_migrate."
"html\"/>."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1382
msgid ""
"To specify a particular CPU model for a VM Guest, add a respective entry to "
"the VM Guest configuration file. The following example configures a "
"Broadwell CPU with the invariant TSC feature:"
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1387
#, no-wrap
msgid ""
"&lt;cpu mode='custom' match='exact'&gt;\n"
"  &lt;model&gt;Broadwell&lt;/model&gt;\n"
"  &lt;feature name='invtsc'/&gt;\n"
"  &lt;/cpu&gt;"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1391
msgid ""
"For a virtual CPU that most closely resembles the host physical CPU, "
"<literal>&lt;cpu mode='host-passthrough'&gt;</literal> can be used. Note "
"that a <literal>host-passthrough</literal> CPU model may not exactly "
"resemble the host physical CPU, since by default KVM will mask any non-"
"migratable features. For example invtsc is not included in the virtual CPU "
"feature set. Changing the default KVM behavior is not directly supported "
"through libvirt, although it does allow arbitrary passthrough of KVM command "
"line arguments. Continuing with the <literal>invtsc</literal> example, you "
"can achieve passthrough of the host CPU (including <literal>invtsc</"
"literal>) by the following command line passthrough in VM Guest "
"configuration file:"
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1404
#, no-wrap
msgid ""
"&lt;domain type='kvm' xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0'&gt;\n"
"     &lt;qemu:commandline&gt;\n"
"     &lt;qemu:arg value='-cpu'/&gt;\n"
"     &lt;qemu:arg value='host,migratable=off,+invtsc'/&gt;\n"
"     &lt;/qemu:commandline&gt;\n"
"     ...\n"
"     &lt;/domain&gt;\n"
"     "
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:1413
msgid "The <literal>host-passthrough</literal> Mode"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:1414
msgid ""
"Since <literal>host-passthrough</literal> exposes the physical CPU details "
"to the virtual CPU, migration to dissimilar hardware is not possible. See "
"<xref linkend=\"sec.vt.best.perf.cpu.guests.vcpumigration\"/> for more "
"information."
msgstr ""

#. (itstool) path: sect4/title
#: xml/vt_best_practices.xml:1424
msgid "Virtual CPU Pinning"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1425
msgid ""
"Virtual CPU pinning is used to constrain virtual CPU threads to a set of "
"physical CPUs. The <literal>vcpupin</literal> element specifies the physical "
"host CPUs that a virtual CPU can use. If this element is not set and the "
"attribute <literal>cpuset</literal> of the <literal>vcpu</literal> element "
"is not specified, the virtual CPU is free to use any of the physical CPUs."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1433
msgid ""
"CPU intensive workloads can benefit from virtual CPU pinning by increasing "
"the physical CPU cache hit ratio. To pin a virtual CPU to a specific "
"physical CPU, run the following commands:"
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1438
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>virsh vcpupin <replaceable>DOMAIN_ID</replaceable> --vcpu <replaceable>vCPU_NUMBER</replaceable>\n"
"VCPU: CPU Affinity\n"
"----------------------------------\n"
"0: 0-7\n"
"<prompt role=\"root\">root # </prompt>virsh vcpupin SLE12 --vcpu 0 0 --config"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1443
msgid ""
"The last command generates the following entry in the XML configuration:"
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1446
#, no-wrap
msgid ""
"&lt;cputune&gt;\n"
"   &lt;vcpupin vcpu='0' cpuset='0'/&gt;\n"
"&lt;/cputune&gt;"
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:1450
msgid "Virtual CPU Pinning on NUMA Nodes"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:1451
msgid ""
"To confine a VM Guest's CPUs and its memory to a NUMA node, you can use "
"virtual CPU pinning and memory allocation policies on a NUMA system. See "
"<xref linkend=\"sec.vt.best.perf.numa\"/> for more information related to "
"NUMA tuning."
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:1459
msgid "Virtual CPU Pinning and Live Migration"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:1460
msgid ""
"Even though <literal>vcpupin</literal> can improve performance, it can "
"complicate live migration. See <xref linkend=\"sec.vt.best.perf.cpu.guests."
"vcpumigration\"/> for more information on virtual CPU migration "
"considerations."
msgstr ""

#. (itstool) path: sect4/title
#: xml/vt_best_practices.xml:1469
msgid "Virtual CPU Migration Considerations"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1470
msgid ""
"Selecting a virtual CPU model containing all the latest features may improve "
"performance of a VM Guest workload—but often at the expense of "
"migratability. Unless all hosts in the cluster contain the latest CPU "
"features, migration can fail when a destination host lacks the new features. "
"If migratability of a virtual CPU is preferred over the latest CPU features, "
"a normalized CPU model and feature set should be used. The <command>virsh "
"cpu-baseline</command> command can help define a normalized virtual CPU that "
"can be migrated across all hosts. The following command, when run on each "
"host in the migration cluster, illustrates collection of all hosts' "
"capabilities in <literal>all-hosts-caps.xml</literal>."
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1483
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> virsh capabilities &gt;&gt; all-hosts-cpu-caps.xml"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1484
msgid ""
"With the capabilities from each host collected in all-hosts-caps.xml, use "
"<command>virsh cpu-baseline</command> to create a virtual CPU definition "
"that will be compatible across all hosts."
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1489
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> virsh cpu-baseline all-hosts-caps.xml"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1490
msgid ""
"The resulting virtual CPU definition can be used as the <literal>cpu</"
"literal> element in VM Guest configuration file."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1494
msgid ""
"At a logical level, virtual CPU pinning is a form of hardware passthrough. "
"Pinning couples physical resources to virtual resources, and can also be "
"problematic for migration. For example, the migration will fail if the "
"requested physical resources are not available on the destination host, or "
"if the source and destination hosts have different NUMA topologies. For more "
"recommendations about Live Migration see <link xlink:href=\"https://www.suse."
"com/documentation/sles-12/book_virt/data/sec_libvirt_admin_migrate."
"html#libvirt_admin_live_migration_requirements\">Virtualization Live "
"Migration Requirements</link>."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:1510
msgid "NUMA Tuning"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1511
msgid ""
"NUMA is an acronym for Non Uniform Memory Access. A NUMA system has multiple "
"physical CPUs, each with local memory attached. Each CPU can also access "
"other CPUs' memory, known as <quote>remote memory access</quote>, but it is "
"much slower than accessing local memory. NUMA systems can negatively impact "
"VM Guest performance if not tuned properly. Although ultimately tuning is "
"workload dependent, this section describes controls that should be "
"considered when deploying VM Guests on NUMA hosts. Always consider your host "
"topology when configuring and deploying VMs."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1521
msgid ""
"<phrase role=\"productname\"><phrase os=\"osuse\">openSUSE Leap</"
"phrase><phrase os=\"sles\">SUSE Linux Enterprise Server</phrase><phrase os="
"\"sled\">SUSE Linux Enterprise Desktop</phrase></phrase> contains a NUMA "
"auto-balancer that strives to reduce remote memory access by placing memory "
"on the same NUMA node as the CPU processing it. In addition, standard tools "
"such as <command>cgset</command> and virtualization tools such as libvirt "
"provide mechanisms to constrain VM Guest resources to physical resources."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1528
msgid "<command>numactl</command> is used to check for host NUMA capabilities:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:1531
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt><command>sudo</command> numactl --hardware\n"
"available: 4 nodes (0-3)\n"
"node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 72 73 74 75 76 77 78\n"
"79 80 81 82 83 84 85 86 87 88 89\n"
"node 0 size: 31975 MB\n"
"node 0 free: 31120 MB\n"
"node 1 cpus: 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 90 91 92 93\n"
"94 95 96 97 98 99 100 101 102 103 104 105 106 107\n"
"node 1 size: 32316 MB\n"
"node 1 free: 31673 MB\n"
"node 2 cpus: 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 108 109 110\n"
"111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n"
"node 2 size: 32316 MB\n"
"node 2 free: 31726 MB\n"
"node 3 cpus: 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 126 127 128\n"
"129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n"
"node 3 size: 32314 MB\n"
"node 3 free: 31387 MB\n"
"node distances:\n"
"node   0   1   2   3\n"
"0:  10  21  21  21\n"
"1:  21  10  21  21\n"
"2:  21  21  10  21\n"
"3:  21  21  21  10"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1555
msgid ""
"The <command>numactl</command> output shows this is a NUMA system with 4 "
"nodes or cells, each containing 36 CPUs and approximately 32G memory. "
"<command>virsh capabilities</command> can also be used to examine the "
"systems NUMA capabilities and CPU topology."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1562
msgid "NUMA Balancing"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1563
msgid ""
"On NUMA machines, there is a performance penalty if remote memory is "
"accessed by a CPU. Automatic NUMA balancing scans a task's address space and "
"unmaps pages. By doing so, it detects whether pages are properly placed or "
"whether to migrate the data to a memory node local to where the task is "
"running. In defined intervals (configured with "
"<literal>numa_balancing_scan_delay_ms</literal>), the task scans the next "
"scan size number of pages (configured with "
"<literal>numa_balancing_scan_size_mb</literal>) in its address space. When "
"the end of the address space is reached the scanner restarts from the "
"beginning."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1575
msgid ""
"Higher scan rates cause higher system overhead as page faults must be "
"trapped and data needs to be migrated. However, the higher the scan rate, "
"the more quickly a task's memory is migrated to a local node when the "
"workload pattern changes. This minimizes the performance impact because of "
"remote memory accesses. These <command>sysctl</command> directives control "
"the thresholds for scan delays and the number of pages scanned:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:1583
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt><command>sudo</command> sysctl -a | grep numa_balancing\n"
"kernel.numa_balancing = 1<co xml:id=\"co.numa.balancing\"/>\n"
"kernel.numa_balancing_scan_delay_ms = 1000<co xml:id=\"co.numa.delay\"/>\n"
"kernel.numa_balancing_scan_period_max_ms = 60000<co xml:id=\"co.numa.pmax\"/>\n"
"kernel.numa_balancing_scan_period_min_ms = 1000<co xml:id=\"co.numa.pmin\"/>\n"
"kernel.numa_balancing_scan_size_mb = 256<co xml:id=\"co.numa.size\"/>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1591
msgid "Enables/disables automatic page fault-based NUMA balancing"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1596
msgid "Starting scan delay used for a task when it initially forks"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1601
msgid "Maximum time in milliseconds to scan a task's virtual memory"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1606
msgid "Minimum time in milliseconds to scan a task's virtual memory"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1611
msgid "Size in megabytes' worth of pages to be scanned for a given scan"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1616
msgid ""
"For more information see <link xlink:href=\"https://www.suse.com/"
"documentation/sles-12/book_sle_tuning/data/cha_tuning_numactl.html\"/>."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1620
msgid ""
"The main goal of automatic NUMA balancing is either to reschedule tasks on "
"the same node's memory (so the CPU follows the memory), or to copy the "
"memory's pages to the same node (so the memory follows the CPU)."
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:1626
msgid "Task Placement"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:1627
msgid ""
"There are no rules to define the best place to run a task, because tasks "
"could share memory with other tasks. For best performance, it is recommended "
"to group tasks sharing memory on the same node. Check NUMA statistics with "
"<command># cat /proc/vmstat | grep numa_</command>."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1636
msgid "Memory Allocation Control with the CPUset Controller"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1637
msgid ""
"The cgroups cpuset controller can be used confine memory used by a process "
"to a NUMA node. There are three cpuset memory policy modes available:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1644
msgid ""
"<literal>interleave</literal>: This is a memory placement policy which is "
"also known as round-robin. This policy can provide substantial improvements "
"for jobs that need to place thread local data on the corresponding node. "
"When the interleave destination is not available, it will be moved to "
"another node."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1653
msgid ""
"<literal>bind</literal>: This will place memory only on one node, which "
"means in case of insufficient memory, the allocation will fail."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1659
msgid ""
"<literal>preferred</literal>: This policy will apply a preference to "
"allocate memory to a node. If there is not enough space for memory on this "
"node, it will fall back to another node."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1666
msgid ""
"You can change the memory policy mode with the <command>cgset</command> tool "
"from the <package>libcgroup-tools</package> package:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:1670
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> cgset -r cpuset.mems=<replaceable>NODE</replaceable> sysdefault/libvirt/qemu/<replaceable>KVM_NAME</replaceable>/emulator"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1671
msgid ""
"To migrate pages to a node, use the <command>migratepages</command> tool:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:1675
#, no-wrap
msgid "<prompt>tux &gt; </prompt>migratepages <replaceable>PID</replaceable> <replaceable>FROM-NODE</replaceable> <replaceable>TO-NODE</replaceable>"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1676
msgid ""
"To check everything is fine. use: <command>cat /proc/<replaceable>PID</"
"replaceable>/status | grep Cpus</command>."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:1681
msgid "Kernel NUMA/cpuset memory policy"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:1682
msgid ""
"For more information see <link xlink:href=\"https://www.kernel.org/doc/"
"Documentation/vm/numa_memory_policy.txt\">Kernel NUMA memory policy</link> "
"and <link xlink:href=\"https://www.kernel.org/doc/Documentation/cgroup-v1/"
"cpusets.txt\">cpusets memory policy</link>. Check also the <link xlink:href="
"\"https://libvirt.org/formatdomain.html#elementsNUMATuning\">Libvirt NUMA "
"Tuning documentation</link>."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1694
msgid "VM Guest: NUMA Related Configuration"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:1695
msgid ""
"<systemitem class=\"library\">libvirt</systemitem> allows to set up virtual "
"NUMA and memory access policies. Configuring these settings is not supported "
"by <command>virt-install</command> or <command>virt-manager</command> and "
"needs to be done manually by editing the VM Guest configuration file with "
"<command>virsh edit</command>."
msgstr ""

#. (itstool) path: sect4/title
#: xml/vt_best_practices.xml:1703
msgid "VM Guest Virtual NUMA Topology"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1704
msgid ""
"Creating a VM Guest virtual NUMA (vNUMA) policy that resembles the host NUMA "
"topology can often increase performance of traditional large, scale-up "
"workloads. VM Guest vNUMA topology can be specified using the <literal>numa</"
"literal> element in the XML configuration:"
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1710
#, no-wrap
msgid ""
"&lt;cpu&gt;\n"
"...\n"
"  &lt;numa&gt;\n"
"    &lt;cell<co xml:id=\"co.numa.cell\"/> id='0'<co xml:id=\"co.numa.id\"/> cpus='0-1'<co xml:id=\"co.numa.cpus\"/> memory='512000' unit='KiB'/&gt;\n"
"    &lt;cell id='1' cpus='2-3' memory='256000'<co xml:id=\"co.numa.mem\"/>\n"
"    unit='KiB'<co xml:id=\"co.numa.unit\"/> memAccess='shared'<co xml:id=\"co.numa.memaccess\"/>/&gt;\n"
"  &lt;/numa&gt;\n"
"  ...\n"
"&lt;/cpu&gt;"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1722
msgid "Each <literal>cell</literal> element specifies a vNUMA cell or node"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1727
msgid ""
"All cells should have an <literal>id</literal> attribute, allowing to "
"reference the cell in other configuration blocks. Otherwise cells are "
"assigned ids in ascending order starting from 0."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1734
msgid "The CPU or range of CPUs that are part of the node"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1739
msgid "The node memory"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1744
msgid "Units in which node memory is specified"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1749
msgid ""
"Optional attribute which can control whether the memory is to be mapped as "
"<option>shared</option> or <option>private</option>. This is valid only for "
"hugepages-backed memory."
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1756
msgid ""
"To find where the VM Guest has allocated its pages. use: <command>cat /proc/"
"<replaceable>PID</replaceable>/numa_maps</command> and <command>cat /sys/fs/"
"cgroup/memory/sysdefault/libvirt/qemu/<replaceable>KVM_NAME</replaceable>/"
"memory.numa_stat</command>."
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:1763
msgid "NUMA specification"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:1764
msgid ""
"The <systemitem class=\"library\">libvirt</systemitem> VM Guest NUMA "
"specification is currently only available for QEMU/KVM."
msgstr ""

#. (itstool) path: sect4/title
#: xml/vt_best_practices.xml:1771
msgid ""
"Memory Allocation Control with <systemitem class=\"library\">libvirt</"
"systemitem>"
msgstr ""

#. (itstool) path: sect4/para
#: xml/vt_best_practices.xml:1772
msgid ""
"If the VM Guest has a vNUMA topology (see <xref linkend=\"sec.vt.best.perf."
"numa.vmguest.topo\"/>), memory can be pinned to host NUMA nodes using the "
"<literal>numatune</literal> element. This method is currently only available "
"for QEMU/KVM guests. See <xref linkend=\"sec.vt.best.perf.numa.alloc_libvirt."
"non-vnuma\"/> for how to configure non-vNUMA VM Guests."
msgstr ""

#. (itstool) path: sect4/screen
#: xml/vt_best_practices.xml:1780
#, no-wrap
msgid ""
"&lt;numatune&gt;\n"
"    &lt;memory mode=\"strict\"<co xml:id=\"co.numat.mode\"/> nodeset=\"1-4,^3\"<co xml:id=\"co.numat.nodeset\"/>/&gt;\n"
"    &lt;memnode<co xml:id=\"co.numat.memnode\"/> cellid=\"0\"<co xml:id=\"co.numat.cellid\"/> mode=\"strict\" nodeset=\"1\"/&gt;\n"
"    &lt;memnode cellid=\"2\" placement=\"strict\"<co xml:id=\"co.numat.placement\"/> mode=\"preferred\" nodeset=\"2\"/&gt;\n"
"&lt;/numatune&gt;"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1787
msgid ""
"Policies available are: <literal>interleave</literal> (round-robin like), "
"<literal>strict</literal> (default) or <literal>preferred</literal>."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1794
msgid "Specify the NUMA nodes."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1799
msgid ""
"Specify memory allocation policies for each guest NUMA node (if this element "
"is not defined then this will fall back and use the <literal>memory</"
"literal> element)."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1806
msgid "Addresses the guest NUMA node for which the settings are applied."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:1811
msgid ""
"The placement attribute can be used to indicate the memory placement mode "
"for a domain process, the value can be <literal>auto</literal> or "
"<literal>strict</literal>."
msgstr ""

#. (itstool) path: important/title
#: xml/vt_best_practices.xml:1819
msgid "Non-vNUMA VM Guest"
msgstr ""

#. (itstool) path: important/para
#: xml/vt_best_practices.xml:1820
msgid ""
"On a non-vNUMA VM Guest, pinning memory to host NUMA nodes is done like in "
"the following example:"
msgstr ""

#. (itstool) path: important/screen
#: xml/vt_best_practices.xml:1824
#, no-wrap
msgid ""
"&lt;numatune&gt;\n"
"   &lt;memory mode=\"strict\" nodeset=\"0-1\"/&gt;\n"
"&lt;/numatune&gt;"
msgstr ""

#. (itstool) path: important/para
#: xml/vt_best_practices.xml:1827
msgid ""
"In this example, memory is allocated from the host nodes <literal>0</"
"literal> and <literal>1</literal>. In case these memory requirements cannot "
"be fulfilled, starting the VM Guest will fail. <command>virt-install</"
"command> also supports this configuration with the <option>--numatune</"
"option> option."
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:1837
msgid "Memory and CPU across NUMA Nodes"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:1838
msgid ""
"You should avoid allocating VM Guest memory across NUMA nodes, and prevent "
"virtual CPUs from floating across NUMA nodes."
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:1849
msgid "VM Guest Images"
msgstr ""

#. (itstool) path: sect1/para
#: xml/vt_best_practices.xml:1850
msgid ""
"Images are virtual disks used to store the operating system and data of VM "
"Guests. They can be created, maintained and queried with the <command>qemu-"
"img</command> command. Refer to <link xlink:href=\"https://www.suse.com/"
"documentation/sles-12/singlehtml/book_virt/book_virt.html#cha.qemu."
"guest_inst.qemu-img.create\">SLE12 qemu-img documentation</link> for more "
"information on the <command>qemu-img</command> tool and examples."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:1859
msgid "VM Guest Image Formats"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1860
msgid ""
"Certain storage formats which QEMU recognizes have their origins in other "
"virtualization technologies. By recognizing these formats, QEMU can leverage "
"either data stores or entire guests that were originally targeted to run "
"under these other virtualization technologies. Some formats are supported "
"only in read-only mode. To use them in read/write mode, convert them to a "
"fully supported QEMU storage format (using <command>qemu-img</command>). "
"Otherwise they can only be used as read-only data store in a QEMU guest. See "
"SUSE Linux Enterprise <link xlink:href=\"https://www.suse.com/releasenotes/"
"x86_64/SUSE-SLES/12/#fate-317891\">Release Notes</link> to get the list of "
"supported formats."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:1872
msgid ""
"Use <command>qemu-img info <replaceable>VMGUEST.IMG</replaceable></command> "
"to get information about an existing image, such as: the format, the virtual "
"size, the physical size, snapshots if available."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:1878
msgid "Performance"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:1879
msgid ""
"It is recommended to convert the disk images to either raw or qcow2 to "
"achieve good performance."
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:1885
msgid "Encrypted Images Cannot Be Compressed"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:1886
msgid ""
"When you create an image, you cannot use compression (<option>-c</option>) "
"in the output file together with the encryption option (<option>-e</option>)."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1893
msgid "Raw Format"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1897
msgid ""
"This format is simple and easily exportable to all other emulators/"
"hypervisors."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1903
msgid "It provides best performance (least I/O overhead)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1908
msgid ""
"If your file system supports holes (for example in Ext2 or Ext3 on Linux or "
"NTFS on Windows*), then only the written sectors will reserve space."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1915
msgid ""
"The raw format allows to copy a VM Guest image to a physical device "
"(<command>dd if=<replaceable>VMGUEST.RAW</replaceable> of=<replaceable>/dev/"
"sda</replaceable></command>)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1922
msgid ""
"It is byte-for-byte the same as what the VM Guest sees, so this wastes a lot "
"of space."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:1930
msgid "qcow2 Format"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1934
msgid ""
"Use this to have smaller images (useful if your file system does not "
"supports holes)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1940
msgid "It has optional AES encryption (now deprecated)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1945
msgid "Zlib-based compression option."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1950
msgid "Support of multiple VM snapshots (internal, external)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1955
msgid "Improved performance and stability."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1960
msgid "Supports changing the backing file."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1965
msgid "Supports consistency checks."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1970
msgid "Less performance than raw format."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/vt_best_practices.xml:1977
msgid "l2-cache-size"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1979
msgid ""
"qcow2 can provide the same performance for random read/write access as raw "
"format, but it needs a well-sized cache size. By default cache size is set "
"to 1 MB. This will give good performance up to a disk size of 8 GB. If you "
"need a bigger disk size, you need to adjust the cache size. For a disk size "
"of 64 GB (64*1024 = 65536), you need 65536 / 8192B = 8 MB of cache (<option>-"
"drive format=qcow2,l2-cache-size=8M</option>)."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/vt_best_practices.xml:1991
msgid "Cluster Size"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:1993
msgid ""
"The qcow2 format offers the capability to change the cluster size. The value "
"must be between 512 KB and 2 MB. Smaller cluster sizes can improve the image "
"file size whereas larger cluster sizes generally provide better performance."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/vt_best_practices.xml:2002
msgid "Preallocation"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2004
msgid ""
"An image with preallocated metadata is initially larger but can improve "
"performance when the image needs to grow."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/vt_best_practices.xml:2011
msgid "Lazy Refcounts"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2013
msgid ""
"Reference count updates are postponed with the goal of avoiding metadata I/O "
"and improving performance. This is particularly beneficial with "
"<option>cache=writethrough</option>. This option does not batch metadata "
"updates, but if in case of host crash, the reference count tables must be "
"rebuilt, this is done automatically at the next open with <command>qemu-img "
"check -r all</command>. Note that this takes some time."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2026
msgid "qed Format"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2027
msgid ""
"qed is a follow-on qcow (QEMU Copy On Write) format. Because qcow2 provides "
"all the benefits of qed and more, qed is now deprecated."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2034
msgid "VMDK Format"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2035
msgid ""
"VMware 3, 4, or 6 image format, for exchanging images with that product."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:2042
msgid "Overlay Disk Images"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2043
msgid ""
"The qcow2 and qed formats provide a way to create a base image (also called "
"backing file) and overlay images on top of the base image. A backing file is "
"useful to be able to revert to a known state and discard the overlay. If you "
"write to the image, the backing image will be untouched and all changes will "
"be recorded in the overlay image file. The backing file will never be "
"modified unless you use the <option>commit</option> monitor command (or "
"<command>qemu-img commit</command>)."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2053
msgid "To create an overlay image:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2056
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>qemu-img create -o<co xml:id=\"co.1.minoro\"/>backing_file=vmguest.raw<co xml:id=\"co.1.backingfile\"/>,backing_fmt=raw<co xml:id=\"co.1.backingfmt\"/>\\\n"
"     -f<co xml:id=\"co.1.minorf\"/> qcow2 vmguest.cow<co xml:id=\"co.1.imagename\"/>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2060
msgid "Use <option>-o ?</option> for an overview of available options."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2065
msgid "The backing file name."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2070
msgid "Specify the file format for the backing file."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2075
msgid "Specify the image format for the VM Guest."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2080
msgid ""
"Image name of the VM Guest, it will only record the differences from the "
"backing file."
msgstr ""

#. (itstool) path: warning/title
#: xml/vt_best_practices.xml:2087
msgid "Backing Image Path"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:2088
msgid ""
"You should not change the path to the backing image, otherwise you will need "
"to adjust it. The path is stored in the overlay image file. To update the "
"path, you should make a symbolic link from the original path to the new path "
"and then use the <command>qemu-img</command> <option>rebase</option> option."
msgstr ""

#. (itstool) path: warning/screen
#: xml/vt_best_practices.xml:2095
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>ln -sf /var/lib/images/vmguest.raw  /var/lib/images/SLE12/vmguest.raw\n"
"<prompt role=\"root\">root # </prompt>qemu-img rebase<co xml:id=\"co.2.rebase\"/>-u<co xml:id=\"co.2.unsafe\"/> -b<co xml:id=\"co.2.minorb\"/> /var/lib/images/vmguest.raw /var/lib/images/SLE12/vmguest.cow<co xml:id=\"co.2.image\"/>"
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:2097
msgid ""
"The <command>rebase</command> subcommand tells <command>qemu-img</command> "
"to change the backing file image. The <option>-u</option> option activates "
"the unsafe mode (see note below). The backing image to be used is specified "
"with <option>-b</option> and the image path is the last argument of the "
"command."
msgstr ""

#. (itstool) path: warning/para
#: xml/vt_best_practices.xml:2104
msgid ""
"There are two different modes in which <option>rebase</option> can operate:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2110
msgid ""
"<emphasis>Safe</emphasis>: This is the default mode and performs a real "
"rebase operation. The safe mode is a time-consuming operation."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2116
msgid ""
"<emphasis>Unsafe</emphasis>: The unsafe mode (<option>-u</option>) only "
"changes the backing files name and the format of the file name without "
"making any checks on the files contents. You should use this mode to rename "
"or moving a backing file."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2125
msgid ""
"A common use is to initiate a new guest with the backing file. Let's assume "
"we have a <filename>sle12_base.img</filename> VM Guest ready to be used "
"(fresh installation without any modification). This will be our backing "
"file. Now you need to test a new package, on an updated system and on a "
"system with a different kernel. We can use <filename>sle12_base.img</"
"filename> to instantiate the new SUSE Linux Enterprise VM Guest by creating "
"a qcow2 overlay file pointing to this backing file (<filename>sle12_base."
"img</filename>)."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2135
msgid ""
"In our example we will use <filename>sle12_updated.qcow2</filename> for the "
"updated system, and <filename>sle12_kernel.qcow2</filename> for the system "
"with a different kernel."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2140
msgid ""
"To create the two thin provisioned systems use the <command>qemu-img</"
"command> command line with the <option>-b</option> option:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2145
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>qemu-img create -b /var/lib/libvirt/sle12_base.img -f qcow2 \\\n"
"/var/lib/libvirt/sle12_updated.qcow2\n"
"Formatting 'sle12_updated.qcow2', fmt=qcow2 size=17179869184\n"
"backing_file='sle12_base.img' encryption=off cluster_size=65536\n"
"lazy_refcounts=off nocow=off\n"
"<prompt role=\"root\">root # </prompt>qemu-img create -b /var/lib/libvirt/sle12_base.img -f qcow2 \\\n"
"/var/lib/libvirt/sle12_kernel.qcow2\n"
"Formatting 'sle12_kernel.qcow2', fmt=qcow2 size=17179869184\n"
"backing_file='vmguest-sle12_base.img' encryption=off cluster_size=65536\n"
"lazy_refcounts=off nocow=off"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2155
msgid ""
"The images are now usable, and you can do your test without touching the "
"initial <filename>sle12_base.img</filename> backing file, all changes will "
"be stored in the new overlay images. Additionally, you can also use these "
"new images as a backing file, and create a new overlay."
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2161
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>qemu-img create -b sle12_kernel.qcow2 -f qcow2 sle12_kernel_TEST.qcow2"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2162
msgid ""
"When using <command>qemu-img info</command> with the option <option>--"
"backing-chain</option>, it will return all information about the entire "
"backing chain recursively:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2167
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>qemu-img info --backing-chain\n"
"/var/lib/libvirt/images/sle12_kernel_TEST.qcow2\n"
"image: sle12_kernel_TEST.qcow2\n"
"file format: qcow2\n"
"virtual size: 16G (17179869184 bytes)\n"
"disk size: 196K\n"
"cluster_size: 65536\n"
"backing file: sle12_kernel.qcow2\n"
"Format specific information:\n"
"compat: 1.1\n"
"lazy refcounts: false\n"
"\n"
"image: sle12_kernel.qcow2\n"
"file format: qcow2\n"
"virtual size: 16G (17179869184 bytes)\n"
"disk size: 196K\n"
"cluster_size: 65536\n"
"backing file: SLE12.qcow2\n"
"Format specific information:\n"
"compat: 1.1\n"
"lazy refcounts: false\n"
"\n"
"image: sle12_base.img\n"
"file format: qcow2\n"
"virtual size: 16G (17179869184 bytes)\n"
"disk size: 16G\n"
"cluster_size: 65536\n"
"Format specific information:\n"
"compat: 1.1\n"
"lazy refcounts: true"
msgstr ""

#. (itstool) path: figure/title
#: xml/vt_best_practices.xml:2198
msgid "Understanding Image Overlay"
msgstr ""

#. (itstool) path: imageobject/imagedata
#. This is a reference to an external file such as an image or video. When
#. the file changes, the md5 hash will change to let you know you need to
#. update your localized copy. The msgstr is not used at all. Set it to
#. whatever you like once you have updated your copy of the file.
#: xml/vt_best_practices.xml:2201 xml/vt_best_practices.xml:2204
msgctxt "_"
msgid "external ref='qemu-img-overlay.png' md5='__failed__'"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:2261
msgid "Opening a VM Guest Image"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2262
msgid ""
"To access the file system of an image, use the <package>guestfs-tools</"
"package>. If you do not have this tool installed on your system you can "
"mount an image with other Linux tools. Avoid accessing an untrusted or "
"unknown VM Guest's image system because this can lead to security issues "
"(for more information, read <link xlink:href=\"https://www.berrange.com/"
"posts/2013/02/20/a-reminder-why-you-should-never-mount-guest-disk-images-on-"
"the-host-os/\">D. Berrangé's post</link>)."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2272
msgid "Opening a Raw Image"
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:2274
msgid "Mounting a Raw Image"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2276
msgid ""
"To be able to mount the image, find a free loop device. The following "
"command displays the first unused loop device, <filename>/dev/loop1</"
"filename> in this example."
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2281
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>losetup -f\n"
"/dev/loop1"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2285
msgid ""
"Associate an image (<filename>SLE12.raw</filename> in this example) with the "
"loop device:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2289
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>losetup /dev/loop1 SLE12.raw"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2292
msgid ""
"Check whether the image has successfully been associated with the loop "
"device by getting detailed information about the loop device:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2296
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>losetup -l\n"
"NAME       SIZELIMIT OFFSET AUTOCLEAR RO BACK-FILE\n"
"/dev/loop1         0      0         0  0    /var/lib/libvirt/images/SLE12.raw"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2301
msgid "Check the image's partitions with <command>kpartx</command>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2304
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>kpartx -a<co xml:id=\"co.kpartx.a\"/> -v<co xml:id=\"co.kpartx.v\"/> /dev/loop1\n"
"add map loop1p1 (254:1): 0 29358080 linear /dev/loop1 2048"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2308
msgid "Add partition device mappings."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2313
msgid "Verbose mode."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2320
msgid ""
"Now mount the image partition(s) (to <filename>/mnt/sle12mount</filename> in "
"the following example):"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2324
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>mkdir /mnt/sle12mount\n"
"<prompt role=\"root\">root # </prompt>mount /dev/mapper/loop1p1 /mnt/sle12mount"
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:2329
msgid "Raw image with LVM"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:2330
msgid ""
"If your raw image contains an LVM volume group you should use LVM tools to "
"mount the partition. Refer to <xref linkend=\"sec.lvm.found\"/>."
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:2338
msgid "Unmounting a Raw Image"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2340 xml/vt_best_practices.xml:2457
msgid "Unmount all mounted partitions of the image, for example:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2343
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>umount /mnt/sle12mount"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2346
msgid "Delete partition device mappings with <command>kpartx</command>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2349
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>kpartx -d /dev/loop1"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2352
msgid "Detach the devices with <command>losetup</command>"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2355
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>losetup -d /dev/loop1"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2361
msgid "Opening a qcow2 Image"
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:2363
msgid "Mounting a qcow2 Image"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2365
msgid ""
"First you need to load the <literal>nbd</literal> (network block devices) "
"module. The following example loads it with support for 16 block devices "
"(<option>max_part=16</option>). Check with <command>dmesg</command> whether "
"the operation was successful:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2371
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>modprobe nbd max_part=16\n"
"<prompt role=\"root\">root # </prompt>dmesg | grep nbd\n"
"[89155.142425] nbd: registered device at major 43"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2376
msgid ""
"Connect the VM Guest image (for example <filename>SLE12.qcow2</filename>) to "
"an NBD device (<filename>/debv/nbd0</filename> in the following example) "
"with the <command>qemu-nbd</command> command. Make sure to use a free NBD "
"device:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2382
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>qemu-nbd -c<co xml:id=\"co.qemunbd.minusc\"/> /dev/nbd0<co xml:id=\"co.qemunbd.device\"/> SLE12.qcow2<co xml:id=\"co.qemunbd.image\"/>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2385
msgid ""
"Connect <filename>SLE12.qcow2</filename> to the local NBD device <filename>/"
"dev/nbd0</filename>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2391
msgid "NBD device to use"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2396
msgid "VM Guest image to use"
msgstr ""

#. (itstool) path: tip/title
#: xml/vt_best_practices.xml:2402
msgid "Checking for a free NBD Device"
msgstr ""

#. (itstool) path: tip/para
#: xml/vt_best_practices.xml:2403
msgid "To check whether an NBD device is free, run the following command:"
msgstr ""

#. (itstool) path: tip/screen
#: xml/vt_best_practices.xml:2406
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>lsof /dev/nbd0\n"
"COMMAND    PID USER   FD   TYPE DEVICE SIZE/OFF  NODE NAME\n"
"qemu-nbd 15149 root   10u   BLK   43,0      0t0 47347 /dev/nbd0"
msgstr ""

#. (itstool) path: tip/para
#: xml/vt_best_practices.xml:2409
msgid ""
"If the command produces an output like in the example above, the device is "
"busy (not free). This can also be confirmed by the presence of the "
"<filename>/sys/devices/virtual/block/nbd0/pid</filename> file."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2417
msgid ""
"Inform the operating system about partition table changes with "
"<command>partprobe</command>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2421
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>partprobe /dev/nbd0 -s\n"
"/dev/nbd0: msdos partitions 1 2\n"
"<prompt role=\"root\">root # </prompt>dmesg | grep nbd0 | tail -1\n"
"[89699.082206]  nbd0: p1 p2"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2427
msgid ""
"In the example above, the <filename>SLE12.qcow2</filename> contains two "
"partitions: <filename>/dev/nbd0p1</filename> and <filename>/dev/nbd0p2</"
"filename>. Before mounting these partitions, use <command>vgscan</command> "
"to check whether they belong to an LVM volume:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2433
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>vgscan -v\n"
"    Wiping cache of LVM-capable devices\n"
"    Wiping internal VG cache\n"
"    Reading all physical volumes. This may take a while...\n"
"    Using volume group(s) on command line.\n"
"    No volume groups found."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2441
msgid ""
"If no LVM volume has been found, you can mount the partition with "
"<command>mount</command>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2445
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>mkdir /mnt/nbd0p2\n"
"# mount /dev/nbd0p1 /mnt/nbd0p2"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2447
msgid ""
"Refer to <xref linkend=\"sec.lvm.found\"/> for information on how to handle "
"LVM volumes."
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:2455
msgid "Unmounting a qcow2 Image"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2460
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>umount /mnt/nbd0p2"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2463
msgid "Disconnect the image from the <filename>/dev/nbd0</filename> device."
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2466
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>qemu-nbd -d /dev/nbd0"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2472
msgid "Opening Images Containing LVM"
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:2475
msgid "Mounting Images Containing LVM"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2477
msgid ""
"To check images for LVM groups, use <command>vgscan -v</command>. If an "
"image contains LVM groups, the output of the command looks like the "
"following:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2482
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>vgscan -v\n"
"Wiping cache of LVM-capable devices\n"
"Wiping internal VG cache\n"
"Reading all physical volumes.  This may take a while...\n"
"Finding all volume groups\n"
"Finding volume group \"system\"\n"
"Found volume group \"system\" using metadata type lvm2"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2491
msgid ""
"The <literal>system</literal> LVM volume group has been found on the system. "
"You can get more information about this volume with <command>vgdisplay "
"<replaceable>VOLUMEGROUPNAME</replaceable></command> (in our case "
"<replaceable>VOLUMEGROUPNAME</replaceable> is <literal>system</literal>). "
"You should activate this volume group to expose LVM partitions as devices so "
"the system can mount them. Use <command>vgchange</command>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2500
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>vgchange -ay -v\n"
"Finding all volume groups\n"
"Finding volume group \"system\"\n"
"Found volume group \"system\"\n"
"activation/volume_list configuration setting not defined: Checking only\n"
"host tags for system/home\n"
"Creating system-home\n"
"Loading system-home table (254:0)\n"
"Resuming system-home (254:0)\n"
"Found volume group \"system\"\n"
"activation/volume_list configuration setting not defined: Checking only\n"
"host tags for system/root\n"
"Creating system-root\n"
"Loading system-root table (254:1)\n"
"Resuming system-root (254:1)\n"
"Found volume group \"system\"\n"
"activation/volume_list configuration setting not defined: Checking only\n"
"host tags for system/swap\n"
"Creating system-swap\n"
"Loading system-swap table (254:2)\n"
"Resuming system-swap (254:2)\n"
"Activated 3 logical volumes in volume group system\n"
"    3 logical volume(s) in volume group \"system\" now active"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2525
msgid ""
"All partitions in the volume group will be listed in the <filename>/dev/"
"mapper</filename> directory. You can simply mount them now."
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2530
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>ls /dev/mapper/system-*\n"
"/dev/mapper/system-home  /dev/mapper/system-root /dev/mapper/system-swap\n"
"\n"
"<prompt role=\"root\">root # </prompt>mkdir /mnt/system-root\n"
"<prompt role=\"root\">root # </prompt>mount  /dev/mapper/system-root /mnt/system-root\n"
"\n"
"<prompt role=\"root\">root # </prompt>ls /mnt/system-root/\n"
"bin   dev  home  lib64       mnt  proc        root  sbin     srv  tmp  var\n"
"boot  etc  lib   lost+found  opt  read-write  run   selinux  sys  usr"
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:2542
msgid "Unmounting Images Containing LVM"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2544
msgid "Unmount all partitions (with <command>umount</command>)"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2547
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>umount /mnt/system-root"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2550
msgid ""
"Deactivate the LVM volume group (with <command>vgchange -an "
"<replaceable>VOLUMEGROUPNAME</replaceable></command>)"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:2554
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>vgchange -an -v system\n"
"Using volume group(s) on command line\n"
"Finding volume group \"system\"\n"
"Found volume group \"system\"\n"
"Removing system-home (254:0)\n"
"Found volume group \"system\"\n"
"Removing system-root (254:1)\n"
"Found volume group \"system\"\n"
"Removing system-swap (254:2)\n"
"Deactivated 3 logical volumes in volume group system\n"
"0 logical volume(s) in volume group \"system\" now active"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:2567
msgid "Now you have two choices:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2572
msgid ""
"In case of a qcow2 image, proceed as described in <xref linkend=\"st.umount."
"qcow2\"/> (<command>qemu-nbd -d /dev/nbd0</command>)."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2579
msgid ""
"In case of a raw image, proceeds as described in <xref linkend=\"st.umount."
"raw\"/> (<command>kpartx -d /dev/loop1</command>; <command>losetup -d /dev/"
"loop1</command>)."
msgstr ""

#. (itstool) path: important/title
#: xml/vt_best_practices.xml:2587
msgid "Check for a Successful Unmount"
msgstr ""

#. (itstool) path: important/para
#: xml/vt_best_practices.xml:2588
msgid ""
"You should double-check that umounting succeeded by using a system command "
"like <command>losetup</command>, <command>qemu-nbd</command>, "
"<command>mount</command> or <command>vgscan</command>. If this is not the "
"case you may have trouble using the VM Guest because its system image is "
"used in different places."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:2602
msgid "File System Sharing"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2603
msgid ""
"You can access a host directory in the VM Guest using the <tag class="
"\"element\">filesystem</tag> element. In the following example we will share "
"the <filename>/data/shared</filename> directory and mount it in the VM "
"Guest. Note that the <tag class=\"attribute\">accessmode</tag> parameter "
"only works with <tag class=\"attribute\">type='mount'</tag> for the QEMU/KVM "
"drive (most other values for <tag class=\"attribute\">type</tag> are "
"exclusively used for the LXC driver)."
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2612
#, no-wrap
msgid ""
"&lt;filesystem type='mount'<co xml:id=\"co.fs.mount\"/> accessmode='mapped'<co xml:id=\"co.fs.mode\"/>&gt;\n"
"   &lt;source dir='/data/shared'<co xml:id=\"co.fs.sourcedir\"/>&gt;\n"
"   &lt;target dir='shared'<co xml:id=\"co.fs.targetdir\"/>/&gt;\n"
"&lt;/filesystem&gt;"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2618
msgid "A host directory to mount VM Guest."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2623
msgid ""
"Access mode (the security mode) set to <literal>mapped</literal> will give "
"access with the permissions of the hypervisor. Use <literal>passthrough</"
"literal> to access this share with the permissions of the user inside the VM "
"Guest."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2631
msgid "Path to share with the VM Guest."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:2636
msgid "Name or label of the path for the mount command."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2641
msgid ""
"To mount the <literal>shared</literal> directory on the VM Guest, use the "
"following commands: Under the VM Guest now you need to mount the "
"<literal>target dir='shared'</literal>:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2647
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>mkdir /opt/mnt_shared\n"
"<prompt role=\"root\">root # </prompt>mount shared -t 9p /opt/mnt_shared -o trans=virtio"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2649
msgid ""
"See <link xlink:href=\"https://libvirt.org/formatdomain."
"html#elementsFilesystems\"><systemitem class=\"library\">libvirt</"
"systemitem> File System </link> and <link xlink:href=\"http://wiki.qemu.org/"
"Documentation/9psetup\">QEMU 9psetup</link> for more information."
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:2660
msgid "VM Guest Configuration"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:2663
msgid "Virtio Driver"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2664
msgid ""
"To increase VM Guest performance it is recommended to use paravirtualized "
"drivers within the VM Guests. The virtualization standard for such drivers "
"for KVM are the <literal>virtio</literal> drivers, which are designed for "
"running in a virtual environment. Xen uses similar paravirtualized device "
"drivers (like <link xlink:href=\"https://www.suse.com/products/vmdriverpack/"
"\">VMDP</link> in a Windows* guest). For a better understanding of this "
"topic, refer to the <link xlink:href=\"https://www.suse.com/documentation/"
"sles-12/book_virt/data/sec_vt_io.html\">I/O Virtualization</link> section in "
"the official Virtualization Guide."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2678
msgid "<literal>virtio blk</literal>"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2679
msgid ""
"<literal>virtio_blk</literal> is the virtio block device for disk. To use "
"the <literal>virtio blk</literal> driver for a block device, specify the "
"<tag class=\"attribute\">bus='virtio'</tag> attribute in the <tag class="
"\"element\">disk</tag> definition:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2685
#, no-wrap
msgid ""
"&lt;disk type='....' device='disk'&gt;\n"
"    ....\n"
"    &lt;target dev='vda' bus='virtio'/&gt;\n"
"&lt;/disk&gt;"
msgstr ""

#. (itstool) path: important/title
#: xml/vt_best_practices.xml:2691
msgid "Disk Device Names"
msgstr ""

#. (itstool) path: important/para
#: xml/vt_best_practices.xml:2692
msgid ""
"<literal>virtio</literal> disk devices are named <literal>/dev/vd[a-z][1-9]</"
"literal>. If you migrate a Linux guest from a non-virtio disk you need to "
"adjust the <literal>root=</literal> parameter in the GRUB configuration, and "
"regenerate the <filename>initrd</filename> file. Otherwise the system cannot "
"boot. On VM Guests with other operating systems, the boot loader may need to "
"be adjusted or reinstalled accordingly, too."
msgstr ""

#. (itstool) path: important/title
#: xml/vt_best_practices.xml:2704
msgid ""
"Using <literal>virtio</literal> Disks with <command>qemu-system-ARCH</"
"command>"
msgstr ""

#. (itstool) path: important/para
#: xml/vt_best_practices.xml:2708
msgid ""
"When running <command>qemu-system-ARCH</command>, use the <option>-drive</"
"option> option to add a disk to the VM Guest. See the <link xlink:href="
"\"https://www.suse.com/documentation/sles-12/book_virt/data/"
"cha_qemu_guest_inst_qemu-kvm.html\">Basic Installation with qemu-system-"
"ARCH</link> section in the official Virtualization guide for an example. The "
"<option>-hd[abcd]</option> option will not work for virtio disks."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2721
msgid "virtio net"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2722
msgid ""
"<literal>virtio_net</literal> is the virtio network device. The kernel "
"modules should be loaded automatically in the guest at boot time. You need "
"to start the service to make the network available."
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2727
#, no-wrap
msgid ""
"&lt;interface type='network'&gt;\n"
"    ...\n"
"    &lt;model type='virtio' /&gt;\n"
"&lt;/interface&gt;"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2733
msgid "virtio balloon"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2734
msgid ""
"The virtio balloon is used for host memory over-commits for guests. For "
"Linux guests, the balloon driver runs in the guest kernel, whereas for "
"Windows guests, the balloon driver is in the VMDP package. "
"<literal>virtio_balloon</literal> is a PV driver to give or take memory from "
"a VM Guest."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2743
msgid ""
"<emphasis>Inflate balloon</emphasis>: Return memory from guest to host "
"kernel (for KVM) or to hypervisor (for Xen)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2749
msgid ""
"<emphasis>Deflate balloon</emphasis>: Guest will have more available memory"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2755
msgid ""
"It is controlled by the <literal>currentMemory</literal> and "
"<literal>memory</literal> options."
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2759
#, no-wrap
msgid ""
"&lt;memory unit='KiB'&gt;16777216&lt;/memory&gt;\n"
"    &lt;currentMemory unit='KiB'&gt;1048576&lt;/currentMemory&gt;\n"
"    [...]\n"
"    &lt;devices&gt;\n"
"        &lt;memballoon model='virtio'/&gt;\n"
"    &lt;/devices&gt;"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2765
msgid "You can also use <command>virsh</command> to change it:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2768
#, no-wrap
msgid "<prompt>tux &gt; </prompt>virsh setmem <replaceable>DOMAIN_ID</replaceable> <replaceable>MEMORY in KB</replaceable>"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2771
msgid "Checking virtio Presence"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2772
msgid "You can check the virtio block PCI with:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2775
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>find /sys/devices/ -name virtio*\n"
"/sys/devices/pci0000:00/0000:00:06.0/virtio0\n"
"/sys/devices/pci0000:00/0000:00:07.0/virtio1\n"
"/sys/devices/pci0000:00/0000:00:08.0/virtio2"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2779
msgid "To find the block device associated with <filename>vdX</filename>:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2782
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>find /sys/devices/ -name virtio* -print  -exec ls {}/block 2&gt;/dev/null \\;\n"
"/sys/devices/pci0000:00/0000:00:06.0/virtio0\n"
"/sys/devices/pci0000:00/0000:00:07.0/virtio1\n"
"/sys/devices/pci0000:00/0000:00:08.0/virtio2\n"
"vda"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2787
msgid "To get more information on the virtio block:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2790
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>udevadm info -p /sys/devices/pci0000:00/0000:00:08.0/virtio2\n"
"P: /devices/pci0000:00/0000:00:08.0/virtio2\n"
"E: DEVPATH=/devices/pci0000:00/0000:00:08.0/virtio2\n"
"E: DRIVER=virtio_blk\n"
"E: MODALIAS=virtio:d00000002v00001AF4\n"
"E: SUBSYSTEM=virtio"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2796
msgid "To check all virtio drivers being used:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2799
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>find /sys/devices/ -name virtio* -print  -exec ls -l {}/driver 2&gt;/dev/null \\;\n"
"/sys/devices/pci0000:00/0000:00:06.0/virtio0\n"
"lrwxrwxrwx 1 root root 0 Jun 17 15:48 /sys/devices/pci0000:00/0000:00:06.0/virtio0/driver -&gt; ../../../../bus/virtio/drivers/virtio_console\n"
"/sys/devices/pci0000:00/0000:00:07.0/virtio1\n"
"lrwxrwxrwx 1 root root 0 Jun 17 15:47 /sys/devices/pci0000:00/0000:00:07.0/virtio1/driver -&gt; ../../../../bus/virtio/drivers/virtio_balloon\n"
"/sys/devices/pci0000:00/0000:00:08.0/virtio2\n"
"lrwxrwxrwx 1 root root 0 Jun 17 14:35 /sys/devices/pci0000:00/0000:00:08.0/virtio2/driver -&gt; ../../../../bus/virtio/drivers/virtio_blk"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:2813
msgid "Find Device Driver Options"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:2814
msgid ""
"Virtio devices and other drivers have various options. To list all of them, "
"use the <option>help</option> parameter of the<command>qemu-system-ARCH</"
"command> command."
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:2819
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>qemu-system-x86_64 -device virtio-net,help\n"
"virtio-net-pci.ioeventfd=on/off\n"
"virtio-net-pci.vectors=uint32\n"
"virtio-net-pci.indirect_desc=on/off\n"
"virtio-net-pci.event_idx=on/off\n"
"virtio-net-pci.any_layout=on/off\n"
"....."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:2830
msgid "Cirrus Video Driver"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2831
msgid ""
"To get 16-bit color, high compatibility and better performance it is "
"recommended to use the <literal>cirrus</literal> video driver."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:2836
msgid "<systemitem class=\"library\">libvirt</systemitem>"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:2837
msgid ""
"<systemitem class=\"library\">libvirt</systemitem> ignores the "
"<literal>vram</literal> value because video size has been hardcoded in QEMU."
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2842
#, no-wrap
msgid ""
"&lt;video&gt;\n"
"   &lt;model type='cirrus' vram='9216' heads='1'/&gt;\n"
"&lt;/video&gt;"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:2848
msgid "Better Entropy"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2849
msgid ""
"Virtio RNG (random number generator) is a paravirtualized device that is "
"exposed as a hardware RNG device to the guest. On the host side, it can be "
"wired up to one of several sources of entropy (including a real hardware RNG "
"device and the host's <filename>/dev/random</filename>) if hardware support "
"does not exist. The Linux kernel contains the guest driver for the device "
"from version 2.6.26 and higher."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2857
msgid ""
"The system entropy is collected from various non-deterministic hardware "
"events and is mainly used by cryptographic applications. The virtual random "
"number generator device (paravirtualized device) allows the host to pass "
"through entropy to VM Guest operating systems. This results in a better "
"entropy in the VM Guest."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2864
msgid ""
"To use Virtio RNG, add an <literal>RNG</literal> device in <command>virt-"
"manager</command> or directly in the VM Guest's XML configuration:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2869
#, no-wrap
msgid ""
"&lt;devices&gt;\n"
"   &lt;rng model='virtio'&gt;\n"
"       &lt;backend model='random'&gt;/dev/random&lt;/backend&gt;\n"
"   &lt;/rng&gt;\n"
"&lt;/devices&gt;"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2874
msgid "The host now should used <filename>/dev/random</filename>:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2877
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>lsof /dev/random\n"
"qemu-syst 4926 qemu    6r   CHR    1,8      0t0 8199 /dev/random"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2879
msgid "On the VM Guest, the source of entropy can be checked with:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2882
#, no-wrap
msgid "<prompt>tux &gt; </prompt>cat /sys/devices/virtual/misc/hw_random/rng_available"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2883
msgid "The current device used for entropy can be checked with:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2886
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>cat /sys/devices/virtual/misc/hw_random/rng_current\n"
"virtio_rng.0"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2888
msgid ""
"You should install the <package>rng-tools</package> package on the VM Guest, "
"enable the service, and start it. Under SLE12 do the following:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:2893
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>zypper in rng-tools\n"
"<prompt role=\"root\">root # </prompt>systemctl enable rng-tools\n"
"<prompt role=\"root\">root # </prompt>systemctl start rng-tools"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:2899
msgid "Disable Unused Tools and Devices"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2900
msgid ""
"Per host, use one virtualization technology only. For example, do not use "
"KVM and Containers on the same computer. Otherwise, you may find yourself "
"with a reduced amount of available resources, increased security risk and a "
"longer software update queue. Even when the amount of resources allocated to "
"each of the technologies is configured carefully, the host may suffer from "
"reduced overall availability and degraded performance."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2909
msgid ""
"Minimize the amount of software and services available on hosts. Most "
"default installations of operating systems are not optimized for VM usage. "
"Install what you really need and remove all other components in the VM Guest."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2915
msgid "Windows* Guest:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2920
msgid "Disable the screen saver"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2925
msgid "Remove all graphical effects"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2930
msgid "Disable indexing of hard disks if not necessary"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2935 xml/vt_best_practices.xml:2986
msgid "Check the list of started services and disable the ones you do not need"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2941
msgid "Check and remove all unneeded devices"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2946
msgid ""
"Disable system update if not needed, or configure it to avoid any delay "
"while rebooting or shutting down the host"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2952
msgid "Check the Firewall rules"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2957
msgid "Schedule backups and anti-virus updates appropriately"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2962
msgid ""
"Install the <link xlink:href=\"https://www.suse.com/products/vmdriverpack/"
"\">VMDP</link> paravirtualized driver for best performance"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2969
msgid ""
"Check the operating system recommendations, such as on the <link xlink:href="
"\"http://windows.microsoft.com/en-us/windows/optimize-windows-better-"
"performance#optimize-windows-better-performance=windows-7\">Microsoft "
"Windows* 7 better performance</link> Web page."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:2976
msgid "Linux Guest:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2981
msgid "Remove or do not start the X Window System if not necessary"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2992
msgid ""
"Check the OS recommendations for kernel parameters that enable better "
"performance"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:2998
msgid "Only install software that you really need"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:3003
msgid ""
"Optimize the scheduling of predictable tasks (system updates, hard disk "
"checks, etc.)"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3012
msgid "Updating the Guest Machine Type"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3013
msgid ""
"QEMU machine types define details of the architecture that are particularly "
"relevant for migration and session management. As changes or improvements to "
"QEMU are made, new machine types are added. Old machine types are still "
"supported for compatibility reasons, but to take advantage of improvements, "
"we recommend to always migrate to the latest machine type when upgrading."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3021
msgid ""
"Changing the guest's machine type for a Linux guest will mostly be "
"transparent. For Windows* guests, we recommend to take a snapshot or backup "
"of the guest—in case Windows* has issues with the changes it detects and "
"subsequently the user decides to revert to the original machine type the "
"guest was created with."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:3029
msgid "Changing the machine type"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:3030
msgid ""
"Refer to the Virtualization guide section <link xlink:href=\"https://www."
"suse.com/documentation/sles-12/singlehtml/book_virt/book_virt.html#sec."
"libvirt.config.mahcinetype.virsh\">Change Machine Type</link> for "
"documentation."
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:3039
msgid "VM Guest-Specific Configurations and Settings"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3042
msgid "ACPI Testing"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3043
msgid ""
"The ability to change a VM Guest's state heavily depends on the operating "
"system. It is very important to test this feature before any use of your VM "
"Guests in production. For example, most Linux operating systems disable this "
"capability by default, so this requires you to enable this operation (mostly "
"through PolKit)."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3050
msgid ""
"ACPI must be enabled in the guest for a graceful shutdown to work. To check "
"if ACPI is enabled, run:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3054
#, no-wrap
msgid "<prompt>tux &gt; </prompt>virsh dumpxml <replaceable>VMNAME</replaceable> | grep acpi"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3055
msgid ""
"If nothing is printed, ACPI is not enabled for your machine. Use "
"<command>virsh edit</command> to add the following XML under &lt;domain&gt;:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3060
#, no-wrap
msgid ""
"&lt;features&gt;\n"
"   &lt;acpi/&gt;\n"
"&lt;/features&gt;"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3063
msgid ""
"If ACPI was enabled during a Windows Server* guest installation, it is not "
"sufficient to turn it on in the VM Guest configuration only. For more "
"information, see <link xlink:href=\"https://support.microsoft.com/en-us/"
"kb/309283\"/>."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3073
msgid ""
"Regardless of the VM Guest's configuration, a graceful shutdown is always "
"possible from within the guest operating system."
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3080
msgid "Keyboard Layout"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3081
msgid ""
"Though it is possible to specify the keyboard layout from a <command>qemu-"
"system-ARCH</command> command, it is recommended to configure it in the "
"<systemitem class=\"library\">libvirt</systemitem> XML file. To change the "
"keyboard layout while connecting to a remote VM Guest using vnc, you should "
"edit the VM Guest XML configuration file. For example, to add an <literal>en-"
"us</literal> keymap, add in the <literal>&lt;devices&gt;</literal> section:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3090
#, no-wrap
msgid "&lt;graphics type='vnc' port='-1' autoport='yes' keymap='en-us'/&gt;"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3091
msgid ""
"Check the <literal>vncdisplay</literal> configuration and connect to your VM "
"Guest:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3095
#, no-wrap
msgid "<prompt>tux &gt; </prompt>virsh vncdisplay sles12 127.0.0.1:0"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3099
msgid "Spice default listen URL"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3100
msgid ""
"If no network interface other than <literal>lo</literal> is assigned an IPv4 "
"address on the host, the default address on which the spice server listens "
"will not work. An error like the following one will occur:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3105
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt>virsh start sles12\n"
"error: Failed to start domain sles12\n"
"error: internal error: process exited while connecting to monitor: ((null):26929): Spice-Warning **: reds.c:2330:reds_init_socket: getaddrinfo(127.0.0.1,5900): Address family for hostname not supported\n"
"2015-08-12T11:21:14.221634Z qemu-system-x86_64: failed to initialize spice server"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3109
msgid ""
"To fix this, you can change the default <literal>spice_listen</literal> "
"value in <filename>/etc/libvirt/qemu.conf</filename> using the local IPv6 "
"address <systemitem class=\"ipaddress\">::1</systemitem>. The spice server "
"listening address can also be changed on a per VM Guest basis, use "
"<command>virsh edit</command> to add the listen XML attribute to the "
"<literal>graphics type='spice'</literal> element:"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3117
#, no-wrap
msgid "&lt;graphics type='spice' listen='::1' autoport='yes'/&gt;&gt;"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3121
msgid "XML to QEMU command line"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3122
msgid ""
"Sometimes it could be useful to get the QEMU command line to launch the VM "
"Guest from the XML file."
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3126
#, no-wrap
msgid "<prompt>tux &gt; </prompt>virsh domxml-to-native<co xml:id=\"co.domxml.native\"/> qemu-argv<co xml:id=\"co.domxml.argv\"/> SLE12.xml<co xml:id=\"co.domxml.file\"/>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3129
msgid ""
"Convert the XML file in domain XML format to the native guest configuration"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3135
msgid "For the QEMU/KVM hypervisor, the format argument needs be qemu-argv"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3140
msgid "Domain XML file to use"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3145
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt><command>sudo</command> virsh domxml-to-native qemu-argv /etc/libvirt/qemu/SLE12.xml\n"
"LC_ALL=C PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\n"
"   QEMU_AUDIO_DRV=none /usr/bin/qemu-system-x86_64 -name SLE12 -machine \\\n"
"   pc-i440fx-2.3,accel=kvm,usb=off -cpu SandyBridge -m 4048 -realtime \\\n"
"   mlock=off -smp 4,sockets=4,cores=1,threads=1 -uuid 8616d00f-5f05-4244-97cc-86aeaed8aea7 \\\n"
"   -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/SLE12.monitor,server,nowait \\\n"
"   -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew \\\n"
"   -global kvm-pit.lost_tick_policy=discard -no-hpet \\\n"
"   -no-shutdown -global PIIX4_PM.disable_s3=1 -global PIIX4_PM.disable_s4=1 \\\n"
"   -boot strict=on -device ich9-usb-ehci1,id=usb,bus=pci.0,addr=0x4.0x7 \\\n"
"   -device ich9-usb-uhci1,masterbus=usb.0,firstport=0,bus=pci.0,multifunction=on,addr=0x4 \\\n"
"   -device ich9-usb-uhci2,masterbus=usb.0,firstport=2,bus=pci.0,addr=0x4.0x1 \\\n"
"   -device ich9-usb-uhci3,masterbus=usb.0,firstport=4,bus=pci.0,addr=0x4.0x2 \\\n"
"   -drive file=/var/lib/libvirt/images/SLE12.qcow2,if=none,id=drive-virtio-disk0,format=qcow2,cache=none \\\n"
"   -device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x6,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=2 \\\n"
"   -drive if=none,id=drive-ide0-0-1,readonly=on,format=raw  \\\n"
"   -device ide-cd,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,id=hostnet0  \\\n"
"   -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:28:04:a9,bus=pci.0,addr=0x3,bootindex=1 \\\n"
"   -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 \\\n"
"   -vnc 127.0.0.1:0 -device cirrus-vga,id=video0,bus=pci.0,addr=0x2 \\\n"
"   -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5 -msg timestamp=on"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3169
msgid "Change Kernel Parameters at Boot Time"
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:3171
msgid "SUSE Linux Enterprise 11"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:3172
msgid ""
"To change the value for SLE 11 products at boot time, you need to modify "
"your <filename>/boot/grub/menu.lst</filename> file by adding the "
"<option>OPTION=parameter</option>. Then reboot your system."
msgstr ""

#. (itstool) path: sect3/title
#: xml/vt_best_practices.xml:3179
msgid "SUSE Linux Enterprise 12"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:3180
msgid ""
"To change the value for SLE 12 products at boot time, you need to modify "
"your <filename>/etc/default/grub</filename> file. Find the variable starting "
"with <option>GRUB_CMDLINE_LINUX_DEFAULT</option> and add at the end "
"<option>OPTION=parameter</option> (or change it with the correct value if it "
"is already available)."
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:3187
msgid "Now you need to regenerate your <literal>grub2</literal> configuration:"
msgstr ""

#. (itstool) path: sect3/screen
#: xml/vt_best_practices.xml:3190
#, no-wrap
msgid "# grub2-mkconfig -o /boot/grub2/grub.cfg"
msgstr ""

#. (itstool) path: sect3/para
#: xml/vt_best_practices.xml:3191
msgid "Then reboot your system"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3198
msgid "Add a Device to an XML Configuration"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3199
msgid ""
"To create a new VM Guest based on an XML file, you can specify the QEMU "
"command line using the special tag <literal>qemu:commandline</literal>. For "
"example, to add a virtio-balloon-pci, add this block at the end of the XML "
"configuration file (before the &lt;/domain&gt; tag):"
msgstr ""

#. (itstool) path: sect2/screen
#: xml/vt_best_practices.xml:3206
#, no-wrap
msgid ""
"&lt;qemu:commandline&gt;\n"
"    &lt;qemu:arg value='-device'/&gt;\n"
"    &lt;qemu:arg value='virtio-balloon-pci,id=balloon0'/&gt;\n"
"&lt;/qemu:commandline&gt;"
msgstr ""

#. (itstool) path: sect1/title
#. (itstool) path: table/title
#: xml/vt_best_practices.xml:3516 xml/vt_best_practices.xml:3521
msgid "Hypervisors Compared to Containers"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3529
msgid "Features"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3534
msgid "Hypervisors"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3539
msgid "Containers"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3548
msgid "Technologies"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3553
msgid "Emulation of a physical computing environment"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3558
msgid "Use kernel host"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3565
msgid "System layer level"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3570
msgid "Managed by a virtualization layer (Hypervisor)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3575
msgid "Rely on kernel namespaces and cgroups"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3582
msgid "Level (layer)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3587
msgid "Hardware level"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3592
msgid "Software level"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3599
msgid "Virtualization mode available"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3604
msgid "FV or PV"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3609
msgid "None, only user space"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3616
msgid "Security"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3621
msgid "Strong"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3626
msgid "Warning: Security is very low"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3633
msgid "Confinement"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3638
msgid "Full isolation"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3643
msgid "Warning: Host kernel (OS must be compatible with kernel version)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3650
msgid "Operating system"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3655
msgid "Any operating system"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3660
msgid "Only Linux (must be \"kernel\" compatible)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3667
msgid "Type of system"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3672
msgid "Full OS needed"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3677
msgid "Scope is an instance of Linux"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3684
msgid "Boot time"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3689
msgid "Slow to start (OS delay)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3694
msgid "Really quick start"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3701
msgid "Overhead"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3706
msgid "High"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3711
msgid "Very low"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3718
msgid "Efficiency"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3723
msgid "Depends on OS"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3728
msgid "Very efficient"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3735
msgid "Sharing with host"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3740
msgid "Warning: Complex because of isolation"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3745
msgid "Sharing is easy (host sees everything; container sees its own objects)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3753
msgid "Migration"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3758
msgid "Supports migration (live mode)"
msgstr ""

#. (itstool) path: entry/para
#: xml/vt_best_practices.xml:3763
msgid "Warning: Not possible"
msgstr ""

#. (itstool) path: sect2/title
#: xml/vt_best_practices.xml:3773
msgid "Getting the Best of Both Worlds"
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3774
msgid ""
"Even if the above table seems to indicate that running a single application "
"in a highly secure way is not possible, <command>virt-sandbox</command> will "
"allow running a single application in a KVM guest, starting with SUSE Linux "
"Enterprise Server 12 SP1. <command>virt-sandbox</command> bootstraps any "
"command within a Linux kernel with a minimal root file system."
msgstr ""

#. (itstool) path: sect2/para
#: xml/vt_best_practices.xml:3781
msgid ""
"The guest root file system can either be the root file system mounted read-"
"only or a disk image. The following steps will show how to set up a sandbox "
"with qcow2 disk image as root file system."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3788
msgid "Create the disk image using <command>qemu-img</command>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:3791
#, no-wrap
msgid "<prompt role=\"root\">root # </prompt>qemu-img create -f qcow2 rootfs.qcow2 6G"
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3794
msgid "Format the disk image:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:3797
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>modprobe nbd<co xml:id=\"co.vsmkfs.modprobe\"/>\n"
"<prompt role=\"root\">root # </prompt>/usr/bin/qemu-nbd --format qcow2 -n -c /dev/nbd0 $PWD/test-base.qcow2<co xml:id=\"co.vsmkfs.qemu-nbd\"/>\n"
"<prompt role=\"root\">root # </prompt>mkfs.ext3 /dev/nbd0<co xml:id=\"co.vsmkfs.do\"/>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3802
msgid ""
"Make sure the nbd module is loaded: it is not loaded by default and will "
"only be used to format the qcow image."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3808
msgid ""
"Create an NBD device for the qcow2 image. This device will then behave like "
"any other block device. The example uses <replaceable>/dev/nbd0</"
"replaceable> but any other free NBD device will work."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3816
msgid ""
"Format the disk image directly. Note that no partition table has been "
"created: <command>virt-sandbox</command> considers the image to be a "
"partition, not a disk."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3821
msgid ""
"The partition formats that can be used are limited: the Linux kernel "
"bootstrapping the sandbox needs to have the corresponding features built in. "
"The Ext4 module is also available at the sandbox start-up time."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3831
msgid "Now populate the newly formatted image:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:3834
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>guestmount -a base.qcow2 -m /dev/sda:/ /mnt<co xml:id=\"co.vsfs.mount\"/>\n"
"\n"
"<prompt role=\"root\">root # </prompt>zypper --root /mnt ar cd:///?devices=/dev/dvd SLES12_DVD\n"
"<prompt role=\"root\">root # </prompt>zypper --root /mnt in -t pattern Minimal<co xml:id=\"co.vsfs.install\"/>\n"
"\n"
"<prompt role=\"root\">root # </prompt>guestunmount /mnt<co xml:id=\"co.vsfs.unmount\"/>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3843
msgid "Mount the qcow2 image using the <command>guestfs</command> tools."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3848
msgid ""
"Use Zypper with the <literal>--root</literal> parameter to add a SUSE Linux "
"Enterprise Server repository and install the <literal>Minimal</literal> "
"pattern in the disk image. Any additional package or configuration change "
"should be performed in this step."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:3855
msgid "Using backing chains"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:3856
msgid ""
"To share the root file system between several sandboxes, create qcow2 images "
"with a common disk image as backing chain as described in <xref linkend="
"\"sec.vt.best.img.overlay\"/>."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3864
msgid "Unmount the qcow2 image."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3871
msgid ""
"Run the sandbox, using <command>virt-sandbox</command>. This command has "
"many interesting options, read its man page to discover them all. The "
"command can be run as <systemitem class=\"username\">root</systemitem> or as "
"an unprivileged user."
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:3876
#, no-wrap
msgid ""
"<prompt role=\"root\">root # </prompt>virt-sandbox -n <replaceable>NAME</replaceable> \\\n"
"     -m host-image:/=$PWD/rootfs.qcow2 \\ <co xml:id=\"co.vs.rootfs\"/>\n"
"     -m host-bind:/srv/www=/guests/www \\ <co xml:id=\"co.vs.bind\"/>\n"
"     -m ram:/tmp=100MiB \\\n"
"     -m ram:/run=100MiB \\ <co xml:id=\"co.vs.tmpfs\"/>\n"
"     -N source=default,address=192.168.122.12/24 \\ <co xml:id=\"co.vs.net\"/>\n"
"     -- \\\n"
"     <replaceable>/bin/sh</replaceable>"
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3886
msgid ""
"Mount the created disk image as the root file system. Note that without any "
"image being mounted as <filename>/</filename>, the host root file system is "
"read-only mounted as the guest one."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3891
msgid ""
"The host-image mount is not reserved for the root file system, it can be "
"used to mount any disk image anywhere in the guest."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3897
msgid ""
"The host-bind mount is pretty convenient for sharing files and directories "
"between the host and the guest. In this example the host directory "
"<filename>/guests/www</filename> is mounted as <filename>/srv/www</filename> "
"in the sandbox."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3905
msgid ""
"The RAM mounts are defining <literal>tmpfs</literal> mounts in the sandbox."
msgstr ""

#. (itstool) path: callout/para
#: xml/vt_best_practices.xml:3911
msgid ""
"The network uses a network defined in libvirt. When running as an "
"unprivileged user, the source can be omitted, and the KVM user networking "
"feature will be used. Using this option requires the <package>dhcp-client</"
"package> and <package>iproute2</package> packages, which are part of the "
"SUSE Linux Enterprise Server <literal>Minimal</literal> pattern."
msgstr ""

#. (itstool) path: sect1/title
#: xml/vt_best_practices.xml:3930
msgid ""
"Xen: Converting a Paravirtual (PV) Guest to a Fully Virtual (FV/HVM) Guest"
msgstr ""

#. (itstool) path: sect1/para
#: xml/vt_best_practices.xml:3931
msgid ""
"This chapter explains how to convert a Xen paravirtual machine into a Xen "
"fully virtualized machine."
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:3936
msgid "Guest Side"
msgstr ""

#. (itstool) path: procedure/para
#: xml/vt_best_practices.xml:3937
msgid ""
"In order to start the guest in FV mode, you have to run the following steps "
"inside the guest."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3941
msgid ""
"Prior to converting the guest, apply all pending patches and reboot the "
"guest."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3946
msgid ""
"FV machines use the <literal>-default</literal> kernel. If this kernel is "
"not already installed, install the <literal>kernel-default</literal> package "
"(while running in PV mode)."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3953
msgid ""
"PV machines typically use disk names such as <literal>vda*</literal>. These "
"names must be changed to the FV <literal>hd*</literal> syntax. This change "
"must be done in the following files:"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:3960
msgid "<filename>/etc/fstab</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:3962
msgid "<filename>/boot/grub/menu.lst</filename> (SLES11 only)"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:3963
msgid "<filename>/boot/grub*/device.map</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:3964
msgid "<filename>/etc/sysconfig/bootloader</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:3966
msgid "<filename>/etc/default/grub</filename> (SLES12 only)"
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:3970
msgid "Prefer UUIDs"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:3971
msgid ""
"You should use UUIDs or logical volumes within your <filename>/etc/fstab</"
"filename>. Using UUID simplifies using attached network storage, "
"multipathing, and virtualization. To find the UUID of your disk use the "
"command <command>blkid</command>."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3980
msgid ""
"To avoid any error regenerating the initrd with the needed modules you can "
"create a symlink from <filename>/dev/hda2</filename> to <filename>/dev/"
"xvda2</filename> etc. by using the <command>ln</command>:"
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:3984
#, no-wrap
msgid ""
"ln -sf /dev/xvda2 /dev/hda2\n"
"ln -sf /dev/xvda1 /dev/hda1\n"
"....."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:3989
msgid ""
"PV and FV machines use different disk and network driver modules. These FV "
"modules must be added to the initrd manually. The expected modules are "
"<literal>xen-vbd</literal> (for disk) and <literal>xen-vnif</literal> (for "
"network). These are the only PV drivers for a fully virtualized VM Guest. "
"All other modules, such as <literal>ata_piix</literal>, "
"<literal>ata_generic</literal> and <literal>libata</literal>, should be "
"added automatically."
msgstr ""

#. (itstool) path: tip/title
#: xml/vt_best_practices.xml:3998
msgid "Adding Modules to the initrd"
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:4001
msgid ""
"On SLES 11, you can add modules to the <literal>INITRD_MODULES</literal> "
"line in the <filename>/etc/sysconfig/kernel</filename> file. For example:"
msgstr ""

#. (itstool) path: listitem/screen
#: xml/vt_best_practices.xml:4006
#, no-wrap
msgid "INITRD_MODULES=\"xen-vbd xen-vnif\""
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:4007
msgid ""
"Run <command>mkinitrd</command> to build a new initrd containing the modules."
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:4013
msgid ""
"On SLES 12, open or create <filename>/etc/dracut.conf.d/01-dist.conf</"
"filename> and add the modules with <literal>force_drivers</literal> by "
"adding a line as in the example below:"
msgstr ""

#. (itstool) path: listitem/screen
#: xml/vt_best_practices.xml:4018
#, no-wrap
msgid "force_drivers+=\"xen-vbd xen-vnif\""
msgstr ""

#. (itstool) path: listitem/para
#: xml/vt_best_practices.xml:4019
msgid ""
"Run <command>dracut -f --kver [KERNEL_VERSION]-default</command> to build a "
"new initrd (for the -default version of the kernel) which contains the "
"required modules."
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:4024
msgid "Find your Kernel version"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:4024
msgid ""
"Use the <command>uname -r</command> command to get the current version used "
"on your system."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:4030
msgid ""
"Before shutting down the guest, set the default boot parameter to the "
"<literal>-default</literal> kernel using <command>yast bootloader</command>."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:4036
msgid ""
"Under <phrase role=\"productname\"><phrase os=\"osuse\">openSUSE Leap</"
"phrase><phrase os=\"sles\">SUSE Linux Enterprise Server</phrase><phrase os="
"\"sled\">SUSE Linux Enterprise Desktop</phrase></phrase> 11, if you have an "
"X server running on your guest, you need to adjust the <filename>/etc/X11/"
"xorg.conf</filename> file to adjust the X driver. Search for <literal>fbdev</"
"literal> and change to <literal>cirrus</literal>."
msgstr ""

#. (itstool) path: step/screen
#: xml/vt_best_practices.xml:4040
#, no-wrap
msgid ""
"Section \"Device\"\n"
"          Driver       \"cirrus\"\n"
"          ......\n"
"          EndSection"
msgstr ""

#. (itstool) path: note/title
#: xml/vt_best_practices.xml:4044
msgid ""
"<phrase role=\"productname\"><phrase os=\"osuse\">openSUSE Leap</"
"phrase><phrase os=\"sles\">SUSE Linux Enterprise Server</phrase><phrase os="
"\"sled\">SUSE Linux Enterprise Desktop</phrase></phrase> 12 and Xorg"
msgstr ""

#. (itstool) path: note/para
#: xml/vt_best_practices.xml:4044
msgid ""
"Under <phrase role=\"productname\"><phrase os=\"osuse\">openSUSE Leap</"
"phrase><phrase os=\"sles\">SUSE Linux Enterprise Server</phrase><phrase os="
"\"sled\">SUSE Linux Enterprise Desktop</phrase></phrase> 12, Xorg will "
"automatically adjust the driver needed to be able to get a working X server."
msgstr ""

#. (itstool) path: step/para
#: xml/vt_best_practices.xml:4047
msgid "Shut down the guest."
msgstr ""

#. (itstool) path: procedure/title
#: xml/vt_best_practices.xml:4053
msgid "Host Side"
msgstr ""

#. (itstool) path: procedure/para
#: xml/vt_best_practices.xml:4054
msgid "The following steps explain the action you have to do on the host."
msgstr ""
