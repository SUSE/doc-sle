<?xml version="1.0"?>
<!DOCTYPE glossary PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>

<glossdiv id="gloss.vt.acronym">
 <title>Acronyms</title>
 <glossentry id="gloss.vt.acronym.vmroot">
  <glossterm>VM root</glossterm>
  <glossdef>
   <para>
    <xref linkend="gloss.vt.acronym.hypervisor_vmm"/> will run in <xref
    linkend="gloss.vt.acronym.vmx"/> root
    operation and guest software will run in <xref linkend="gloss.vt.acronym.vmx"/> non-root
    operation. Transitions between <xref linkend="gloss.vt.acronym.vmx"/>
    root operation and
    <xref linkend="gloss.vt.acronym.vmx"/> non-root
    operation are called <xref linkend="gloss.vt.acronym.vmx"/> transitions.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.vhs">
  <glossterm>VHS</glossterm>
  <glossdef>
   <para>virtualization host server
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.pae">
  <glossterm>PAE</glossterm>
  <glossdef>
   <para>
    Physical Address Extension
   </para>
   <para>
    32 bit x86 operating systems use Physical Address Extension (PAE) mode to
    enable addressing of more than 4 GB of physical memory. In PAE mode, page
    table entries (PTEs) are 64 bits in size.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.hypervisor_vmm">
  <glossterm>VMM</glossterm>
  <glossdef>
   <para>
    Virtual Machine Monitor (Hypervisor)
   </para>
   <para>
    When the processor encounters an instruction or event of interest to the
    Hypervisor (<xref linkend="gloss.vt.acronym.hypervisor_vmm"/>), it exits from guest mode back to the
    VMM. The VMM emulates the instruction or other event, at a fraction of
    native speed, and then returns to guest mode. The transitions from guest
    mode to the VMM and back again are high latency operations, during which
    guest execution is completely stalled.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.mmu">
  <glossterm>MMU</glossterm>
  <glossdef>
   <para>
    Memory Management Unit
   </para>
   <para>
    is a computer hardware component responsible for handling accesses to
    memory requested by the CPU. Its functions include translation of virtual
    addresses to physical addresses (i.e., virtual memory management), memory
    protection, cache control, bus arbitration and in simpler computer
    architectures (especially 8-bit systems) bank switching.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.iommu">
  <glossterm>IOMMU</glossterm>
  <glossdef>
   <para>
    Input/Output Memory Management Unit
   </para>
   <para>
    IOMMU (AMD* technology) is a memory management unit (<xref linkend="gloss.vt.acronym.mmu"/>)
    that connects a direct memory access-capable (DMA-capable) I/O bus to the main memory.
   </para>
  </glossdef>
 </glossentry>
  <glossentry id="gloss.vt.acronym.vtd">
  <glossterm>VT-d</glossterm>
  <glossdef>
   <para>
    Virtualization Technology for Directed I/O
   </para>
   <para>
    Like <xref linkend="gloss.vt.acronym.iommu"/> for <ulink url="https://software.intel.com/en-us/articles/intel-virtualization-technology-for-directed-io-vt-d-enhancing-intel-platforms-for-efficient-virtualization-of-io-devices">Intel*</ulink>.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.ept">
  <glossterm>EPT</glossterm>
  <glossdef>
   <para>
    Extended Page Tables
   </para>
   <para>
    Performance in a virtualized environment is close to that in a native
    environment. Virtualization does create some overheads, however. These
    come from the virtualization of the CPU, the <xref linkend="gloss.vt.acronym.mmu"/>,
    and the I/O devices. In some of their recent x86 processors AMD and Intel
    have begun to provide hardware extensions to help bridge this performance
    gap. In 2006, both vendors introduced their first generation hardware
    support for x86 virtualization with AMD-VirtualizationTM (AMD-VTM) and
    IntelÂ® VT-x technologies. Recently Intel introduced its second generation
    of hardware support that incorporates MMU-virtualization, called Extended
    Page Tables (EPT). EPT-enabled systems can improve performance compared to
    using shadow paging for  <xref linkend="gloss.vt.acronym.mmu"/>
    virtualization. EPT increases memory access
    latencies for a few workloads, this cost can be reduced by effectively
    using large pages in the guest and the hypervisor.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.rvi_npt">
  <glossterm>RVI or NPT</glossterm>
  <glossdef>
   <para>
    Rapid Virtualization Indexing, Nested Page Tables
   </para>
   <para>
    It's an AMD second generation hardware-assisted virtualization technology
    for the processor memory management unit (<xref linkend="gloss.vt.acronym.mmu"/>)
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.pse_pse36">
  <glossterm>PSE and PSE36</glossterm>
  <glossdef>
   <para>
    Page Size Extended
   </para>
   <para>
    PSE refers to a feature of x86 processors that
    allows for pages larger than the traditional 4 KiB size. PSE-36 capability
    offers 4 more bits, in addition to normal 10 bits, are used inside a page
    directory entry pointing to a large page. This allows a large page to be
    located in 36 bit address space.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.pt">
  <glossterm>PT</glossterm>
  <glossdef>
   <para>
    Page Table
   </para>
  <para>
   A page table is the data structure used by a virtual memory system in a
   computer operating system to store the mapping between virtual addresses
   and physical addresses. Virtual addresses are those unique to the accessing
   process. Physical addresses are those unique to the hardware (RAM).
  </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.vmcs">
  <glossterm>VMCS</glossterm>
  <glossdef>
   <para>
    Virtual Machine Control Structure
   </para>
   <para>
    VMX non-root operation and VMX transitions are controlled by a data
    structure called a virtual-machine control structure (VMCS). Access to the
    VMCS is managed through a component of processor state called the VMCS
    pointer (one per logical processor). The value of the VMCS pointer is the
    64-bit address of the VMCS. The VMCS pointer is read and written using the
    instructions VMPTRST and VMPTRLD. The <xref
    linkend="gloss.vt.acronym.hypervisor_vmm"/> configures a VMCS using the
    VMREAD, VMWRITE, and VMCLEAR instructions. A 
    <xref linkend="gloss.vt.acronym.hypervisor_vmm"/> could use a different
    VMCS for each virtual machine that it supports. For a virtual machine with
    multiple logical processors (virtual processors), the
    <xref linkend="gloss.vt.acronym.hypervisor_vmm"/> could use a
    different VMCS for each virtual processor.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.tlb">
  <glossterm>TLB</glossterm>
  <glossdef>
   <para>
    Translation Lookaside Buffer
   </para>
   <para>
    TLB is a cache that memory management hardware uses to improve virtual
    address translation speed. All current desktop, notebook, and server
    processors use a TLB to map virtual and physical address spaces, and it is
    nearly always present in any hardware which utilizes virtual memory.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.pcid">
  <glossterm>PCID</glossterm>
  <glossdef>
   <para>
    Process-context identifiers
   </para>
   <para>
    They are a facility by which a logical processor may cache information for
    multiple linear-address spaces so that the processor may retain cached
    information when software switches to a different linear address
    space. INVPCID instruction is used for fine-grained <xref
    linkend="gloss.vt.acronym.tlb"/> flush which is
    benefit for kernel.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.vpid">
  <glossterm>VPID</glossterm>
  <glossdef>
   <para>
    New Support for Software Control of <xref linkend="gloss.vt.acronym.tlb"/>
    (VPID improves <xref linkend="gloss.vt.acronym.tlb"/> performance
    with small <xref linkend="gloss.vt.acronym.hypervisor_vmm"/> development effort).
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.vcpu">
  <glossterm>Vcpu</glossterm>
  <glossdef>
   <para>
    A scheduling entity, containing all the state for virtualized CPU.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.thp">
  <glossterm>THP</glossterm>
  <glossdef>
   <para>
    Transparent Huge Pages
   </para>
   <para>
    It's allows CPUs to address memory using pages larger than the default 4
    KB. This helps reducing memory consumption and CPU cache usage. &kvm; is
    optimized to use THP (via madvise and opportunistic methods) if enabled on
    the &vmhost;.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.tcg">
  <glossterm>TCG</glossterm>
  <glossdef>
   <para>
    Tiny Code Generator
   </para>
   <para>
    Instruction are emulated rather than executed by the CPU.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.vfio">
  <glossterm>vfio</glossterm>
  <glossdef>
   <para>
    Since kernel v3.6 a new method of accessing PCI devices from userspace called vfio.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.vtpm">
  <glossterm>vTPM</glossterm>
  <glossdef>
   <para>
    Component to establish end-to-end integrity for guests via Trusted Computing
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.seccomp2_based_sandboxing">
  <glossterm>Seccomp2 based sandboxing</glossterm>
  <glossdef>
   <para>
    Sandboxed environment where only predetermined system calls are permitted
    for added protection against malicious behavior
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.cg">
  <glossterm>CG</glossterm>
  <glossdef>
   <para>
    Control Groups
   </para>
   <para>
    Feature to limit, account and isolate resource usage (CPU, memory, disk
    I/O, etc.)
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.smep">
  <glossterm>SMEP</glossterm>
  <glossdef>
   <para>
    Supervisor Mode Execution Protection
   </para>
   <para>
    This prevent the execution of usermode pages by the Xen hypervisor, making
    many application-to-hypervisor exploits much harder.
   </para>
  </glossdef>
 </glossentry>
 <glossentry id="gloss.vt.acronym.vmdq">
  <glossterm>VMDq</glossterm>
  <glossdef>
   <para>
    Virtual Machine Device Queue
   </para>
  <para>
   Multi-queue network adapters exist which support multiple VMs at the
   hardware level, having separate packet queues associated to the different
   hosted VMs (by means of the IP addresses of the VMs).
  </para>
  </glossdef>
 </glossentry>
  <glossentry id="gloss.vt.acpi">
   <glossterm>ACPI</glossterm>
   <glossdef>
    <para>
     Advanced Configuration and Power Interface (ACPI) specification provides
     an open standard for device configuration and power management by the 
     operating system.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.apic">
   <glossterm>APIC</glossterm>
   <glossdef>
    <para>
     Advanced Programmable Interrupt Controller (APIC) is a family of
     interrupt controllers.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.ksm">
   <glossterm>KSM</glossterm>
   <glossdef>
    <para>
     Kernel Samepage Merging
    </para>
    <para>
     KSM allows for automatic sharing of identical memory pages between
     guests to save host memory. &kvm; is optimized to use KSM if enabled
     on the &vmhost;.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.hvm">
   <glossterm>HVM</glossterm>
   <glossdef>
    <para>
     Hardware Virtual Machine (commonly called like that by &xen;).
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.vmx">
   <glossterm>VMX</glossterm>
   <glossdef>
    <para>
     Virtual Machine eXtensions
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.hap">
   <glossterm>HAP</glossterm>
   <glossdef>
    <para>
     High Assurance Platform
    </para>
    <para>
     HAP combines hardware and software technologies to improve workstation and network security.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.spice">
   <glossterm>SPICE</glossterm>
   <glossdef>
    <para>
     Simple Protocol for Independent Computing Environments
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.vdi">
   <glossterm>VDI</glossterm>
   <glossdef>
    <para>
     Virtual Desktop Infrastructure
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.qxl">
   <glossterm>QXL</glossterm>
   <glossdef>
    <para>
     QXL is a cirrus VGA framebuffer (8M) driver for virtualized environment.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.aer">
   <glossterm>AER</glossterm>
   <glossdef>
    <para>
     Advanced Error Reporting
    </para>
    <para>
     AER is a capability provided by the PCI Express specification which
     allows for reporting of PCI errors and recovery from some of those errors.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.sata">
   <glossterm>SATA</glossterm>
   <glossdef>
    <para>Serial ATA</para>
    <para>
     SATA is a computer bus interface that connects host bus
     adapters to mass storage devices such as hard disk drives and optical
     drives.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.vt.acronym.pcie">
   <glossterm>PCIe</glossterm>
   <glossdef>
    <para>
     Peripheral Component Interconnect Express
    </para>
    <para>
     PCIe was designed to replace older PCI, PCI-X and AGP bus standards. PCIe
     has numerous improvements including a higher maximum system bus
     throughput, a lower I/O pin count and smaller physical
     footprint. Moreover it also has a more detailed error detection and
     reporting mechanism (<xref linkend="gloss.vt.acronym.aer"/>), and
     a native hot-plug functionality. It is
     also backward compatible with PCI.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.xmtoxl.vt.bdf">
   <glossterm>BDF</glossterm>
   <glossdef>
    <para>Bus:Device:Function</para>
    <para>
     Notation used to succinctly describe PCI and PCIe devices
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.xmtoxl.vt.edf">
   <glossterm>EDF</glossterm>
   <glossdef>
    <para>Earliest Deadline First</para>
    <para>
     This scheduler provides
     weighted CPU sharing in an intuitive way and uses
     realtime-algorithms to ensure time guarantees.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.xmtoxl.vt.flask">
   <glossterm>FLASK</glossterm>
   <glossdef>
    <para>Flux Advanced Security Kernel</para>
    <para>
      &xen; implements a type of mandatory access control via a security
      architecture called FLASK using a module of the same name.
    </para>
   </glossdef>
  </glossentry>
  <glossentry id="gloss.xmtoxl.vt.sxp">
   <glossterm>SXP</glossterm>
   <glossdef>
    <para>
     SXP file is a &xen; Configuration File.
    </para>
   </glossdef>
  </glossentry>
</glossdiv>

