<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook50-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE article
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<article xml:id="article-nvidia-vgpu" xml:lang="en" version="5.0"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>&nvidia; virtual GPU (vGPU) Guide</title>
 <info><productname>&productname;</productname>
  <productnumber>&productnumber;</productnumber><date>
<?dbtimestamp format="B d, Y" ?></date>
 </info>
 <sect1 xml:id="configure-nvidia-vgpu-introduction">
  <title>Introduction</title>

  <para>
   &nvidia; vGPU is a graphics virtualization solution that provides multiple
   virtual machines (VMs) simultaneous access to one physical Graphics
   Processing Unit (GPU) on the &vmhost;. This article refers to the Volta and
   Ampere GPU architecture.
  </para>
 </sect1>
 <sect1 xml:id="configure-nvidia-vgpu-topology">
  <title>Topology</title>

  <sect2 xml:id="configure-nvidia-vgpu-architecture">
   <title>&nvidia; GPU architectures</title>
   <para>
    There are two types of GPU architectures:
   </para>
   <variablelist>
    <varlistentry>
     <term>Time-sliced vGPU architecture</term>
     <listitem>
      <para>
       Introduced on GPUs that are based on the &nvidia; Ampere GPU
       architecture. Only Ampere GPU cards can support MIG-backed vGPU.
      </para>
      <figure>
       <title>Time-sliced architecture</title>
       <mediaobject>
        <imageobject role="fo">
         <imagedata fileref="nvidia-vgpu-time-sliced.png" width="75%"/>
        </imageobject>
        <imageobject role="html">
         <imagedata fileref="nvidia-vgpu-time-sliced.png" width="75%"/>
        </imageobject>
       </mediaobject>
      </figure>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Multi-Instance GPU (MIG) vGPU architecture</term>
     <listitem>
      <para>
       All GPU cards support time-sliced vGPU. For time-sliced vGPU
       architecture, Ampere GPU cards are based on Single Root I/O
       Virtualization (SR-IOV) mechanism. Volta and the earlier architecture
       are based on meditated device mechanism. These two mechanisms are
       transparent to a VM. However, they need different configurations from
       the host side.
      </para>
      <figure>
       <title>MIG-backed architecture</title>
       <mediaobject>
        <imageobject role="fo">
         <imagedata fileref="nvidia-vgpu-mig-backed.png" width="75%"/>
        </imageobject>
        <imageobject role="html">
         <imagedata fileref="nvidia-vgpu-mig-backed.png" width="75%"/>
        </imageobject>
       </mediaobject>
      </figure>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="configure-nvidia-vgpu-vgpu-types">
   <title>vGPU types</title>
   <para>
    Each physical GPU can support several different types of vGPUs. vGPU types
    have a fixed amount of frame buffer, the number of supported display heads,
    and maximum resolutions. NVIDIA has four types of vGPUs: A, B, C, and
    Q-series. &suse; currently supports Q and C-series.
   </para>
   <table>
    <title>vGPU types</title>
    <tgroup cols="2" align="left">
     <colspec colname="c1" colwidth="20*"/>
     <colspec colname="c2" colwidth="80*"/>
     <thead>
      <row>
       <entry>
        <para>
         vGPU series
        </para>
       </entry>
       <entry>
        <para>
         Optimal workload
        </para>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         Q-series
        </para>
       </entry>
       <entry>
        <para>
         Virtual workstations for creative and technical professionals who
         require the performance and features of the &nvidia; Quadro
         technology.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         C-series
        </para>
       </entry>
       <entry>
        <para>
         Compute-intensive server workloads, for example, artificial
         intelligence (AI), deep learning, or high-performance computing (HPC).
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         B-series
        </para>
       </entry>
       <entry>
        <para>
         Virtual desktops for business professionals and knowledge workers.
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         A-series
        </para>
       </entry>
       <entry>
        <para>
         Application streaming or session-based solutions for virtual
         applications users.
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </sect2>

  <sect2 xml:id="configure-nvidia-vgpu-valid-configurations">
   <title>Valid vGPU configurations on a single GPU</title>
   <sect3 xml:id="configure-nvidia-vgpu-valid-configurations-time-sliced">
    <title>Time-sliced vGPU configurations</title>
    <para>
     For time-sliced vGPUs, all vGPUs types must be the same:
    </para>
    <figure>
     <title>Example time-sliced vGPU configurations on &nvidia; Tesla M60</title>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="nvidia-vgpus-supported.png" width="75%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="nvidia-vgpus-supported.png" width="75%"/>
      </imageobject>
     </mediaobject>
    </figure>
   </sect3>
   <sect3 xml:id="configure-nvidia-vgpu-valid-configurations-mig-backed">
    <title>MIG-backed vGPU configurations</title>
    <para>
     For MIG-backed vGPUs, vGPUs can be both homogeneous and mixed-type:
    </para>
    <figure>
     <title>Example MIG-backed vGPU configurations on &nvidia; A100 PCIe 40GB</title>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="nvidia-vgpus-supported2.png" width="75%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="nvidia-vgpus-supported2.png" width="75%"/>
      </imageobject>
     </mediaobject>
    </figure>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="configure-nvidia-vgpu-configuring-host">
  <title>Configuring vGPU manager in &vmhost;</title>

  <sect2 xml:id="configure-nvidia-vgpu-verify-host">
   <title>Prepare &vmhost; environment</title>
   <procedure>
    <step>
     <para>
      Verify that you have a compatible server and GPU cards. Check
      specification (FIXME) for details.
     </para>
    </step>
    <step>
     <para>
      Verify that &vmhost; is &sls; 15 SP2 or newer:
     </para>
<screen>
&prompt.user;cat /etc/issue
Welcome to SUSE Linux Enterprise Server 15 SP3  (x86_64) - Kernel \r (\l).
</screen>
    </step>
    <step>
     <para>
      If Ampere architecture GPU cards are used, verify that &vmhost; supports
      VT-/IOMMU and SR-IOV technologies, and that they are enabled in BIOS.
     </para>
    </step>
    <step>
     <para>
      Enable IOMMU. Verify that it is included in the boot command line:
     </para>
<screen>
cat /proc/cmdline
BOOT_IMAGE=/boot/vmlinuz-default [...] intel_iommu=on [...]
</screen>
     <para>
      If not, add the following line to <filename>/etc/default/grub</filename>.
     </para>
     <itemizedlist>
      <listitem>
       <para>
        For Intel CPUs:
       </para>
<screen>GRUB_CMDLINE_LINUX="intel_iommu=on"</screen>
       <para>
        For AMD CPUs:
       </para>
<screen>GRUB_CMDLINE_LINUX="amd_iommu=on"</screen>
      </listitem>
     </itemizedlist>
     <para>
      Then generate new &grub; configuration file and reboot:
     </para>
<screen>
&prompt.sudo;grub2-mkconfig -o /boot/grub2/grub.cfg
&prompt.sudo;systemctl reboot
</screen>
     <tip>
      <para>
       You can verify that IOMMU is loaded by running the following command:
      </para>
<screen>sudo dmesg | grep -e IOMMU</screen>
     </tip>
    </step>
    <step>
     <!-- 2021-09-21 tbazant: this seems out of place here:
      "After finishing the driver installation, run
      /usr/lib/nvidia/sriov-manage -e slot:bus:domain.function"
      -->
     <para>
      Enable SR-IOV. Refer to
      <link
      xlink:href="https://documentation.suse.com/sles/15-SP3/single-html/SLES-virtualization/#sec-libvirt-config-io"/>
      for useful information.
     </para>
    </step>
    <step>
     <para>
      Disable the nouveau kernel module by adding the following line it to the
      top of the <filename>/etc/modprobe.d/50-blacklist.conf</filename> file:
     </para>
<screen>blacklist nouveau</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="configure-nvidia-vgpu-kvm-driver">
   <title>Install the &nvidia; &kvm; driver</title>
   <procedure>
    <step>
     <para>
      Exit from the graphical mode:
     </para>
<screen>&prompt.sudo;init 3</screen>
    </step>
    <step>
     <para>
      Install the <package>kernel-default-devel</package> package and its
      dependencies:
     </para>
<screen>&prompt.sudo;zypper in kernel-default-devel</screen>
    </step>
    <step>
     <para>
      Download the vGPU software from the &nvidia; portal, make it executable,
      and run it:
     </para>
<screen>
&prompt.user;chmod +x NVIDIA-Linux-x86_64-450.55-vgpu-kvm.run
&prompt.sudo;./NVIDIA-Linux-x86_64-450.55-vgpu-kvm.run
</screen>
     <tip>
      <para>
       To enable dynamic kernel module support in order to get the module
       rebuilt automatically when new a new kernel is installed, add the
       <option>--dkms</option> option:
      </para>
<screen>&prompt.sudo;./NVIDIA-Linux-x86_64-450.55-vgpu-kvm.run --dkms</screen>
     </tip>
    </step>
    <step>
     <para>
      When the driver installation is finished, reboot the system:
     </para>
<screen>&prompt.sudo;systemctl reboot</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="configure-nvidia-vgpu-verify-driver-installation">
   <title>Verify the driver installation</title>
   <procedure>
    <step>
     <para>
      Verify loaded kernel modules:
     </para>
<screen>
&prompt.user;lsmod | grep nvidia
nvidia_vgpu_vfio       49152  9
nvidia              14393344  229 nvidia_vgpu_vfio
mdev                   20480  2 vfio_mdev,nvidia_vgpu_vfio
vfio                   32768  6 vfio_mdev,nvidia_vgpu_vfio,vfio_iommu_type1
</screen>
     <para>
      The modules containing the <literal>vfio</literal> string are required
      dependencies.
     </para>
    </step>
    <step>
     <para>
      Print the GPU device status with the <command>nvidia-smi</command>
      command. The output should be similar to the following one:
     </para>
<screen>
&prompt.user;nvidia-smi
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.63       Driver Version: 470.63       CUDA Version: N/A      |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A40          Off  | 00000000:31:00.0 Off |                    0 |
|  0%   46C    P0    39W / 300W |      0MiB / 45634MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</screen>
    </step>
    <step>
     <para>
      Check the sysfs file system. For Volta and earlier GPU cards, new
      directory <filename>mdev_supported_types</filename> is added, for
      example:
     </para>
<screen>cd /sys/bus/pci/devices/0000\:84\:00.0/mdev_supported_types</screen>
     <para>
      For Ampere GPU cards, you need to enable SR-IOV first.
      <!-- 2021-09-21 tbazant, this referes to 'out-of-place' comment below -->
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="configure-nvidia-vgpu-passthrough">
  <title>Creating a vGPU device and passing it through to a &vmguest;</title>

  <sect2 xml:id="configure-nvidia-vgpu-passthrough-without-sriov">
   <title>Create a legacy vGPU device without support for SR-IOV</title>
   <para>
    All the &nvidia; Volta and earlier architecture GPUs work in this mode.
   </para>
   <procedure>
    <step>
     <para>
      Obtain the Bus/Device/Function (BDF) numbers of the host GPU device:
     </para>
<screen>
&prompt.user;lspci | grep NVIDIA
84:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100 PCIe 16GB] (rev a1)
</screen>
    </step>
    <step>
     <para>
      Check for the mdev supported devices and detailed information:
     </para>
<screen>
&prompt.user;ls /sys/bus/pci/devices/0000:84:00.0/mdev_supported_types/
nvidia-105  nvidia-106  nvidia-107  nvidia-108  nvidia-109  nvidia-110 [...] 
</screen>
     <para>
      The map of vGPU mdev devices and their type is as follows:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        nvidia-105 to nvidia-109: 1Q 2Q 4Q 8Q 16Q
       </para>
      </listitem>
      <listitem>
       <para>
        nvidia-110 to nvidia-114: 1A 2A 4A 8A 16A
       </para>
      </listitem>
      <listitem>
       <para>
        nvidia-115, nvidia-163, nvidia-217, nvidia-247: 1B 2B 2B4 1B4
       </para>
      </listitem>
      <listitem>
       <para>
        nvidia-299 to nvidia-301: 4C 8C 16C
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Refer to
      <link xlink:href="https://docs.nvidia.com/grid/11.0/grid-vgpu-user-guide/index.html#vgpu-types-tesla-v100-pcie"/>
      for more details.
     </para>
    </step>
    <step>
     <para>
      Inspect a vGPU device:
     </para>
<screen>
&prompt.user;cd /sys/bus/pci/devices/0000:03:00.0/mdev_supported_types/
&prompt.user;ls nvidia-105
&prompt.user;cat nvidia-105/description 
num_heads=2, frl_config=60, framebuffer=1024M, max_resolution=4096x2160, max_instance=16
&prompt.user;cat nvidia-105/name 
GRID V100-1Q
</screen>
    </step>
    <step>
     <para>
      Generate a unique ID and create an mdev device based on it:
     </para>
<screen>
      &prompt.user;uuidgen
      4f3b6e47-0baa-4900-b0b1-284c1ecc192f
      &prompt.sudo;echo "4f3b6e47-0baa-4900-b0b1-284c1ecc192f" > nvidia-105/create
     </screen>
    </step>
    <step>
     <para>
      Verify the new mdev device. You can inspect the content of the
      <filename>/sys/bus/mdev/devices</filename> directory:
     </para>
<screen>
&prompt.user;cd /sys/bus/mdev/devices
&prompt.user;ls -l
lrwxrwxrwx 1 root root 0 Aug 30 23:03 86380ffb-8f13-4685-9c48-0e0f4e65fb87 \
 -> ../../../devices/pci0000:80/0000:80:02.0/0000:84:00.0/86380ffb-8f13-4685-9c48-0e0f4e65fb87
lrwxrwxrwx 1 root root 0 Aug 30 23:03 86380ffb-8f13-4685-9c48-0e0f4e65fb88 \
 -> ../../../devices/pci0000:80/0000:80:02.0/0000:84:00.0/86380ffb-8f13-4685-9c48-0e0f4e65fb88
lrwxrwxrwx 1 root root 0 Aug 30 23:03 86380ffb-8f13-4685-9c48-0e0f4e65fb89 \
 -> ../../../devices/pci0000:80/0000:80:02.0/0000:84:00.0/86380ffb-8f13-4685-9c48-0e0f4e65fb89
lrwxrwxrwx 1 root root 0 Aug 30 23:03 86380ffb-8f13-4685-9c48-0e0f4e65fb90 \
 -> ../../../devices/pci0000:80/0000:80:02.0/0000:84:00.0/86380ffb-8f13-4685-9c48-0e0f4e65fb90
</screen>
     <para>
      Or you can use the <command>mdevctl</command> command:
     </para>
<screen>
&prompt.sudo;mdevctl list
86380ffb-8f13-4685-9c48-0e0f4e65fb90 0000:84:00.0 nvidia-299
86380ffb-8f13-4685-9c48-0e0f4e65fb89 0000:84:00.0 nvidia-299
86380ffb-8f13-4685-9c48-0e0f4e65fb87 0000:84:00.0 nvidia-299
86380ffb-8f13-4685-9c48-0e0f4e65fb88 0000:84:00.0 nvidia-299
</screen>
    </step>
    <step>
     <para>
      Query the new vGPU device capability:
     </para>
<screen>
&prompt.sudo;nvidia-smi vgpu -q
GPU 00000000:84:00.0
Active vGPUs                      : 1
vGPU ID                           : 3251634323
   VM UUID                       : ee7b7a4b-388a-4357-a425-5318b2c65b3f
   VM Name                       : sle15sp3
   vGPU Name                     : GRID V100-4C
   vGPU Type                     : 299
   vGPU UUID                     : d471c7f2-0a53-11ec-afd3-38b06df18e37
   MDEV UUID                     : 86380ffb-8f13-4685-9c48-0e0f4e65fb87
   Guest Driver Version          : 460.91.03
   License Status                : Licensed
   GPU Instance ID               : N/A
   Accounting Mode               : Disabled
   ECC Mode                      : N/A
   Accounting Buffer Size        : 4000
   Frame Rate Limit              : N/A
   FB Memory Usage
       Total                     : 4096 MiB
       Used                      : 161 MiB
       Free                      : 3935 MiB
   Utilization
       Gpu                       : 0 %
       Memory                    : 0 %
       Encoder                   : 0 %
       Decoder                   : 0 %
   Encoder Stats
       Active Sessions           : 0
       Average FPS               : 0
       Average Latency           : 0
   FBC Stats
       Active Sessions           : 0
       Average FPS               : 0
       Average Latency           : 0
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="configure-nvidia-vgpu-passthrough-with-sriov">
   <title>Create a vGPU device with support for SR-IOV</title>
   <para>
    All &nvidia; Ampere and newer architecture GPUs work in this mode.
   </para>
   <procedure>
    <step>
     <para>
      Obtain the Bus/Device/Function (BDF) numbers of the host GPU device:
     </para>
<screen>
&prompt.user;lspci | grep NVIDIA
b1:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 40GB] (rev a1)
</screen>
    </step>
    <step>
     <para>
      Enable virtual functions:
     </para>
<screen>&prompt.sudo;/usr/lib/nvidia/sriov-manage -e 00:b1:0000.0</screen>
     <note>
      <para>
       This configuration is not persistent and must be re-enabled after the
       host reboot.
      </para>
     </note>
    </step>
    <step>
     <para>
      Obtain the Bus/Domain/Function (BDF) of virtual functions on the GPU:
     </para>
<screen>
&prompt.user;ls -l /sys/bus/pci/devices/0000:b1:00.0/ | grep virtfn
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn0 -> ../0000:b1:00.4
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn1 -> ../0000:b1:00.5
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn10 -> ../0000:b1:01.6
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn11 -> ../0000:b1:01.7
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn12 -> ../0000:b1:02.0
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn13 -> ../0000:b1:02.1
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn14 -> ../0000:b1:02.2
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn15 -> ../0000:b1:02.3
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn2 -> ../0000:b1:00.6
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn3 -> ../0000:b1:00.7
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn4 -> ../0000:b1:01.0
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn5 -> ../0000:b1:01.1
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn6 -> ../0000:b1:01.2
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn7 -> ../0000:b1:01.3
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn8 -> ../0000:b1:01.4
lrwxrwxrwx 1 root root           0 Sep 21 11:58 virtfn9 -> ../0000:b1:01.5
</screen>
    </step>
    <step>
     <para>
      <emphasis>Create a vGPU device.</emphasis> Select the virtual function
      (VF) that you want to use to create the vGPU device and assign it a
      unique ID.
     </para>
     <important>
      <para>
       Each VF can only create one vGPU instance. Of you want to create more
       vGPU instances, you need to use a different VFs.
      </para>
     </important>
<screen>
&prompt.user;cd /sys/bus/pci/devices/0000:b1:00.0/virtfn1/mdev_supported_types
&prompt.user;for i in *; do echo "" $(cat $i/name) available: $(cat $i/avail*); done
GRID A100-4C available: 0
GRID A100-5C available: 0
GRID A100-8C available: 0
GRID A100-10C available: 1
GRID A100-20C available: 0
GRID A100-40C available: 0
GRID A100-1-5C available: 0
GRID A100-2-10C available: 0
GRID A100-3-20C available: 0
GRID A100-4-20C available: 0
GRID A100-7-40C available: 0
GRID A100-1-5CME available: 0
&prompt.user;uuidgen
f715f63c-0d00-4007-9c5a-b07b0c6c05de
&prompt.sudo;echo "f715f63c-0d00-4007-9c5a-b07b0c6c05de" > nvidia-471/create
&prompt.sudo;dmesg | tail
[...]
[ 3218.491843] vfio_mdev f715f63c-0d00-4007-9c5a-b07b0c6c05de: Adding to iommu group 322
[ 3218.499700] vfio_mdev f715f63c-0d00-4007-9c5a-b07b0c6c05de: MDEV: group_id = 322
[ 3599.608540] vfio_mdev f715f63c-0d00-4007-9c5a-b07b0c6c05de: Removing from iommu group 322
[ 3599.616753] vfio_mdev f715f63c-0d00-4007-9c5a-b07b0c6c05de: MDEV: detaching iommu
[ 3626.345530] vfio_mdev f715f63c-0d00-4007-9c5a-b07b0c6c05de: Adding to iommu group 322
[ 3626.353383] vfio_mdev f715f63c-0d00-4007-9c5a-b07b0c6c05de: MDEV: group_id = 322
</screen>
    </step>
    <step>
     <para>
      Verify the new vGPU device:
     </para>
<screen>
&prompt.user;cd /sys/bus/mdev/devices/
&prompt.user;ls
f715f63c-0d00-4007-9c5a-b07b0c6c05de
</screen>
    </step>
    <step>
     <para>
      Query the new vGPU device capability:
     </para>
<screen>
&prompt.sudo;nvidia-smi vgpu -q
GPU 00000000:B1:00.0
Active vGPUs                      : 1
vGPU ID                           : 3251634265
  VM UUID                       : b0d9f0c6-a6c2-463e-967b-06cb206415b6
  VM Name                       : sles15sp2-gehc-vm1
  vGPU Name                     : GRID A100-10C
  vGPU Type                     : 471
  vGPU UUID                     : 444f610c-1b08-11ec-9554-ebd10788ee14
  MDEV UUID                     : f715f63c-0d00-4007-9c5a-b07b0c6c05de
  Guest Driver Version          : N/A
  License Status                : N/A
  GPU Instance ID               : N/A
  Accounting Mode               : N/A
  ECC Mode                      : Disabled
  Accounting Buffer Size        : 4000
  Frame Rate Limit              : N/A
  FB Memory Usage
      Total                     : 10240 MiB
      Used                      : 0 MiB
      Free                      : 10240 MiB
  Utilization
      Gpu                       : 0 %
      Memory                    : 0 %
      Encoder                   : 0 %
      Decoder                   : 0 %
  Encoder Stats
      Active Sessions           : 0
      Average FPS               : 0
      Average Latency           : 0
  FBC Stats
      Active Sessions           : 0
      Average FPS               : 0
      Average Latency           : 0
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="configure-nvidia-vgpu-passthrough-mig-backed">
   <title>Creating a MIG-backed vGPU</title>
   <procedure>
    <step>
     <para>
      Enable MIG mode for a GPU:
     </para>
<screen>
&prompt.sudo;nvidia-smi -i 0 -mig 1
Enabled MIG Mode for GPU 00000000:B1:00.0
All done.
</screen>
    </step>
    <step>
     <para>
      Query the GPU instance profile:
     </para>
<screen>
&prompt.sudo;nvidia-smi mig -lgip
+-----------------------------------------------------------------------------+
| GPU instance profiles:                                                      |
| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |
|                              Free/Total   GiB              CE    JPEG  OFA  |
|=============================================================================|
|   0  MIG 1g.5gb        19     7/7        4.75       No     14     0     0   |
|                                                             1     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 1g.5gb+me     20     1/1        4.75       No     14     1     0   |
|                                                             1     1     1   |
+-----------------------------------------------------------------------------+
|   0  MIG 2g.10gb       14     3/3        9.75       No     28     1     0   |
|                                                             2     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 3g.20gb        9     2/2        19.62      No     42     2     0   |
|                                                             3     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 4g.20gb        5     1/1        19.62      No     56     2     0   |
|                                                             4     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 7g.40gb        0     1/1        39.50      No     98     5     0   |
|                                                             7     1     1   |
+-----------------------------------------------------------------------------+
</screen>
    </step>
    <step>
     <para>
      Create a GPU instance specifying '5' as a GPU profile instance ID:
     </para>
<screen>
&prompt.sudo;nvidia-smi mig -cgi 5
Successfully created GPU instance ID  1 on GPU  0 using profile MIG 4g.20gb (ID  5)
&prompt.sudo;nvidia-smi mig -cci -gi 1
Successfully created compute instance ID  0 on GPU  0 GPU instance ID  1 using profile MIG 4g.20gb (ID  3)
</screen>
    </step>
    <step>
     <para>
      Verify the GPU instance:
     </para>
<screen>
&prompt.sudo;nvidia-smi
Tue Sep 21 11:19:36 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.63       Driver Version: 470.63       CUDA Version: N/A      |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:B1:00.0 Off |                   On |
| N/A   38C    P0    38W / 250W |      0MiB / 40536MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |      0MiB / 20096MiB | 56      0 |  4   0    2    0    0 |
|                  |      0MiB / 32767MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</screen>
    </step>
    <step>
     <para>
      Use the MIG instance. You can use the instance directly with the
      UUID&mdash;for example, pass it through to a &vmguest; or assign it to a
      container/CUDA process.
     </para>
     <para>
      You can also create a vGPU on top of it. The procedure is the same as for
      the vGPU with SR-IOV support. Refer to
      <xref linkend="configure-nvidia-vgpu-passthrough-with-sriov"/>.
     </para>
<screen>
&prompt.sudo;nvidia-smi -L
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-ee14e29d-dd5b-2e8e-eeaf-9d3debd10788)
 MIG 4g.20gb     Device  0: (UUID: MIG-fed03f85-fd95-581b-837f-d582496d0260)
</screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="configure-nvidia-vgpu-configure-guest">
  <title>Configuring vGPU in &vmguest;</title>

  <sect2 xml:id="configure-nvidia-vgpu-passthrough-to-vm">
   <title>Prepare the &vmguest; for vGPU passthrough</title>
   <sect3 xml:id="configure-nvidia-vgpu-passthrough-general-notes">
    <title>General notes</title>
    <itemizedlist>
     <listitem>
      <para>
       During &vmguest; installation, disable secure boot, enable the SSH
       service, and select <literal>wicked</literal> for networking.
      </para>
     </listitem>
     <listitem>
      <para>
       Disable the <literal>nouveau</literal> video driver. Edit the file
       <filename>/etc/modprobe.d/50-blacklist.conf</filename> and add the
       following line to its upper section:
      </para>
<screen>blacklist nouveau</screen>
      <important>
       <para>
        Disabling nouveau will work after you re-generate the mkinitrd image
        and reboot the &vmguest;.
       </para>
      </important>
     </listitem>
    </itemizedlist>
   </sect3>
   <sect3 xml:id="configure-nvidia-vgpu-passthrough-to-vm-libvirt">
    <title>Passthrough by &libvirt;</title>
    <procedure>
     <step>
      <para>
       Create a &libvirt;-based virtual machine (VM) with UEFI support and a
       normal VGA display.
      </para>
     </step>
     <step>
      <para>
       Edit the VM's configuration by running <command>virsh edit
       <replaceable>VM-NAME</replaceable></command>.
      </para>
     </step>
     <step>
      <para>
       Add the new mdev device with the unique ID you used when creating the
       vGPU device to the &lt;devices/> section.
      </para>
      <note>
       <para>
        If you are using Q-series, use <literal>display='on'</literal> instead.
       </para>
      </note>
<screen>
&lt;hostdev mode='subsystem' type='mdev' managed='no' model='vfio-pci' display='off'>
  &lt;source>
    &lt;address uuid='4f3b6e47-0baa-4900-b0b1-284c1ecc192f'/>
  &lt;/source>
  &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x0a' function='0x0'/>
&lt;/hostdev>
</screen>
     </step>
    </procedure>
   </sect3>
   <sect3 xml:id="configure-nvidia-vgpu-passthrough-to-vm-qemu">
    <title>Passthrough by &qemu;</title>
    <para>
     Add the following device to the &qemu; command line. Use the unique ID
     that you used when creating the vGPU device:
    </para>
<screen>-device vfio-pci,sysfsdev=/sys/bus/mdev/devices/4f3b6e47-0baa-4900-b0b1-284c1ecc192f</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="configure-nvidia-vgpu-configure-guest-install-driver">
   <title>Install the vGPU driver in the &vmguest;</title>
   <procedure>
    <step>
     <para>
      Install the following packages and their dependencies:
     </para>
<screen>&prompt.sudo;zypper install kernel-default-devel inlibglvnd-devel</screen>
    </step>
    <step>
     <para>
      Download the &nvidia; video driver from
      <link xlink:href="www.nvidia.com"/>. Make it executable and run it:
     </para>
<screen>
      &prompt.user;chmod +x NVIDIA-Linux-x86_64-470.63.01-grid.run
      &prompt.sudo;./NVIDIA-Linux-x86_64-470.63.01-grid.run
      </screen>
     <tip>
      <para>
       To enable dynamic kernel module support in order to get the module
       rebuilt automatically when new a new kernel is installed, add the
       <option>--dkms</option> option:
      </para>
<screen>&prompt.sudo;./NVIDIA-Linux-x86_64-470.63.01-grid.run --dkms</screen>
     </tip>
    </step>
    <step>
     <para>
      During driver installation:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Select <guimenu>No</guimenu> when prompted about installing 32-bit
        compatibility drivers.
       </para>
      </listitem>
      <listitem>
       <para>
        Select to run the nvidia-xconfig utility.
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Verify the driver installation by checking the output of the
      <command>nvidia-smi</command> command:
     </para>
<screen>
&prompt.sudo;nvidia-smi
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GRID A100-10C       On   | 00000000:07:00.0 Off |                    0 |
| N/A   N/A    P0    N/A /  N/A |    930MiB / 10235MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="configure-nvidia-vgpu-licensing">
  <title>Licensing vGPU in the &vmguest;</title>

  <procedure>
   <step>
    <para>
     Create the configuration file <filename>/etc/nvidia/grid.conf</filename>
     based on <filename>/etc/nvidia/gridd.conf.template</filename>.
    </para>
   </step>
   <step>
    <para>
     Update the following options:
    </para>
    <variablelist>
     <varlistentry>
      <term>ServerAddress</term>
      <listitem>
       <para>
        Add your license server IP address.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>ServerPort</term>
      <listitem>
       <para>
        Use the default "7070" or port configured during the server setup.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>FeatureType</term>
      <listitem>
       <para>
        Choose the right vGPU type.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </step>
   <step>
    <para>
     Restart the <systemitem class="daemon">nvidia-gridd</systemitem> service:
    </para>
<screen>&prompt.sudo;systemctl restart nvidia-gridd.service</screen>
   </step>
   <step>
    <para>
     Inspect the log file for possible errors:
    </para>
<screen>
&prompt.sudo;grep gridd /var/log/messages
[...]
Aug 5 15:40:06 localhost nvidia-gridd: Started (4293)
Aug 5 15:40:24 localhost nvidia-gridd: License acquired successfully.
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="configure-nvidia-vgpu-xorg">
  <title>Configuring a graphics mode</title>

  <para>
   Select <literal>Profile Q</literal> in the licensing configuration file
   <filename>/etc/nvidia/gridd.conf</filename>.
  </para>

  <sect2 xml:id="configure-nvidia-vgpu-xorg-create">
   <title>Create or update the <filename>/etc/X11/xorg.conf</filename> file</title>
   <procedure>
    <step>
     <para>
      If there is no <filename>/etc/X11/xorg.conf</filename> on the &vmguest;,
      run the <command>nvidia-xconfig</command> utility.
     </para>
    </step>
    <step>
     <para>
      Query the GPU device for detailed information:
     </para>
<screen>
&prompt.user;nvidia-xconfig --query-gpu-info
Number of GPUs: 1

GPU #0:
 Name      : GRID V100-16Q
 UUID      : GPU-089f39ad-01cb-11ec-89dc-da10f5778138
 PCI BusID : PCI:0:10:0

Number of Display Devices: 0
</screen>
    </step>
    <step>
     <para>
      Add GPU's BusID to <filename>/etc/X11/xorg.conf</filename>, for example:
     </para>
<screen>
Section "Device"
Identifier "Device0"
Driver "nvidia"
BusID "PCI:0:10:0"
VendorName "NVIDIA Corporation"
EndSection
</screen>
    </step>
   </procedure>
  </sect2>
  <sect2 xml:id="configure-nvidia-vgpu-xorg-verify">
   <title>Verify the graphics mode</title>
   <para>
   </para>
  </sect2>
 </sect1>
 <xi:include href="common_gfdl1.2_i.xml"/>
</article>
