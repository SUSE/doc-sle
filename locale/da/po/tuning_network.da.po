msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2018-09-30 01:10+0200\n"
"PO-Revision-Date: 2018-09-30 01:10+0200\n"
"Last-Translator: Automatically generated\n"
"Language-Team: none\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: da\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#. Put one translator per line, in the form NAME <EMAIL>, YEAR1, YEAR2
msgctxt "_"
msgid "translator-credits"
msgstr ""

#. (itstool) path: chapter/title
#: xml/tuning_network.xml:21
msgid "Tuning the Network"
msgstr ""

#. (itstool) path: chapter/para
#: xml/tuning_network.xml:28
msgid ""
"The network subsystem is complex and its tuning highly depends on the system "
"use scenario and on external factors such as software clients or hardware "
"components (switches, routers, or gateways) in your network. The Linux "
"kernel aims more at reliability and low latency than low overhead and high "
"throughput. Other settings can mean less security, but better performance."
msgstr ""

#. (itstool) path: sect1/title
#: xml/tuning_network.xml:37
msgid "Configurable Kernel Socket Buffers"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:39
msgid ""
"Networking is largely based on the TCP/IP protocol and a socket interface "
"for communication; for more information about TCP/IP, see <xref linkend="
"\"cha.network\"/>. The Linux kernel handles data it receives or sends via "
"the socket interface in socket buffers. These kernel socket buffers are "
"tunable."
msgstr ""

#. (itstool) path: important/title
#: xml/tuning_network.xml:50
msgid "TCP Autotuning"
msgstr ""

#. (itstool) path: important/para
#: xml/tuning_network.xml:51
msgid ""
"Since kernel version 2.6.17 full autotuning with 4 MB maximum buffer size "
"exists. This means that manual tuning usually will not improve networking "
"performance considerably. It is often the best not to touch the following "
"variables, or, at least, to check the outcome of tuning efforts carefully."
msgstr ""

#. (itstool) path: important/para
#: xml/tuning_network.xml:58
msgid ""
"If you update from an older kernel, it is recommended to remove manual TCP "
"tunings in favor of the autotuning feature."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:64
msgid ""
"The special files in the <filename>/proc</filename> file system can modify "
"the size and behavior of kernel socket buffers; for general information "
"about the <filename>/proc</filename> file system, see <xref linkend=\"sec."
"util.proc\"/>. Find networking related files in:"
msgstr ""

#. (itstool) path: sect1/screen
#: xml/tuning_network.xml:71
#, no-wrap
msgid ""
"/proc/sys/net/core\n"
"/proc/sys/net/ipv4\n"
"/proc/sys/net/ipv6"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:75
msgid ""
"General <systemitem>net</systemitem> variables are explained in the kernel "
"documentation (<filename>linux/Documentation/sysctl/net.txt</filename>). "
"Special <systemitem>ipv4</systemitem> variables are explained in "
"<filename>linux/Documentation/networking/ip-sysctl.txt</filename> and "
"<filename>linux/Documentation/networking/ipvs-sysctl.txt</filename>."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:84
msgid ""
"In the <filename>/proc</filename> file system, for example, it is possible "
"to either set the Maximum Socket Receive Buffer and Maximum Socket Send "
"Buffer for all protocols, or both these options for the TCP protocol only "
"(in <filename>ipv4</filename>) and thus overriding the setting for all "
"protocols (in <filename>core</filename>)."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:94
msgid "<filename>/proc/sys/net/ipv4/tcp_moderate_rcvbuf</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:97
msgid ""
"If <filename>/proc/sys/net/ipv4/tcp_moderate_rcvbuf</filename> is set to "
"<literal>1</literal>, autotuning is active and buffer size is adjusted "
"dynamically."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:105
msgid "<filename>/proc/sys/net/ipv4/tcp_rmem</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:108
msgid ""
"The three values setting the minimum, initial, and maximum size of the "
"Memory Receive Buffer per connection. They define the actual memory usage, "
"not only TCP window size."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:116
msgid "<filename>/proc/sys/net/ipv4/tcp_wmem</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:119
msgid ""
"The same as <filename>tcp_rmem</filename>, but for Memory Send Buffer per "
"connection."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:126
msgid "<filename>/proc/sys/net/core/rmem_max</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:129
msgid ""
"Set to limit the maximum receive buffer size that applications can request."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:136
msgid "<filename>/proc/sys/net/core/wmem_max</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:139
msgid ""
"Set to limit the maximum send buffer size that applications can request."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:147
msgid ""
"Via <filename>/proc</filename> it is possible to disable TCP features that "
"you do not need (all TCP features are switched on by default). For example, "
"check the following files:"
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:155
msgid "<filename>/proc/sys/net/ipv4/tcp_timestamps</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:158
msgid "TCP time stamps are defined in RFC1323."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:164
msgid "<filename>/proc/sys/net/ipv4/tcp_window_scaling</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:167
msgid "TCP window scaling is also defined in RFC1323."
msgstr ""

#. (itstool) path: varlistentry/term
#: xml/tuning_network.xml:173
msgid "<filename>/proc/sys/net/ipv4/tcp_sack</filename>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:176
msgid "Select acknowledgments (SACKS)."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:183
msgid ""
"Use <command>sysctl</command> to read or write variables of the <filename>/"
"proc</filename> file system. <command>sysctl</command> is preferable to "
"<command>cat</command> (for reading) and <command>echo</command> (for "
"writing), because it also reads settings from <filename>/etc/sysctl.conf</"
"filename> and, thus, those settings survive reboots reliably. With "
"<command>sysctl</command> you can read all variables and their values "
"easily; as <systemitem class=\"username\">root</systemitem> use the "
"following command to list TCP related settings:"
msgstr ""

#. (itstool) path: sect1/screen
#: xml/tuning_network.xml:194
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> sysctl -a | grep tcp"
msgstr ""

#. (itstool) path: note/title
#: xml/tuning_network.xml:200
msgid "Side-Effects of Tuning Network Variables"
msgstr ""

#. (itstool) path: note/para
#: xml/tuning_network.xml:201
msgid ""
"Tuning network variables can affect other system resources such as CPU or "
"memory use."
msgstr ""

#. (itstool) path: sect1/title
#: xml/tuning_network.xml:212
msgid "Detecting Network Bottlenecks and Analyzing Network Traffic"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:214
msgid ""
"Before starting with network tuning, it is important to isolate network "
"bottlenecks and network traffic patterns. There are some tools that can help "
"you with detecting those bottlenecks."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:220
msgid ""
"The following tools can help analyzing your network traffic: "
"<command>netstat</command>, <command>tcpdump</command>, and "
"<command>wireshark</command>. Wireshark is a network traffic analyzer."
msgstr ""

#. (itstool) path: sect1/title
#: xml/tuning_network.xml:235
msgid "Netfilter"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:237
msgid ""
"The Linux firewall and masquerading features are provided by the Netfilter "
"kernel modules. This is a highly configurable rule based framework. If a "
"rule matches a packet, Netfilter accepts or denies it or takes special "
"action (<quote>target</quote>) as defined by rules such as address "
"translation."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:245
msgid ""
"There are quite a lot of properties Netfilter can take into account. Thus, "
"the more rules are defined, the longer packet processing may last. Also "
"advanced connection tracking could be rather expensive and, thus, slowing "
"down overall networking."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:254
msgid ""
"When the kernel queue becomes full, all new packets are dropped, causing "
"existing connections to fail. The 'fail-open' feature allows a user to "
"temporarily disable the packet inspection and maintain the connectivity "
"under heavy network traffic. For reference, see <link xlink:href=\"https://"
"home.regit.org/netfilter-en/using-nfqueue-and-libnetfilter_queue/\"/>."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:262
msgid ""
"For more information, see the home page of the Netfilter and iptables "
"project, <link xlink:href=\"http://www.netfilter.org\"/>"
msgstr ""

#. (itstool) path: sect1/title
#: xml/tuning_network.xml:268
msgid "Improving the Network Performance with Receive Packet Steering (RPS)"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:270
msgid ""
"Modern network interface devices can move so many packets that the host can "
"become the limiting factor for achieving maximum performance. To keep up, "
"the system must be able to distribute the work across multiple CPU cores."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:277
msgid ""
"Some modern network interfaces can help distribute the work to multiple CPU "
"cores through the implementation of multiple transmission and multiple "
"receive queues in hardware. However, others are only equipped with a single "
"queue and the driver must deal with all incoming packets in a single, "
"serialized stream. To work around this issue, the operating system must "
"\"parallelize\" the stream to distribute the work across multiple CPUs. On "
"<phrase role=\"productname\"><phrase os=\"osuse\">openSUSE Leap</"
"phrase><phrase os=\"sles\">SUSE Linux Enterprise Server</phrase><phrase os="
"\"sled\">SUSE Linux Enterprise Desktop</phrase></phrase> this is done via "
"Receive Packet Steering (RPS). RPS can also be used in virtual environments."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:288
msgid ""
"RPS creates a unique hash for each data stream using IP addresses and port "
"numbers. The use of this hash ensures that packets for the same data stream "
"are sent to the same CPU, which helps to increase performance."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:294
msgid ""
"RPS is configured per network device receive queue and interface. The "
"configuration file names match the following scheme:"
msgstr ""

#. (itstool) path: sect1/screen
#: xml/tuning_network.xml:299
#, no-wrap
msgid "/sys/class/net/<replaceable>&lt;device&gt;</replaceable>/queues/<replaceable>&lt;rx-queue&gt;</replaceable>/rps_cpus"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:301
msgid ""
"<replaceable>&lt;device&gt;</replaceable> stands for the network device, "
"such as <literal>eth0</literal>, <literal>eth1</literal>. <replaceable>&lt;"
"rx-queue&gt;</replaceable> stands for the receive queue, such as "
"<literal>rx-0</literal>, <literal>rx-1</literal>."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:308
msgid ""
"If the network interface hardware only supports a single receive queue, only "
"<literal>rx-0</literal> will exist. If it supports multiple receive queues, "
"there will be an rx-<replaceable>N</replaceable> directory for each receive "
"queue."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:315
msgid ""
"These configuration files contain a comma-delimited list of CPU bitmaps. By "
"default, all bits are set to <literal>0</literal>. With this setting RPS is "
"disabled and therefore the CPU that handles the interrupt will also process "
"the packet queue."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:322
msgid ""
"To enable RPS and enable specific CPUs to process packets for the receive "
"queue of the interface, set the value of their positions in the bitmap to "
"<literal>1</literal>. For example, to enable CPUs 0-3 to process packets for "
"the first receive queue for eth0, set the bit positions 0-3 to 1 in binary: "
"<literal>00001111</literal>. This representation then needs to be converted "
"to hex—which results in <literal>F</literal> in this case. Set this hex "
"value with the following command:"
msgstr ""

#. (itstool) path: sect1/screen
#: xml/tuning_network.xml:332
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> echo \"f\" &gt; /sys/class/net/eth0/queues/rx-0/rps_cpus"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:334
msgid "If you wanted to enable CPUs 8-15:"
msgstr ""

#. (itstool) path: sect1/screen
#: xml/tuning_network.xml:338
#, no-wrap
msgid ""
"1111 1111 0000 0000 (binary)\n"
"15     15    0    0 (decimal)\n"
"F       F    0    0 (hex)"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:342
msgid "The command to set the hex value of <literal>ff00</literal> would be:"
msgstr ""

#. (itstool) path: sect1/screen
#: xml/tuning_network.xml:346
#, no-wrap
msgid "<prompt>tux &gt; </prompt><command>sudo</command> echo \"ff00\" &gt; /sys/class/net/eth0/queues/rx-0/rps_cpus"
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:348
msgid ""
"On NUMA machines, best performance can be achieved by configuring RPS to use "
"the CPUs on the same NUMA node as the interrupt for the interface's receive "
"queue."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:354
msgid ""
"On non-NUMA machines, all CPUs can be used. If the interrupt rate is very "
"high, excluding the CPU handling the network interface can boost "
"performance. The CPU being used for the network interface can be determined "
"from <filename>/proc/interrupts</filename>. For example:"
msgstr ""

#. (itstool) path: sect1/screen
#: xml/tuning_network.xml:361
#, no-wrap
msgid ""
"<prompt>tux &gt; </prompt><command>sudo</command> cat /proc/interrupts\n"
"            CPU0       CPU1       CPU2       CPU3\n"
"...\n"
"  51:  113915241          0          0          0      Phys-fasteoi   eth0\n"
"..."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:367
msgid ""
"In this case, <literal>CPU 0</literal> is the only CPU processing interrupts "
"for <literal>eth0</literal>, since only <literal>CPU0</literal> contains a "
"non-zero value."
msgstr ""

#. (itstool) path: sect1/para
#: xml/tuning_network.xml:373
msgid ""
"On x86 and AMD64/Intel 64 platforms, <command>irqbalance</command> can be "
"used to distribute hardware interrupts across CPUs. See <command>man 1 "
"irqbalance</command> for more details."
msgstr ""

#. (itstool) path: sect1/title
#: xml/tuning_network.xml:384
msgid "For More Information"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:388
msgid ""
"Eduardo Ciliendo, Takechika Kunimasa: <quote>Linux Performance and Tuning "
"Guidelines</quote> (2007), esp. sections 1.5, 3.5, and 4.7: <link xlink:href="
"\"http://www.redbooks.ibm.com/redpapers/abstracts/redp4285.html\"/>"
msgstr ""

#. (itstool) path: listitem/para
#: xml/tuning_network.xml:395
msgid ""
"John Heffner, Matt Mathis: <quote>Tuning TCP for Linux 2.4 and 2.6</quote> "
"(2006): <link xlink:href=\"http://www.psc.edu/networking/projects/tcptune/"
"#Linux\"/>"
msgstr ""
