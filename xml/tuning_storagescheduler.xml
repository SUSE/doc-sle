<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>

<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha-tuning-io">
 <title>Tuning I/O Performance</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:bugtracker>
          </dm:bugtracker>
      </dm:docmanager>
    </info>
    <para>
  I/O scheduling controls how input/output operations will be submitted to
  storage. &productname; offers various I/O algorithms&mdash;called
  <literal>elevators</literal>&mdash;suiting different workloads.
  Elevators can help to reduce seek operations and can prioritize I/O requests.
 </para>
 <para>
  Choosing the best suited I/O elevator not only depends on the workload,
  but on the hardware, too. Single ATA disk systems, SSDs, RAID arrays, or
  network storage systems, for example, each require different tuning
  strategies.
 </para>
 <sect1 xml:id="cha-tuning-io-switch">
  <title>Switching I/O Scheduling</title>

  <para>
   &productname; picks a default I/O scheduler at boot-time, which can be
   changed on the fly per block device. This makes it possible to set different
   algorithms, for example, for the device hosting the system partition and the
   device hosting a database.
  </para>


  <para>
   The default I/O scheduler is chosen for each device based on whether the
   device reports to be rotational disk or not. For rotational disks, the
   <systemitem class="resource">BFQ</systemitem> I/O scheduler is picked.
   Other devices default to <systemitem
   class="resource">MQ-DEADLINE</systemitem> or <systemitem
   class="resource">NONE</systemitem>.
  </para>

  <para>
   To change the elevator for a specific device in the running system, run
   the following command:
  </para>

<screen>&prompt.sudo;echo <replaceable>SCHEDULER</replaceable> &gt; /sys/block/<replaceable>DEVICE</replaceable>/queue/scheduler</screen>

  <para>
   Here, <replaceable>SCHEDULER</replaceable> is one of
   <option>bfq</option>, <option>none</option>,
   <option>kyber</option>, or <option>mq-deadline</option>.
   <replaceable>DEVICE</replaceable> is the block device
   (<systemitem>sda</systemitem> for example). Note that this change will not
   persist during reboot. For permanent I/O scheduler change for a particular
   device either place the command switching the I/O scheduler into init
   scripts or add appropriate udev rule into
   <filename>/lib/udev/rules.d/</filename>. See
   <filename>/lib/udev/rules.d/60-io-scheduler.rules</filename> for an example
   of such tuning.
  </para>

  <note os="sles" arch="zseries">
   <title>Default Scheduler on &zseries;</title>
   <para>
    On &zseries;, the default I/O scheduler for a storage device is
    set by the device driver.
   </para>
  </note>

  <note os="sles" arch="x86_64">
   <title>Change Due to Use of Multi-Queue (blk-mq) I/O path</title>
   <para>
     The <literal>elevator</literal> boot parameter no longer applies to
     devices using blk-mq I/O path.
   </para>
  </note>

 </sect1>

 <sect1 xml:id="cha-tuning-io-schedulers-blkmq">
   <title>Available I/O Elevators with blk-mq I/O path</title>
     <para>
       Below is a list of elevators available on &productname; for devices
       that use the blk-mq I/O path.
       If an elevator has tunable parameters, they can be set with the
       command:
     </para>

<screen>echo <replaceable>VALUE</replaceable> &gt; /sys/block/<replaceable>DEVICE</replaceable>/queue/iosched/<replaceable>TUNABLE</replaceable></screen>

  <para>
   In the command above, <replaceable>VALUE</replaceable> is the desired value for the
   <replaceable>TUNABLE</replaceable> and <replaceable>DEVICE</replaceable> is
   the block device.
  </para>

  <para>
   To find out what elevators are available for a device
   (<systemitem>sda</systemitem> for example), run the following
   command (the currently selected scheduler is listed in brackets):
  </para>

<screen>&prompt.user;cat /sys/block/sda/queue/scheduler
[mq-deadline] kyber bfq none</screen>

  <note os="sles" arch="x86_64">
    <title>Scheduler Options When Switching from
    Legacy Block to blk-mq I/O path</title>
    <para>
      When switching from legacy block to blk-mq I/O path for a device,
      the <option>none</option> option is roughly comparable to
      <option>noop</option>, <option>mq-deadline</option> is comparable
      to <option>deadline</option>, and <option>bfq</option> is
      comparable to <option>cfq</option>.
     </para>
  </note>

  <sect2 xml:id="sec-tuning-io-schedulers-mqdeadline">
   <title><systemitem class="resource">MQ-DEADLINE</systemitem></title>
   <para>
     <systemitem class="resource">MQ-DEADLINE</systemitem> is a
     latency-oriented I/O scheduler. <systemitem
     class="resource">MQ-DEADLINE</systemitem> has the following
     tunable parameters:
   </para>

   <table xml:id="tab-tunables-mq-deadline">
     <title><systemitem class="resource">MQ-DEADLINE</systemitem> tunable parameters</title>
     <tgroup cols="2">
       <colspec colnum="1" colname="1" colwidth="3000*"/>
       <colspec colnum="2" colname="2" colwidth="7000*"/>
       <thead>
	 <row>
	   <entry><para>File</para></entry>
	   <entry><para>Description</para></entry>
	 </row>
       </thead>
       <tbody>
	 <row>
	   <entry><para><filename>writes_starved</filename></para></entry>
	   <entry><para> Controls how many times reads are preferred
	   over writes. A value of <literal>3</literal> means that
	   three read operations can be done before writes and reads
	   are dispatched on the same selection criteria.
	   </para><para>Default is <literal>3</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>read_expire</filename></para></entry>
	   <entry><para> Sets the deadline (current time plus the
	   <literal>read_expire</literal> value) for read operations in milliseconds.
	   </para><para>Default is <literal>500</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>write_expire</filename></para></entry>
	   <entry><para> Sets the deadline (current time plus the
	   <literal>write_expire</literal> value) for write operations in
	   milliseconds.
	   </para><para>Default is <literal>5000</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>front_merges</filename></para></entry>
	   <entry><para> Enables (1) or disables (0) attempts to front
	   merge requests.
	   </para><para>Default is <literal>1</literal>.</para></entry>
	 </row>
	 <row>
	   <entry><para><filename>fifo_batch</filename></para></entry>
	   <entry><para> Sets the maximum number of requests per batch
	   (deadline expiration is only checked for batches). This
	   parameter allows to balance between latency and
	   throughput. When set to <literal>1</literal> (that is, one
	   request per batch), it results in "first come, first served"
	   behavior and usually lowest latency. Higher values usually
	   increase throughput.
	   </para><para>Default is <literal>16</literal>.
	   </para></entry>
	 </row>
       </tbody>
     </tgroup>
   </table>
  </sect2>

  <sect2 xml:id="sec-tuning-io-schedulers-none">
   <title><systemitem class="resource">NONE</systemitem></title>
   <para>
     When <systemitem class="resource">NONE</systemitem> is selected
     as I/O elevator option for blk-mq, no I/O scheduler
     is used, and I/O requests are passed down to the
     device without further I/O scheduling interaction.
   </para>
   <para>
     <systemitem class="resource">NONE</systemitem> is the default for
     NVM Express devices. With no overhead compared to other I/O
     elevator options, it is considered the fastest way of passing down
     I/O requests on multiple queues to such devices.
   </para>
   <para>
     There are no tunable parameters for <systemitem
     class="resource">NONE</systemitem>.
   </para>
  </sect2>

  <sect2 xml:id="sec-tuning-io-schedulers-bfq">
   <title><systemitem class="resource">BFQ</systemitem> (Budget Fair Queueing)</title>
   <para>
     <systemitem class="resource">BFQ</systemitem> is a
     fairness-oriented scheduler. It is described as "a
     proportional-share storage-I/O scheduling algorithm based on the
     slice-by-slice service scheme of CFQ. But BFQ assigns budgets,
     measured in number of sectors, to processes instead of time
     slices." (Source: <!-- This is a permalink for https://github.com/torvalds/linux/blob/v4.12/block/bfq-iosched.c#L31 -->
     <link xlink:href="https://github.com/torvalds/linux/blob/6f7da290413ba713f0cdd9ff1a2a9bb129ef4f6c/block/bfq-iosched.c#L31">linux-4.12/block/bfq-iosched.c</link>)
   </para>
   <para>
     <systemitem class="resource">BFQ</systemitem> allows to assign
     I/O priorities to tasks which are taken into account during
     scheduling decisions (see <xref
     linkend="cha-tuning-resources-disk-ionice"/>).
   </para>
   <para>
     <systemitem class="resource">BFQ</systemitem> scheduler has the
     following tunable parameters:
   </para>
   <table xml:id="tab-tunables-bfq">
     <title><systemitem class="resource">BFQ</systemitem> tunable parameters</title>
     <tgroup cols="2">
       <colspec colnum="1" colname="1" colwidth="3000*"/>
       <colspec colnum="2" colname="2" colwidth="7000*"/>
       <thead>
	 <row>
	   <entry><para>File</para></entry>
	   <entry><para>Description</para></entry>
	 </row>
       </thead>
       <tbody>
	 <row>
	   <entry><para><filename>slice_idle</filename></para></entry>
	   <entry><para>Value in milliseconds specifies how long to
	   idle, waiting for next request on an empty queue.
	   </para><para>Default is <literal>8</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>slice_idle_us</filename></para></entry>
	   <entry><para>Same as <filename>slice_idle</filename> but in
	   microseconds.
	   </para><para>Default is <literal>8000</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>low_latency</filename></para></entry>
	   <entry><para>Enables (1) or disables (0) <systemitem
	   class="resource">BFQ</systemitem>'s low latency mode. This
	   mode prioritizes certain applications (for example, if interactive)
	   such that they observe lower latency.
	   </para><para>Default is <literal>1</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>back_seek_max</filename></para></entry>
	   <entry><para> Maximum value (in Kbytes) for backward seeking.
	   </para><para>Default is <literal>16384</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>back_seek_penalty</filename></para></entry>
	   <entry><para> Used to compute the cost of backward seeking.
	   </para><para>Default is <literal>2</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>fifo_expire_async</filename></para></entry>
	   <entry><para> Value (in milliseconds) is used to set the
	   timeout of asynchronous requests.
	   </para><para>Default is <literal>250</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>fifo_expire_sync</filename></para></entry>
	   <entry><para> Value in milliseconds specifies the
	   timeout of synchronous requests.
	   </para><para>Default is <literal>125</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>timeout_sync</filename></para></entry>
	   <entry><para> Maximum time in milliseconds that a task
	   (queue) is serviced after it has been selected.
	   </para><para>Default is <literal>124</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>max_budget</filename></para></entry>
	   <entry><para> Limit for number of sectors that are served
	   at maximum within <literal>timeout_sync</literal>. If set to
	   <literal>0</literal> <systemitem
	   class="resource">BFQ</systemitem> internally calculates a
	   value based on <filename>timeout_sync</filename> and an
	   estimated peak rate.
	   </para><para>Default is <literal>0</literal>
	   (set to auto-tuning). </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>strict_guarantees</filename></para></entry>
	   <entry><para> Enables (1) or disables (0) <systemitem
	   class="resource">BFQ</systemitem> specific queue handling
	   required to give stricter bandwidth sharing guarantees
	   under certain conditions.
	   </para><para>Default is <literal>0</literal>.
	   </para></entry>
	 </row>
       </tbody>
     </tgroup>
   </table>
  </sect2>

  <sect2 xml:id="sec-tuning-io-schedulers-kyber">
   <title><systemitem class="resource">KYBER</systemitem></title>
   <para>
    <systemitem class="resource">KYBER</systemitem> is a
    latency-oriented I/O scheduler. It makes it possible to set target latencies
    for reads and synchronous writes and throttles I/O requests in
    order to try to meet these target latencies.
   </para>
   <table xml:id="tab-tunables-kyber">
     <title><systemitem class="resource">KYBER</systemitem> tunable parameters</title>
     <tgroup cols="2">
       <colspec colnum="1" colname="1" colwidth="3000*"/>
       <colspec colnum="2" colname="2" colwidth="7000*"/>
       <thead>
	 <row>
	   <entry><para>File</para></entry>
	   <entry><para>Description</para></entry>
	 </row>
       </thead>
       <tbody>
	 <row>
	   <entry><para><filename>read_lat_nsec</filename></para></entry>
	   <entry><para>Sets the target latency for read operations in
	   nanoseconds.
	   </para><para>Default is <literal>2000000</literal>.
	   </para></entry>
	 </row>
	 <row>
	   <entry><para><filename>write_lat_nsec</filename></para></entry>
	   <entry><para>Sets the target latency for write operations in
	   nanoseconds.
	   </para><para>Default is <literal>10000000</literal>.
	   </para></entry>
	 </row>
       </tbody>
     </tgroup>
   </table>

  </sect2>
 </sect1>
 <sect1 xml:id="cha-tuning-io-barrier">
  <title>I/O Barrier Tuning</title>

  <para>
   Some file systems (for example, Ext3 or Ext4) send write
   barriers to disk after fsync or during transaction commits. Write
   barriers enforce proper ordering of writes, making volatile disk write
   caches safe to use (at some performance penalty). If your disks are
   battery-backed in one way or another, disabling barriers can safely
   improve performance.
  </para>

  <para>
   Sending write barriers can be disabled using the
   <option>nobarrier</option> mount option.
  </para>

  <warning>
   <title>Disabling Barriers Can Lead to Data Loss</title>
   <para>
    Disabling barriers when disks cannot guarantee caches are properly
    written in case of power failure can lead to severe file system
    corruption and data loss.
   </para>
  </warning>
 </sect1>

</chapter>
